{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np, os, sys\n",
    "from tqdm.notebook import tqdm    \n",
    "from manipulations import get_classes, get_classes_from_header, get_Fs_from_header, load_challenge_data\n",
    "from sklearn.model_selection import KFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLASS = 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_RR = 750 # 60 beats/min => 60 beats/60 s ==> beat/1s ==> 500 samples / beat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from manipulations import get_abbr, get_name\n",
    "from global_vars import labels, Dx_map, Dx_map_unscored\n",
    "first_idx = {scored_code: None for scored_code in list(Dx_map['SNOMED CT Code'])}\n",
    "first_idx_unscored = {unscored_code: None for unscored_code in list(Dx_map_unscored['SNOMED CT Code'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from global_vars import labels, normal_class, equivalent_mapping\n",
    "normal_idx = np.argwhere(labels==int(normal_class))\n",
    "def get_scored_class(code, labels):\n",
    "    return [1 if label in code else 0 for label in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset  1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7689163a134b46f0815999a4ea38a0a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done.\n",
      "Dataset  2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "601b0179a44e46cab4f9482ce241f645",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done.\n",
      "Dataset  3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0b6f736d128438794a4ee94dcef688d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done.\n",
      "Dataset  4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f71b41531264bf0ae86d69beda7aec2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done.\n",
      "Dataset  5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5765026105a4375bbc8a84a0314f439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done.\n",
      "Dataset  6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42cb49ea2b884a6e97f7aabb9a26c7c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "#pip install iterative-stratification\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    Datas = []\n",
    "    Header_datas = []\n",
    "    Classes = []\n",
    "    Codes = []\n",
    "    \n",
    "    dataset_idx = {}\n",
    "    dataset_data_labels = {}\n",
    "    dataset_train_idx = {}\n",
    "    dataset_test_idx = {}\n",
    "    \n",
    "    global_idx = 0\n",
    "    datasets = [1,2,3,4,5,6]\n",
    "    for dataset in datasets:\n",
    "        print('Dataset ', dataset)\n",
    "        # Parse arguments.\n",
    "        if len(sys.argv) != 3:\n",
    "            raise Exception('Include the input and output directories as arguments, e.g., python driver.py input output.')\n",
    "\n",
    "        input_directory = '../NewData/{}/'.format(dataset)\n",
    "        output_directory = '../Output/'\n",
    "\n",
    "        # Find files.\n",
    "        input_files = []\n",
    "        for f in os.listdir(input_directory):\n",
    "            if os.path.isfile(os.path.join(input_directory, f)) and not f.lower().startswith('.') and f.lower().endswith('mat'):\n",
    "                input_files.append(f)\n",
    "\n",
    "        if not os.path.isdir(output_directory):\n",
    "            os.mkdir(output_directory)\n",
    "\n",
    "        classes=get_classes(input_directory,input_files)\n",
    "\n",
    "        num_files = len(input_files)\n",
    "        datas = []\n",
    "        header_datas = []\n",
    "        dataset_data_labels[dataset] = []\n",
    "        dataset_idx[dataset] = []\n",
    "        for i, f in tqdm(enumerate(input_files)):\n",
    "            #print('    {}/{}...'.format(i+1, num_files), f)\n",
    "            tmp_input_file = os.path.join(input_directory,f)\n",
    "            data,header_data = load_challenge_data(tmp_input_file)\n",
    "            \n",
    "            codes = get_classes_from_header(header_data)\n",
    "            data_labels = get_scored_class(codes, labels)\n",
    "            \n",
    "            datas.append(data[:,1000:7000])\n",
    "            header_datas.append(header_data)\n",
    "            dataset_data_labels[dataset].append(data_labels)\n",
    "            dataset_idx[dataset].append(global_idx)\n",
    "            global_idx += 1\n",
    "\n",
    "        Datas += datas\n",
    "        Header_datas += header_datas\n",
    "        Classes += classes\n",
    "        \n",
    "        kf = MultilabelStratifiedKFold(5)\n",
    "        train_idx, test_idx = next(kf.split(datas, np.array(dataset_data_labels[dataset])))\n",
    "\n",
    "\n",
    "        dataset_train_idx[dataset] = train_idx\n",
    "        dataset_test_idx[dataset] = test_idx\n",
    "        \n",
    "        \n",
    "        print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "Q_locs = None\n",
    "with open('../saved/newData_Q_locs_1000_7000_peakdist100.pkl', 'rb') as Q_locs_file:\n",
    "    Q_locs = pickle.load(Q_locs_file)\n",
    "\n",
    "Codes = None\n",
    "with open('../saved/newData_Codes_1000_7000_peakdist100.pkl', 'rb') as Codes_file:\n",
    "    Codes = pickle.load(Codes_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../saved/all_train_idx_stratified.pkl', 'rb') as all_train_idx_file:\n",
    "    all_train_idx = pickle.load(all_train_idx_file)\n",
    "with open('../saved/all_test_idx_stratified.pkl', 'rb') as all_test_idx_file:\n",
    "    all_test_idx = pickle.load(all_test_idx_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52864"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Idxes_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdbc74af7eb3407ab04f1a5e8a004a05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8619.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_test = []\n",
    "Data_labels_test = []\n",
    "Idxes_test = []\n",
    "for i in tqdm(all_test_idx):\n",
    "    #print(i)\n",
    "        \n",
    "    Q_loc = Q_locs[i]\n",
    "    RR_avg = np.median([Q_loc[k+1] - Q_loc[k] for k in range(len(Q_loc)-1)])\n",
    "    RR_th = (0.3 * RR_avg, 3 * RR_avg)\n",
    "    \n",
    "    ks = [k for k in range(len(Q_loc)-1) if Q_loc[k+1] - Q_loc[k] > RR_th[0] \n",
    "              and Q_loc[k+1] - Q_loc[k] < RR_th[1]]\n",
    "    \n",
    "    \n",
    "    for k in ks:\n",
    "        Data_labels_test.append(get_scored_class(Codes[i], labels))\n",
    "        X_test.append(Datas[i][:,1000+Q_loc[k]:1000+Q_loc[k+1]])\n",
    "        Idxes_test.append(i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 47,\n",
       " 47,\n",
       " 47,\n",
       " 47,\n",
       " 47,\n",
       " 47,\n",
       " 47,\n",
       " 55,\n",
       " 55,\n",
       " 55,\n",
       " 55,\n",
       " 55,\n",
       " 55,\n",
       " 55,\n",
       " 55,\n",
       " 55,\n",
       " 55,\n",
       " 56,\n",
       " 56,\n",
       " 56,\n",
       " 56,\n",
       " 56,\n",
       " 56,\n",
       " 56,\n",
       " 56,\n",
       " 56,\n",
       " 56,\n",
       " 56,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 67,\n",
       " 67,\n",
       " 67,\n",
       " 67,\n",
       " 67,\n",
       " 67,\n",
       " 67,\n",
       " 67,\n",
       " 67,\n",
       " 67,\n",
       " 69,\n",
       " 69,\n",
       " 69,\n",
       " 69,\n",
       " 69,\n",
       " 69,\n",
       " 69,\n",
       " 69,\n",
       " 69,\n",
       " 69,\n",
       " 69,\n",
       " 69,\n",
       " 69,\n",
       " 72,\n",
       " 72,\n",
       " 72,\n",
       " 72,\n",
       " 72,\n",
       " 72,\n",
       " 72,\n",
       " 72,\n",
       " 72,\n",
       " 72,\n",
       " 83,\n",
       " 83,\n",
       " 83,\n",
       " 83,\n",
       " 83,\n",
       " 83,\n",
       " 83,\n",
       " 83,\n",
       " 83,\n",
       " 83,\n",
       " 84,\n",
       " 84,\n",
       " 84,\n",
       " 84,\n",
       " 84,\n",
       " 84,\n",
       " 84,\n",
       " 84,\n",
       " 84,\n",
       " 89,\n",
       " 89,\n",
       " 89,\n",
       " 89,\n",
       " 89,\n",
       " 89,\n",
       " 89,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 97,\n",
       " 97,\n",
       " 97,\n",
       " 97,\n",
       " 97,\n",
       " 97,\n",
       " 97,\n",
       " 97,\n",
       " 97,\n",
       " 97,\n",
       " 97,\n",
       " 97,\n",
       " 97,\n",
       " 104,\n",
       " 104,\n",
       " 104,\n",
       " 104,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 111,\n",
       " 111,\n",
       " 111,\n",
       " 111,\n",
       " 111,\n",
       " 111,\n",
       " 111,\n",
       " 111,\n",
       " 111,\n",
       " 111,\n",
       " 126,\n",
       " 126,\n",
       " 126,\n",
       " 126,\n",
       " 126,\n",
       " 126,\n",
       " 126,\n",
       " 126,\n",
       " 126,\n",
       " 126,\n",
       " 128,\n",
       " 128,\n",
       " 128,\n",
       " 128,\n",
       " 128,\n",
       " 128,\n",
       " 128,\n",
       " 128,\n",
       " 128,\n",
       " 128,\n",
       " 128,\n",
       " 128,\n",
       " 128,\n",
       " 128,\n",
       " 131,\n",
       " 131,\n",
       " 131,\n",
       " 131,\n",
       " 131,\n",
       " 131,\n",
       " 135,\n",
       " 135,\n",
       " 135,\n",
       " 135,\n",
       " 135,\n",
       " 135,\n",
       " 135,\n",
       " 135,\n",
       " 135,\n",
       " 135,\n",
       " 135,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 144,\n",
       " 144,\n",
       " 144,\n",
       " 144,\n",
       " 144,\n",
       " 144,\n",
       " 144,\n",
       " 144,\n",
       " 144,\n",
       " 144,\n",
       " 144,\n",
       " 144,\n",
       " 150,\n",
       " 150,\n",
       " 150,\n",
       " 150,\n",
       " 150,\n",
       " 150,\n",
       " 150,\n",
       " 150,\n",
       " 150,\n",
       " 150,\n",
       " 150,\n",
       " 150,\n",
       " 150,\n",
       " 150,\n",
       " 153,\n",
       " 153,\n",
       " 153,\n",
       " 153,\n",
       " 153,\n",
       " 153,\n",
       " 153,\n",
       " 153,\n",
       " 153,\n",
       " 153,\n",
       " 153,\n",
       " 153,\n",
       " 158,\n",
       " 158,\n",
       " 158,\n",
       " 158,\n",
       " 158,\n",
       " 158,\n",
       " 158,\n",
       " 158,\n",
       " 158,\n",
       " 158,\n",
       " 158,\n",
       " 158,\n",
       " 158,\n",
       " 158,\n",
       " 158,\n",
       " 158,\n",
       " 165,\n",
       " 165,\n",
       " 165,\n",
       " 165,\n",
       " 165,\n",
       " 165,\n",
       " 165,\n",
       " 165,\n",
       " 165,\n",
       " 165,\n",
       " 165,\n",
       " 165,\n",
       " 165,\n",
       " 165,\n",
       " 165,\n",
       " 165,\n",
       " 167,\n",
       " 167,\n",
       " 167,\n",
       " 167,\n",
       " 167,\n",
       " 167,\n",
       " 167,\n",
       " 167,\n",
       " 167,\n",
       " 167,\n",
       " 167,\n",
       " 173,\n",
       " 173,\n",
       " 173,\n",
       " 173,\n",
       " 173,\n",
       " 173,\n",
       " 173,\n",
       " 173,\n",
       " 173,\n",
       " 180,\n",
       " 180,\n",
       " 180,\n",
       " 180,\n",
       " 180,\n",
       " 180,\n",
       " 180,\n",
       " 180,\n",
       " 180,\n",
       " 180,\n",
       " 188,\n",
       " 188,\n",
       " 188,\n",
       " 188,\n",
       " 188,\n",
       " 188,\n",
       " 197,\n",
       " 197,\n",
       " 197,\n",
       " 197,\n",
       " 197,\n",
       " 197,\n",
       " 197,\n",
       " 197,\n",
       " 206,\n",
       " 206,\n",
       " 206,\n",
       " 206,\n",
       " 206,\n",
       " 206,\n",
       " 206,\n",
       " 206,\n",
       " 206,\n",
       " 207,\n",
       " 207,\n",
       " 207,\n",
       " 207,\n",
       " 207,\n",
       " 207,\n",
       " 207,\n",
       " 207,\n",
       " 207,\n",
       " 207,\n",
       " 207,\n",
       " 207,\n",
       " 207,\n",
       " 207,\n",
       " 207,\n",
       " 207,\n",
       " 210,\n",
       " 210,\n",
       " 210,\n",
       " 210,\n",
       " 210,\n",
       " 210,\n",
       " 210,\n",
       " 210,\n",
       " 210,\n",
       " 210,\n",
       " 210,\n",
       " 210,\n",
       " 211,\n",
       " 211,\n",
       " 211,\n",
       " 211,\n",
       " 211,\n",
       " 211,\n",
       " 211,\n",
       " 211,\n",
       " 211,\n",
       " 211,\n",
       " 211,\n",
       " 211,\n",
       " 211,\n",
       " 211,\n",
       " 211,\n",
       " 211,\n",
       " 211,\n",
       " 211,\n",
       " 216,\n",
       " 216,\n",
       " 216,\n",
       " 216,\n",
       " 216,\n",
       " 216,\n",
       " 216,\n",
       " 216,\n",
       " 216,\n",
       " 216,\n",
       " 216,\n",
       " 216,\n",
       " 216,\n",
       " 216,\n",
       " 216,\n",
       " 216,\n",
       " 216,\n",
       " 216,\n",
       " 216,\n",
       " 217,\n",
       " 217,\n",
       " 217,\n",
       " 217,\n",
       " 217,\n",
       " 217,\n",
       " 217,\n",
       " 217,\n",
       " 217,\n",
       " 225,\n",
       " 225,\n",
       " 225,\n",
       " 225,\n",
       " 225,\n",
       " 225,\n",
       " 225,\n",
       " 225,\n",
       " 225,\n",
       " 232,\n",
       " 232,\n",
       " 232,\n",
       " 232,\n",
       " 232,\n",
       " 232,\n",
       " 232,\n",
       " 232,\n",
       " 232,\n",
       " 232,\n",
       " 232,\n",
       " 232,\n",
       " 232,\n",
       " 233,\n",
       " 233,\n",
       " 233,\n",
       " 233,\n",
       " 233,\n",
       " 233,\n",
       " 233,\n",
       " 233,\n",
       " 233,\n",
       " 233,\n",
       " 233,\n",
       " 233,\n",
       " 233,\n",
       " 233,\n",
       " 233,\n",
       " 233,\n",
       " 233,\n",
       " 239,\n",
       " 239,\n",
       " 239,\n",
       " 239,\n",
       " 239,\n",
       " 239,\n",
       " 239,\n",
       " 239,\n",
       " 243,\n",
       " 243,\n",
       " 243,\n",
       " 243,\n",
       " 243,\n",
       " 243,\n",
       " 243,\n",
       " 246,\n",
       " 246,\n",
       " 246,\n",
       " 246,\n",
       " 246,\n",
       " 246,\n",
       " 246,\n",
       " 246,\n",
       " 246,\n",
       " 246,\n",
       " 246,\n",
       " 249,\n",
       " 249,\n",
       " 249,\n",
       " 249,\n",
       " 249,\n",
       " 249,\n",
       " 249,\n",
       " 249,\n",
       " 249,\n",
       " 261,\n",
       " 261,\n",
       " 261,\n",
       " 261,\n",
       " 261,\n",
       " 261,\n",
       " 261,\n",
       " 261,\n",
       " 261,\n",
       " 264,\n",
       " 264,\n",
       " 264,\n",
       " 264,\n",
       " 264,\n",
       " 264,\n",
       " 264,\n",
       " 264,\n",
       " 265,\n",
       " 265,\n",
       " 265,\n",
       " 265,\n",
       " 265,\n",
       " 265,\n",
       " 265,\n",
       " 265,\n",
       " 265,\n",
       " 265,\n",
       " 265,\n",
       " 271,\n",
       " 271,\n",
       " 271,\n",
       " 271,\n",
       " 271,\n",
       " 271,\n",
       " 271,\n",
       " 271,\n",
       " 271,\n",
       " 271,\n",
       " 271,\n",
       " 282,\n",
       " 282,\n",
       " 282,\n",
       " 282,\n",
       " 282,\n",
       " 282,\n",
       " 282,\n",
       " 282,\n",
       " 282,\n",
       " 282,\n",
       " 290,\n",
       " 290,\n",
       " 290,\n",
       " 290,\n",
       " 290,\n",
       " 290,\n",
       " 290,\n",
       " 290,\n",
       " 290,\n",
       " 290,\n",
       " 290,\n",
       " 290,\n",
       " 290,\n",
       " 290,\n",
       " 291,\n",
       " 291,\n",
       " 291,\n",
       " 291,\n",
       " 291,\n",
       " 291,\n",
       " 293,\n",
       " 293,\n",
       " 293,\n",
       " 293,\n",
       " 293,\n",
       " 293,\n",
       " 293,\n",
       " 293,\n",
       " 293,\n",
       " 296,\n",
       " 296,\n",
       " 296,\n",
       " 296,\n",
       " 296,\n",
       " 296,\n",
       " 296,\n",
       " 296,\n",
       " 296,\n",
       " 296,\n",
       " 296,\n",
       " 298,\n",
       " 298,\n",
       " 298,\n",
       " 298,\n",
       " 298,\n",
       " 298,\n",
       " 298,\n",
       " 298,\n",
       " 298,\n",
       " 305,\n",
       " 305,\n",
       " 305,\n",
       " 305,\n",
       " 305,\n",
       " 305,\n",
       " 305,\n",
       " 305,\n",
       " 305,\n",
       " 305,\n",
       " 305,\n",
       " 305,\n",
       " 305,\n",
       " 305,\n",
       " 305,\n",
       " 308,\n",
       " 308,\n",
       " 308,\n",
       " 308,\n",
       " 308,\n",
       " 308,\n",
       " 308,\n",
       " 308,\n",
       " 308,\n",
       " 308,\n",
       " 308,\n",
       " 308,\n",
       " 308,\n",
       " 308,\n",
       " 308,\n",
       " 308,\n",
       " 309,\n",
       " 309,\n",
       " 309,\n",
       " 309,\n",
       " 309,\n",
       " 309,\n",
       " 309,\n",
       " 309,\n",
       " 309,\n",
       " 309,\n",
       " 309,\n",
       " 309,\n",
       " 309,\n",
       " 309,\n",
       " 309,\n",
       " 309,\n",
       " 309,\n",
       " 309,\n",
       " 318,\n",
       " 318,\n",
       " 318,\n",
       " 318,\n",
       " 318,\n",
       " 318,\n",
       " 318,\n",
       " 318,\n",
       " 318,\n",
       " 318,\n",
       " 318,\n",
       " 318,\n",
       " 318,\n",
       " 318,\n",
       " 318,\n",
       " 323,\n",
       " 323,\n",
       " 323,\n",
       " 323,\n",
       " 323,\n",
       " 323,\n",
       " 323,\n",
       " 323,\n",
       " 323,\n",
       " 323,\n",
       " 323,\n",
       " 323,\n",
       " 329,\n",
       " 329,\n",
       " 329,\n",
       " 329,\n",
       " 329,\n",
       " 329,\n",
       " 329,\n",
       " 338,\n",
       " 338,\n",
       " 338,\n",
       " 338,\n",
       " 338,\n",
       " 338,\n",
       " 338,\n",
       " 338,\n",
       " 338,\n",
       " 338,\n",
       " 341,\n",
       " 341,\n",
       " 341,\n",
       " 341,\n",
       " 341,\n",
       " 341,\n",
       " 341,\n",
       " 341,\n",
       " 341,\n",
       " 342,\n",
       " 342,\n",
       " 342,\n",
       " 342,\n",
       " 342,\n",
       " 342,\n",
       " 342,\n",
       " 342,\n",
       " 342,\n",
       " 342,\n",
       " 342,\n",
       " 342,\n",
       " 342,\n",
       " 342,\n",
       " 342,\n",
       " 347,\n",
       " 347,\n",
       " 347,\n",
       " 347,\n",
       " 347,\n",
       " 347,\n",
       " 347,\n",
       " 347,\n",
       " 347,\n",
       " 347,\n",
       " 353,\n",
       " 353,\n",
       " 353,\n",
       " 353,\n",
       " 353,\n",
       " 353,\n",
       " 353,\n",
       " 353,\n",
       " 353,\n",
       " 353,\n",
       " 353,\n",
       " 353,\n",
       " 353,\n",
       " 357,\n",
       " 357,\n",
       " 357,\n",
       " 357,\n",
       " 357,\n",
       " 357,\n",
       " 357,\n",
       " 357,\n",
       " 357,\n",
       " 357,\n",
       " 357,\n",
       " 358,\n",
       " 358,\n",
       " 358,\n",
       " 358,\n",
       " 358,\n",
       " 358,\n",
       " 358,\n",
       " 358,\n",
       " 358,\n",
       " 358,\n",
       " 358,\n",
       " 358,\n",
       " 358,\n",
       " 358,\n",
       " 358,\n",
       " 358,\n",
       " 358,\n",
       " 358,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 375,\n",
       " 375,\n",
       " 375,\n",
       " 375,\n",
       " 375,\n",
       " 375,\n",
       " 375,\n",
       " 375,\n",
       " 375,\n",
       " 375,\n",
       " 375,\n",
       " 375,\n",
       " 378,\n",
       " 378,\n",
       " 378,\n",
       " 378,\n",
       " 378,\n",
       " 378,\n",
       " 378,\n",
       " 378,\n",
       " 378,\n",
       " 378,\n",
       " 378,\n",
       " 378,\n",
       " 378,\n",
       " 385,\n",
       " 385,\n",
       " 385,\n",
       " 385,\n",
       " 385,\n",
       " 385,\n",
       " 385,\n",
       " 385,\n",
       " 385,\n",
       " 385,\n",
       " 385,\n",
       " 385,\n",
       " 385,\n",
       " 385,\n",
       " 386,\n",
       " 386,\n",
       " 386,\n",
       " 386,\n",
       " 386,\n",
       " 386,\n",
       " 386,\n",
       " 386,\n",
       " 386,\n",
       " 386,\n",
       " 386,\n",
       " 386,\n",
       " 386,\n",
       " 386,\n",
       " 386,\n",
       " 396,\n",
       " 396,\n",
       " 396,\n",
       " 396,\n",
       " 396,\n",
       " 396,\n",
       " 396,\n",
       " 396,\n",
       " 396,\n",
       " 396,\n",
       " 396,\n",
       " 396,\n",
       " 396,\n",
       " 396,\n",
       " 396,\n",
       " 399,\n",
       " 399,\n",
       " 399,\n",
       " 399,\n",
       " 399,\n",
       " 399,\n",
       " 399,\n",
       " 399,\n",
       " 399,\n",
       " 404,\n",
       " 404,\n",
       " 404,\n",
       " 404,\n",
       " 404,\n",
       " 404,\n",
       " 404,\n",
       " 404,\n",
       " 404,\n",
       " 404,\n",
       " 404,\n",
       " 410,\n",
       " 410,\n",
       " 410,\n",
       " 410,\n",
       " 410,\n",
       " 410,\n",
       " 410,\n",
       " 410,\n",
       " 410,\n",
       " 410,\n",
       " 410,\n",
       " 410,\n",
       " 413,\n",
       " 413,\n",
       " 413,\n",
       " 413,\n",
       " 413,\n",
       " 413,\n",
       " 413,\n",
       " 413,\n",
       " 413,\n",
       " 413,\n",
       " 413,\n",
       " 413,\n",
       " 413,\n",
       " 413,\n",
       " 413,\n",
       " 413,\n",
       " 413,\n",
       " 413,\n",
       " 416,\n",
       " 416,\n",
       " 416,\n",
       " 416,\n",
       " 416,\n",
       " 416,\n",
       " 416,\n",
       " 416,\n",
       " 416,\n",
       " 416,\n",
       " 416,\n",
       " 416,\n",
       " ...]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Idxes_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On y va"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Signals_test = np.load('../saved/Signals_test_stratified.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../saved/Data_labels_test_stratified.pkl', 'rb') as Data_labels_test_file:\n",
    "    Data_labels_test = pickle.load(Data_labels_test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from resnet1d import ECGResNet50\n",
    "\n",
    "def load_trained_model(model_saved_path):\n",
    "    model = ECGResNet50(MAX_RR, N_CLASS)\n",
    "    \n",
    "    # load saved model\n",
    "    model.load_state_dict(torch.load(model_saved_path, map_location=torch.device('cpu')))\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_saved_path = '../saved/resnet50/resnet50_resnet50_minibatch_adam_batch512_0.01_stratified_model.dict'\n",
    "model = load_trained_model(model_saved_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Signal_12leads_test= np.transpose(Signals_test, (1,0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "import os\n",
    "class SignalDataset(Dataset):\n",
    "\n",
    "    def __init__(self, signals, labels):\n",
    "        self.signals = signals\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.signals)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        sample =(torch.cat([torch.Tensor(np.array([self.signals[channel,idx]]).transpose()) for channel in range(12)], axis=1), \n",
    "                  torch.Tensor(self.labels[idx]))\n",
    "\n",
    "        return sample\n",
    "    \n",
    "signal_datasets_test = SignalDataset(Signal_12leads_test, np.array(Data_labels_test)[:,:N_CLASS])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.array(Data_labels_test).shape[1] == N_CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.evaluate_12ECG_score import compute_modified_confusion_matrix, compute_challenge_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_score(labels, outputs, weights, normal_index=normal_idx):\n",
    "    num_recordings, num_classes = np.shape(labels)\n",
    "    # Compute the observed score.\n",
    "    A = compute_modified_confusion_matrix(labels, outputs)\n",
    "    observed_score = np.nansum(weights * A)\n",
    "\n",
    "    # Compute the score for the model that always chooses the correct label(s).\n",
    "    correct_outputs = labels\n",
    "    A = compute_modified_confusion_matrix(labels, correct_outputs)\n",
    "    correct_score = np.nansum(weights * A)\n",
    "\n",
    "    # Compute the score for the model that always chooses the normal class.\n",
    "    inactive_outputs = np.zeros((num_recordings, num_classes), dtype=np.bool)\n",
    "    inactive_outputs[:, normal_index] = 1\n",
    "    A = compute_modified_confusion_matrix(labels, inactive_outputs)\n",
    "    inactive_score = np.nansum(weights * A)\n",
    "\n",
    "    if correct_score != inactive_score:\n",
    "        normalized_score = float(observed_score - inactive_score) / float(correct_score - inactive_score)\n",
    "    else:\n",
    "        normalized_score = float('nan')\n",
    "\n",
    "    return normalized_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, models, transforms\n",
    "from myeval import agg_y_preds_bags, binary_acc, geometry_loss\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from snippets.pytorchtools import EarlyStopping\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import time\n",
    "\n",
    "st = time.time()\n",
    "patience = 50\n",
    "batch_size= 512#65000\n",
    "\n",
    "saved_dir = '../saved/resnet50/'\n",
    "\n",
    "\n",
    "testDataset = torch.utils.data.Subset(signal_datasets_test, range(0,len(Signals_test), 1))\n",
    "\n",
    "testLoader = torch.utils.data.DataLoader(testDataset, batch_size=65000, shuffle = False, pin_memory=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94421, 12, 750)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(Signals_test).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [get_name(label, Dx_map, Dx_map_unscored) for label in labels]\n",
    "\n",
    "assert len(labels) == 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9e31ba55b0649ec96f7e39e194e95eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "y_tests_tensor = None\n",
    "\n",
    "output_tests = []\n",
    "y_tests = []\n",
    "with torch.no_grad():\n",
    "\n",
    "    for X_test, y_test in tqdm(testLoader):  \n",
    "        output_test = model(X_test)\n",
    "        output_tests.append(output_test)\n",
    "        y_tests.append(y_test)\n",
    "\n",
    "    y_tests_tensor = torch.cat(y_tests, axis=0) # ground truth\n",
    "\n",
    "    output_tests = torch.cat(output_tests, axis=0)\n",
    "    y_test_preds = torch.sigmoid(output_tests)\n",
    "\n",
    "#     output_trains = torch.cat(output_trains, axis=0)\n",
    "#     y_train_preds_max, y_train_preds_mean, _ = agg_y_preds_bags(y_train_preds, bag_size=n_segments)\n",
    "#     y_test_preds_max, y_test_preds_mean, _ = agg_y_preds_bags(y_test_preds, bag_size=n_segments)\n",
    "#     _, _, y_trains = agg_y_preds_bags(y_trains, bag_size=n_segments)\n",
    "#     _, _, y_tests = agg_y_preds_bags(y_tests, bag_size=n_segments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End 1.87 min |\n",
      " Valid: Acc: 0.979, F: 0.264, Fbeta: 0.289, gbeta: 0.152, geo: 0.210, score: 0.533\n",
      " \n"
     ]
    }
   ],
   "source": [
    "from global_vars import weights\n",
    "acc2, fmeasure2, fbeta2, gbeta2 = binary_acc(y_test_preds, y_tests_tensor)\n",
    "geometry2 = geometry_loss(fbeta2, gbeta2)\n",
    "\n",
    "score2 = compute_score(np.round(y_test_preds.data.numpy()), np.round(y_tests_tensor.data.numpy()), weights)\n",
    "output_str = 'End {:.2f} min |\\n Valid: Acc: {:.3f}, F: {:.3f}, Fbeta: {:.3f}, gbeta: {:.3f}, geo: {:.3f}, score: {:.3f}\\n '.format(\n",
    "    (time.time()-st)/60, acc2, fmeasure2, fbeta2, gbeta2, geometry2, score2)\n",
    "\n",
    "print(output_str)\n",
    "\n",
    "#     output_string = 'AUROC|AUPRC|Accuracy|F-measure|Fbeta-measure|Gbeta-measure|Geomotry\\n{:.3f}|{:.3f}|{:.3f}|{:.3f}|{:.3f}|{:.3f}|{:.3f}'.format(auroc2,auprc2,acc2,fmeasure2,fbeta2,gbeta2,geometry2)\n",
    "#     print(output_string)     \n",
    "#     with open(saved_dir+'score'+ str(i)+ '_epoch' + str(epoch) + '.txt', 'w') as f:\n",
    "#         f.write(output_string)\n",
    "\n",
    "#     avg_losses_train = np.array(avg_losses_train)\n",
    "#     avg_losses_test = np.array(avg_losses_test)\n",
    "\n",
    "#     np.save(saved_dir + 'avg_losses_train' + str(i) + '_epoch' + str(epoch), avg_losses_train)\n",
    "#     np.save(saved_dir + 'avg_losses_test' + str(i) + '_epoch' + str(epoch), avg_losses_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, confusion_matrix\n",
    "from global_vars import labels\n",
    "\n",
    "cf_matrices = multilabel_confusion_matrix(y_tests_tensor.data.numpy(), np.round(y_test_preds.data.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st degree av block\n",
      "[[86789  1221]\n",
      " [ 2103  4308]]\n",
      "\n",
      "\n",
      "atrial fibrillation\n",
      "[[77102  2966]\n",
      " [ 3969 10384]]\n",
      "\n",
      "\n",
      "atrial flutter\n",
      "[[93978    34]\n",
      " [  336    73]]\n",
      "\n",
      "\n",
      "bradycardia\n",
      "[[92861   548]\n",
      " [  665   347]]\n",
      "\n",
      "\n",
      "complete right bundle branch block\n",
      "[[93151   301]\n",
      " [  725   244]]\n",
      "\n",
      "\n",
      "incomplete right bundle branch block\n",
      "[[92592   473]\n",
      " [ 1151   205]]\n",
      "\n",
      "\n",
      "left anterior fascicular block\n",
      "[[92720   354]\n",
      " [  984   363]]\n",
      "\n",
      "\n",
      "left axis deviation\n",
      "[[89543  1218]\n",
      " [ 2564  1096]]\n",
      "\n",
      "\n",
      "left bundle branch block\n",
      "[[91556   374]\n",
      " [  752  1739]]\n",
      "\n",
      "\n",
      "low qrs voltages\n",
      "[[94209     3]\n",
      " [  209     0]]\n",
      "\n",
      "\n",
      "nonspecific intraventricular conduction disorder\n",
      "[[93758    16]\n",
      " [  646     1]]\n",
      "\n",
      "\n",
      "pacing rhythm\n",
      "[[94215    61]\n",
      " [  126    19]]\n",
      "\n",
      "\n",
      "premature atrial contraction\n",
      "[[86387  1564]\n",
      " [ 2991  3479]]\n",
      "\n",
      "\n",
      "premature ventricular contractions\n",
      "[[93251   202]\n",
      " [  897    71]]\n",
      "\n",
      "\n",
      "prolonged pr interval\n",
      "[[93971    42]\n",
      " [  406     2]]\n",
      "\n",
      "\n",
      "prolonged qt interval\n",
      "[[94216     0]\n",
      " [  205     0]]\n",
      "\n",
      "\n",
      "qwave abnormal\n",
      "[[93856    52]\n",
      " [  506     7]]\n",
      "\n",
      "\n",
      "right axis deviation\n",
      "[[94104    15]\n",
      " [  301     1]]\n",
      "\n",
      "\n",
      "right bundle branch block\n",
      "[[76998  2469]\n",
      " [ 2400 12554]]\n",
      "\n",
      "\n",
      "sinus arrhythmia\n",
      "[[93722     0]\n",
      " [  699     0]]\n",
      "\n",
      "\n",
      "sinus bradycardia\n",
      "[[93861    40]\n",
      " [  484    36]]\n",
      "\n",
      "\n",
      "sinus rhythm\n",
      "[[67239  4622]\n",
      " [ 7821 14739]]\n",
      "\n",
      "\n",
      "sinus tachycardia\n",
      "[[90637   726]\n",
      " [ 1590  1468]]\n",
      "\n",
      "\n",
      "supraventricular premature beats\n",
      "[[93979    99]\n",
      " [  337     6]]\n",
      "\n",
      "\n",
      "t wave abnormal\n",
      "[[91353   487]\n",
      " [ 2349   232]]\n",
      "\n",
      "\n",
      "t wave inversion\n",
      "[[94064    48]\n",
      " [  304     5]]\n",
      "\n",
      "\n",
      "ventricular premature beats\n",
      "[[94355     9]\n",
      " [   43    14]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for label, cf_matrix in zip(labels, cf_matrices):\n",
    "    print(get_name(label, Dx_map, Dx_map_unscored))\n",
    "    print(cf_matrix)\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from signal_processing import find_AD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a951894993434e1c8614c2f267d8f136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ads = []\n",
    "for signal, label in tqdm(signal_datasets_test):\n",
    "    #print(signal.numpy().shape)\n",
    "    ad = find_AD(signal.numpy().transpose())\n",
    "    ads.append(ad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_labels = np.round(y_test_preds.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94421, 27)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from global_vars import lad_class, rad_class\n",
    "lad_idx = np.argwhere(labels == int(lad_class)).flatten()\n",
    "rad_idx = np.argwhere(labels == int(rad_class)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([270492004, 164889003, 164890007, 426627000, 713427006, 713426002,\n",
       "       445118002,  39732003, 164909002, 251146004, 698252002,  10370003,\n",
       "       284470004, 427172004, 164947007, 111975006, 164917005,  47665007,\n",
       "        59118001, 427393009, 426177001, 426783006, 427084000,  63593006,\n",
       "       164934002,  59931005,  17338001])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, ad in enumerate(ads):\n",
    "    if ad == 'LAD':\n",
    "        test_pred_labels[i, lad_idx] = 1\n",
    "        test_pred_labels[i, rad_idx] = 0\n",
    "    elif ad == 'RAD':\n",
    "        test_pred_labels[i, rad_idx] = 1\n",
    "        test_pred_labels[i, lad_idx] = 0\n",
    "    else:\n",
    "        test_pred_labels[i, rad_idx] = 0\n",
    "        test_pred_labels[i, lad_idx] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrices = multilabel_confusion_matrix(y_tests_tensor.data.numpy(), test_pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st degree av block\n",
      "[[86789  1221]\n",
      " [ 2103  4308]]\n",
      "\n",
      "\n",
      "atrial fibrillation\n",
      "[[77102  2966]\n",
      " [ 3969 10384]]\n",
      "\n",
      "\n",
      "atrial flutter\n",
      "[[93978    34]\n",
      " [  336    73]]\n",
      "\n",
      "\n",
      "bradycardia\n",
      "[[92861   548]\n",
      " [  665   347]]\n",
      "\n",
      "\n",
      "complete right bundle branch block\n",
      "[[93151   301]\n",
      " [  725   244]]\n",
      "\n",
      "\n",
      "incomplete right bundle branch block\n",
      "[[92592   473]\n",
      " [ 1151   205]]\n",
      "\n",
      "\n",
      "left anterior fascicular block\n",
      "[[92720   354]\n",
      " [  984   363]]\n",
      "\n",
      "\n",
      "left axis deviation\n",
      "[[69766 20995]\n",
      " [ 1217  2443]]\n",
      "\n",
      "\n",
      "left bundle branch block\n",
      "[[91556   374]\n",
      " [  752  1739]]\n",
      "\n",
      "\n",
      "low qrs voltages\n",
      "[[94209     3]\n",
      " [  209     0]]\n",
      "\n",
      "\n",
      "nonspecific intraventricular conduction disorder\n",
      "[[93758    16]\n",
      " [  646     1]]\n",
      "\n",
      "\n",
      "pacing rhythm\n",
      "[[94215    61]\n",
      " [  126    19]]\n",
      "\n",
      "\n",
      "premature atrial contraction\n",
      "[[86387  1564]\n",
      " [ 2991  3479]]\n",
      "\n",
      "\n",
      "premature ventricular contractions\n",
      "[[93251   202]\n",
      " [  897    71]]\n",
      "\n",
      "\n",
      "prolonged pr interval\n",
      "[[93971    42]\n",
      " [  406     2]]\n",
      "\n",
      "\n",
      "prolonged qt interval\n",
      "[[94216     0]\n",
      " [  205     0]]\n",
      "\n",
      "\n",
      "qwave abnormal\n",
      "[[93856    52]\n",
      " [  506     7]]\n",
      "\n",
      "\n",
      "right axis deviation\n",
      "[[82524 11595]\n",
      " [  114   188]]\n",
      "\n",
      "\n",
      "right bundle branch block\n",
      "[[76998  2469]\n",
      " [ 2400 12554]]\n",
      "\n",
      "\n",
      "sinus arrhythmia\n",
      "[[93722     0]\n",
      " [  699     0]]\n",
      "\n",
      "\n",
      "sinus bradycardia\n",
      "[[93861    40]\n",
      " [  484    36]]\n",
      "\n",
      "\n",
      "sinus rhythm\n",
      "[[67239  4622]\n",
      " [ 7821 14739]]\n",
      "\n",
      "\n",
      "sinus tachycardia\n",
      "[[90637   726]\n",
      " [ 1590  1468]]\n",
      "\n",
      "\n",
      "supraventricular premature beats\n",
      "[[93979    99]\n",
      " [  337     6]]\n",
      "\n",
      "\n",
      "t wave abnormal\n",
      "[[91353   487]\n",
      " [ 2349   232]]\n",
      "\n",
      "\n",
      "t wave inversion\n",
      "[[94064    48]\n",
      " [  304     5]]\n",
      "\n",
      "\n",
      "ventricular premature beats\n",
      "[[94355     9]\n",
      " [   43    14]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for label, cf_matrix in zip(labels, cf_matrices):\n",
    "    print(get_name(label, Dx_map, Dx_map_unscored))\n",
    "    print(cf_matrix)\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "score2 = compute_score(np.round(y_test_preds.data.numpy()), test_pred_labels, weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.785374733086021"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "def aggr_bag_res(test_pred_labels, Idxes_test):\n",
    "    assert len(test_pred_labels) == len(Idxes_test)\n",
    "    uniq = np.unique(Idxes_test, return_counts=True)[1]\n",
    "    cumsum = np.cumsum(uniq)[:-1]\n",
    "    res = np.split(test_pred_labels, cumsum)\n",
    "    print(\"Done\")\n",
    "    return res, cumsum, uniq\n",
    "#     aggr_labels = []\n",
    "#     cur_label = np.zeros((N_CLASS,))\n",
    "#     for idx in Idxes_test:\n",
    "#         cur_label += test_pred_labels[idx,:]\n",
    "#         aggr_labels = (cur_label > 0).astype(int)\n",
    "    \n",
    "\n",
    "agg_res, cumsum, uniq= aggr_bag_res(Idxes_test, Idxes_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 47,\n",
       " 47,\n",
       " 47,\n",
       " 47,\n",
       " 47,\n",
       " 47,\n",
       " 47,\n",
       " 55,\n",
       " 55,\n",
       " 55,\n",
       " 55,\n",
       " 55,\n",
       " 55,\n",
       " 55,\n",
       " 55,\n",
       " 55,\n",
       " 55,\n",
       " 56,\n",
       " 56,\n",
       " 56,\n",
       " 56,\n",
       " 56,\n",
       " 56,\n",
       " 56,\n",
       " 56,\n",
       " 56,\n",
       " 56,\n",
       " 56,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 67,\n",
       " 67,\n",
       " 67,\n",
       " 67,\n",
       " 67,\n",
       " 67,\n",
       " 67,\n",
       " 67,\n",
       " 67,\n",
       " 67,\n",
       " 69,\n",
       " 69,\n",
       " 69,\n",
       " 69,\n",
       " 69,\n",
       " 69,\n",
       " 69,\n",
       " 69,\n",
       " 69,\n",
       " 69,\n",
       " 69,\n",
       " 69,\n",
       " 69,\n",
       " 72,\n",
       " 72,\n",
       " 72,\n",
       " 72,\n",
       " 72,\n",
       " 72,\n",
       " 72,\n",
       " 72,\n",
       " 72,\n",
       " 72,\n",
       " 83,\n",
       " 83,\n",
       " 83,\n",
       " 83,\n",
       " 83,\n",
       " 83,\n",
       " 83,\n",
       " 83,\n",
       " 83,\n",
       " 83,\n",
       " 84,\n",
       " 84,\n",
       " 84,\n",
       " 84,\n",
       " 84,\n",
       " 84,\n",
       " 84,\n",
       " 84,\n",
       " 84,\n",
       " 89,\n",
       " 89,\n",
       " 89,\n",
       " 89,\n",
       " 89,\n",
       " 89,\n",
       " 89,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 97,\n",
       " 97,\n",
       " 97,\n",
       " 97,\n",
       " 97,\n",
       " 97,\n",
       " 97,\n",
       " 97,\n",
       " 97,\n",
       " 97,\n",
       " 97,\n",
       " 97,\n",
       " 97,\n",
       " 104,\n",
       " 104,\n",
       " 104,\n",
       " 104,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 110,\n",
       " 111,\n",
       " 111,\n",
       " 111,\n",
       " 111,\n",
       " 111,\n",
       " 111,\n",
       " 111,\n",
       " 111,\n",
       " 111,\n",
       " 111,\n",
       " 126,\n",
       " 126,\n",
       " 126,\n",
       " 126,\n",
       " 126,\n",
       " 126,\n",
       " 126,\n",
       " 126,\n",
       " 126,\n",
       " 126,\n",
       " 128,\n",
       " 128,\n",
       " 128,\n",
       " 128,\n",
       " 128,\n",
       " 128,\n",
       " 128,\n",
       " 128,\n",
       " 128,\n",
       " 128,\n",
       " 128,\n",
       " 128,\n",
       " 128,\n",
       " 128,\n",
       " 131,\n",
       " 131,\n",
       " 131,\n",
       " 131,\n",
       " 131,\n",
       " 131,\n",
       " 135,\n",
       " 135,\n",
       " 135,\n",
       " 135,\n",
       " 135,\n",
       " 135,\n",
       " 135,\n",
       " 135,\n",
       " 135,\n",
       " 135,\n",
       " 135,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 140,\n",
       " 144,\n",
       " 144,\n",
       " 144,\n",
       " 144,\n",
       " 144,\n",
       " 144,\n",
       " 144,\n",
       " 144,\n",
       " 144,\n",
       " 144,\n",
       " 144,\n",
       " 144,\n",
       " 150,\n",
       " 150,\n",
       " 150,\n",
       " 150,\n",
       " 150,\n",
       " 150,\n",
       " 150,\n",
       " 150,\n",
       " 150,\n",
       " 150,\n",
       " 150,\n",
       " 150,\n",
       " 150,\n",
       " 150,\n",
       " 153,\n",
       " 153,\n",
       " 153,\n",
       " 153,\n",
       " 153,\n",
       " 153,\n",
       " 153,\n",
       " 153,\n",
       " 153,\n",
       " 153,\n",
       " 153,\n",
       " 153,\n",
       " 158,\n",
       " 158,\n",
       " 158,\n",
       " 158,\n",
       " 158,\n",
       " 158,\n",
       " 158,\n",
       " 158,\n",
       " 158,\n",
       " 158,\n",
       " 158,\n",
       " 158,\n",
       " 158,\n",
       " 158,\n",
       " 158,\n",
       " 158,\n",
       " 165,\n",
       " 165,\n",
       " 165,\n",
       " 165,\n",
       " 165,\n",
       " 165,\n",
       " 165,\n",
       " 165,\n",
       " 165,\n",
       " 165,\n",
       " 165,\n",
       " 165,\n",
       " 165,\n",
       " 165,\n",
       " 165,\n",
       " 165,\n",
       " 167,\n",
       " 167,\n",
       " 167,\n",
       " 167,\n",
       " 167,\n",
       " 167,\n",
       " 167,\n",
       " 167,\n",
       " 167,\n",
       " 167,\n",
       " 167,\n",
       " 173,\n",
       " 173,\n",
       " 173,\n",
       " 173,\n",
       " 173,\n",
       " 173,\n",
       " 173,\n",
       " 173,\n",
       " 173,\n",
       " 180,\n",
       " 180,\n",
       " 180,\n",
       " 180,\n",
       " 180,\n",
       " 180,\n",
       " 180,\n",
       " 180,\n",
       " 180,\n",
       " 180,\n",
       " 188,\n",
       " 188,\n",
       " 188,\n",
       " 188,\n",
       " 188,\n",
       " 188,\n",
       " 197,\n",
       " 197,\n",
       " 197,\n",
       " 197,\n",
       " 197,\n",
       " 197,\n",
       " 197,\n",
       " 197,\n",
       " 206,\n",
       " 206,\n",
       " 206,\n",
       " 206,\n",
       " 206,\n",
       " 206,\n",
       " 206,\n",
       " 206,\n",
       " 206,\n",
       " 207,\n",
       " 207,\n",
       " 207,\n",
       " 207,\n",
       " 207,\n",
       " 207,\n",
       " 207,\n",
       " 207,\n",
       " 207,\n",
       " 207,\n",
       " 207,\n",
       " 207,\n",
       " 207,\n",
       " 207,\n",
       " 207,\n",
       " 207,\n",
       " 210,\n",
       " 210,\n",
       " 210,\n",
       " 210,\n",
       " 210,\n",
       " 210,\n",
       " 210,\n",
       " 210,\n",
       " 210,\n",
       " 210,\n",
       " 210,\n",
       " 210,\n",
       " 211,\n",
       " 211,\n",
       " 211,\n",
       " 211,\n",
       " 211,\n",
       " 211,\n",
       " 211,\n",
       " 211,\n",
       " 211,\n",
       " 211,\n",
       " 211,\n",
       " 211,\n",
       " 211,\n",
       " 211,\n",
       " 211,\n",
       " 211,\n",
       " 211,\n",
       " 211,\n",
       " 216,\n",
       " 216,\n",
       " 216,\n",
       " 216,\n",
       " 216,\n",
       " 216,\n",
       " 216,\n",
       " 216,\n",
       " 216,\n",
       " 216,\n",
       " 216,\n",
       " 216,\n",
       " 216,\n",
       " 216,\n",
       " 216,\n",
       " 216,\n",
       " 216,\n",
       " 216,\n",
       " 216,\n",
       " 217,\n",
       " 217,\n",
       " 217,\n",
       " 217,\n",
       " 217,\n",
       " 217,\n",
       " 217,\n",
       " 217,\n",
       " 217,\n",
       " 225,\n",
       " 225,\n",
       " 225,\n",
       " 225,\n",
       " 225,\n",
       " 225,\n",
       " 225,\n",
       " 225,\n",
       " 225,\n",
       " 232,\n",
       " 232,\n",
       " 232,\n",
       " 232,\n",
       " 232,\n",
       " 232,\n",
       " 232,\n",
       " 232,\n",
       " 232,\n",
       " 232,\n",
       " 232,\n",
       " 232,\n",
       " 232,\n",
       " 233,\n",
       " 233,\n",
       " 233,\n",
       " 233,\n",
       " 233,\n",
       " 233,\n",
       " 233,\n",
       " 233,\n",
       " 233,\n",
       " 233,\n",
       " 233,\n",
       " 233,\n",
       " 233,\n",
       " 233,\n",
       " 233,\n",
       " 233,\n",
       " 233,\n",
       " 239,\n",
       " 239,\n",
       " 239,\n",
       " 239,\n",
       " 239,\n",
       " 239,\n",
       " 239,\n",
       " 239,\n",
       " 243,\n",
       " 243,\n",
       " 243,\n",
       " 243,\n",
       " 243,\n",
       " 243,\n",
       " 243,\n",
       " 246,\n",
       " 246,\n",
       " 246,\n",
       " 246,\n",
       " 246,\n",
       " 246,\n",
       " 246,\n",
       " 246,\n",
       " 246,\n",
       " 246,\n",
       " 246,\n",
       " 249,\n",
       " 249,\n",
       " 249,\n",
       " 249,\n",
       " 249,\n",
       " 249,\n",
       " 249,\n",
       " 249,\n",
       " 249,\n",
       " 261,\n",
       " 261,\n",
       " 261,\n",
       " 261,\n",
       " 261,\n",
       " 261,\n",
       " 261,\n",
       " 261,\n",
       " 261,\n",
       " 264,\n",
       " 264,\n",
       " 264,\n",
       " 264,\n",
       " 264,\n",
       " 264,\n",
       " 264,\n",
       " 264,\n",
       " 265,\n",
       " 265,\n",
       " 265,\n",
       " 265,\n",
       " 265,\n",
       " 265,\n",
       " 265,\n",
       " 265,\n",
       " 265,\n",
       " 265,\n",
       " 265,\n",
       " 271,\n",
       " 271,\n",
       " 271,\n",
       " 271,\n",
       " 271,\n",
       " 271,\n",
       " 271,\n",
       " 271,\n",
       " 271,\n",
       " 271,\n",
       " 271,\n",
       " 282,\n",
       " 282,\n",
       " 282,\n",
       " 282,\n",
       " 282,\n",
       " 282,\n",
       " 282,\n",
       " 282,\n",
       " 282,\n",
       " 282,\n",
       " 290,\n",
       " 290,\n",
       " 290,\n",
       " 290,\n",
       " 290,\n",
       " 290,\n",
       " 290,\n",
       " 290,\n",
       " 290,\n",
       " 290,\n",
       " 290,\n",
       " 290,\n",
       " 290,\n",
       " 290,\n",
       " 291,\n",
       " 291,\n",
       " 291,\n",
       " 291,\n",
       " 291,\n",
       " 291,\n",
       " 293,\n",
       " 293,\n",
       " 293,\n",
       " 293,\n",
       " 293,\n",
       " 293,\n",
       " 293,\n",
       " 293,\n",
       " 293,\n",
       " 296,\n",
       " 296,\n",
       " 296,\n",
       " 296,\n",
       " 296,\n",
       " 296,\n",
       " 296,\n",
       " 296,\n",
       " 296,\n",
       " 296,\n",
       " 296,\n",
       " 298,\n",
       " 298,\n",
       " 298,\n",
       " 298,\n",
       " 298,\n",
       " 298,\n",
       " 298,\n",
       " 298,\n",
       " 298,\n",
       " 305,\n",
       " 305,\n",
       " 305,\n",
       " 305,\n",
       " 305,\n",
       " 305,\n",
       " 305,\n",
       " 305,\n",
       " 305,\n",
       " 305,\n",
       " 305,\n",
       " 305,\n",
       " 305,\n",
       " 305,\n",
       " 305,\n",
       " 308,\n",
       " 308,\n",
       " 308,\n",
       " 308,\n",
       " 308,\n",
       " 308,\n",
       " 308,\n",
       " 308,\n",
       " 308,\n",
       " 308,\n",
       " 308,\n",
       " 308,\n",
       " 308,\n",
       " 308,\n",
       " 308,\n",
       " 308,\n",
       " 309,\n",
       " 309,\n",
       " 309,\n",
       " 309,\n",
       " 309,\n",
       " 309,\n",
       " 309,\n",
       " 309,\n",
       " 309,\n",
       " 309,\n",
       " 309,\n",
       " 309,\n",
       " 309,\n",
       " 309,\n",
       " 309,\n",
       " 309,\n",
       " 309,\n",
       " 309,\n",
       " 318,\n",
       " 318,\n",
       " 318,\n",
       " 318,\n",
       " 318,\n",
       " 318,\n",
       " 318,\n",
       " 318,\n",
       " 318,\n",
       " 318,\n",
       " 318,\n",
       " 318,\n",
       " 318,\n",
       " 318,\n",
       " 318,\n",
       " 323,\n",
       " 323,\n",
       " 323,\n",
       " 323,\n",
       " 323,\n",
       " 323,\n",
       " 323,\n",
       " 323,\n",
       " 323,\n",
       " 323,\n",
       " 323,\n",
       " 323,\n",
       " 329,\n",
       " 329,\n",
       " 329,\n",
       " 329,\n",
       " 329,\n",
       " 329,\n",
       " 329,\n",
       " 338,\n",
       " 338,\n",
       " 338,\n",
       " 338,\n",
       " 338,\n",
       " 338,\n",
       " 338,\n",
       " 338,\n",
       " 338,\n",
       " 338,\n",
       " 341,\n",
       " 341,\n",
       " 341,\n",
       " 341,\n",
       " 341,\n",
       " 341,\n",
       " 341,\n",
       " 341,\n",
       " 341,\n",
       " 342,\n",
       " 342,\n",
       " 342,\n",
       " 342,\n",
       " 342,\n",
       " 342,\n",
       " 342,\n",
       " 342,\n",
       " 342,\n",
       " 342,\n",
       " 342,\n",
       " 342,\n",
       " 342,\n",
       " 342,\n",
       " 342,\n",
       " 347,\n",
       " 347,\n",
       " 347,\n",
       " 347,\n",
       " 347,\n",
       " 347,\n",
       " 347,\n",
       " 347,\n",
       " 347,\n",
       " 347,\n",
       " 353,\n",
       " 353,\n",
       " 353,\n",
       " 353,\n",
       " 353,\n",
       " 353,\n",
       " 353,\n",
       " 353,\n",
       " 353,\n",
       " 353,\n",
       " 353,\n",
       " 353,\n",
       " 353,\n",
       " 357,\n",
       " 357,\n",
       " 357,\n",
       " 357,\n",
       " 357,\n",
       " 357,\n",
       " 357,\n",
       " 357,\n",
       " 357,\n",
       " 357,\n",
       " 357,\n",
       " 358,\n",
       " 358,\n",
       " 358,\n",
       " 358,\n",
       " 358,\n",
       " 358,\n",
       " 358,\n",
       " 358,\n",
       " 358,\n",
       " 358,\n",
       " 358,\n",
       " 358,\n",
       " 358,\n",
       " 358,\n",
       " 358,\n",
       " 358,\n",
       " 358,\n",
       " 358,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 368,\n",
       " 375,\n",
       " 375,\n",
       " 375,\n",
       " 375,\n",
       " 375,\n",
       " 375,\n",
       " 375,\n",
       " 375,\n",
       " 375,\n",
       " 375,\n",
       " 375,\n",
       " 375,\n",
       " 378,\n",
       " 378,\n",
       " 378,\n",
       " 378,\n",
       " 378,\n",
       " 378,\n",
       " 378,\n",
       " 378,\n",
       " 378,\n",
       " 378,\n",
       " 378,\n",
       " 378,\n",
       " 378,\n",
       " 385,\n",
       " 385,\n",
       " 385,\n",
       " 385,\n",
       " 385,\n",
       " 385,\n",
       " 385,\n",
       " 385,\n",
       " 385,\n",
       " 385,\n",
       " 385,\n",
       " 385,\n",
       " 385,\n",
       " 385,\n",
       " 386,\n",
       " 386,\n",
       " 386,\n",
       " 386,\n",
       " 386,\n",
       " 386,\n",
       " 386,\n",
       " 386,\n",
       " 386,\n",
       " 386,\n",
       " 386,\n",
       " 386,\n",
       " 386,\n",
       " 386,\n",
       " 386,\n",
       " 396,\n",
       " 396,\n",
       " 396,\n",
       " 396,\n",
       " 396,\n",
       " 396,\n",
       " 396,\n",
       " 396,\n",
       " 396,\n",
       " 396,\n",
       " 396,\n",
       " 396,\n",
       " 396,\n",
       " 396,\n",
       " 396,\n",
       " 399,\n",
       " 399,\n",
       " 399,\n",
       " 399,\n",
       " 399,\n",
       " 399,\n",
       " 399,\n",
       " 399,\n",
       " 399,\n",
       " 404,\n",
       " 404,\n",
       " 404,\n",
       " 404,\n",
       " 404,\n",
       " 404,\n",
       " 404,\n",
       " 404,\n",
       " 404,\n",
       " 404,\n",
       " 404,\n",
       " 410,\n",
       " 410,\n",
       " 410,\n",
       " 410,\n",
       " 410,\n",
       " 410,\n",
       " 410,\n",
       " 410,\n",
       " 410,\n",
       " 410,\n",
       " 410,\n",
       " 410,\n",
       " 413,\n",
       " 413,\n",
       " 413,\n",
       " 413,\n",
       " 413,\n",
       " 413,\n",
       " 413,\n",
       " 413,\n",
       " 413,\n",
       " 413,\n",
       " 413,\n",
       " 413,\n",
       " 413,\n",
       " 413,\n",
       " 413,\n",
       " 413,\n",
       " 413,\n",
       " 413,\n",
       " 416,\n",
       " 416,\n",
       " 416,\n",
       " 416,\n",
       " 416,\n",
       " 416,\n",
       " 416,\n",
       " 416,\n",
       " 416,\n",
       " 416,\n",
       " 416,\n",
       " 416,\n",
       " ...]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Idxes_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Idxes_test[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([    4,    11,    13, ..., 43078, 43079, 43086]),\n",
       " array([24, 13, 12, ..., 11,  9,  6]))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Idxes_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 in Idxes_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(Idxes_test, return_counts=True)\n",
    "cumsum = np.cumsum(uniq)[:-1]\n",
    "res = np.split(Idxes_test, cumsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94267"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (physioNet)",
   "language": "python",
   "name": "physionet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
