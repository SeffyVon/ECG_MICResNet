{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset  5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1243e8d6865341bab48bf1aa2ce1e852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, os, sys\n",
    "from tqdm.notebook import tqdm    \n",
    "from manipulations import get_classes, get_classes_from_header, get_Fs_from_header, load_challenge_data\n",
    "from sklearn.model_selection import KFold\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    Datas = []\n",
    "    Header_datas = []\n",
    "    Classes = []\n",
    "    dataset_idx = {}\n",
    "    dataset_train_idx = {}\n",
    "    dataset_test_idx = {}\n",
    "    global_idx = 0\n",
    "    for dataset in [5]:\n",
    "        print('Dataset ', dataset)\n",
    "        # Parse arguments.\n",
    "        if len(sys.argv) != 3:\n",
    "            raise Exception('Include the input and output directories as arguments, e.g., python driver.py input output.')\n",
    "\n",
    "        input_directory = '../Data/Training{}/'.format(dataset)\n",
    "        output_directory = '../Output/'\n",
    "\n",
    "        # Find files.\n",
    "        input_files = []\n",
    "        for f in os.listdir(input_directory):\n",
    "            if os.path.isfile(os.path.join(input_directory, f)) and not f.lower().startswith('.') and f.lower().endswith('mat'):\n",
    "                input_files.append(f)\n",
    "\n",
    "        if not os.path.isdir(output_directory):\n",
    "            os.mkdir(output_directory)\n",
    "\n",
    "        classes=get_classes(input_directory,input_files)\n",
    "\n",
    "        num_files = len(input_files)\n",
    "        datas = []\n",
    "        header_datas = []\n",
    "        dataset_idx[dataset] = []\n",
    "        for i, f in tqdm(enumerate(input_files)):\n",
    "            #print('    {}/{}...'.format(i+1, num_files), f)\n",
    "            tmp_input_file = os.path.join(input_directory,f)\n",
    "            data,header_data = load_challenge_data(tmp_input_file)\n",
    "            datas.append(data[:,1000:7000])\n",
    "            header_datas.append(header_data)\n",
    "            dataset_idx[dataset].append(global_idx)\n",
    "            global_idx += 1\n",
    "\n",
    "        Datas += datas\n",
    "        Header_datas += header_datas\n",
    "        Classes += classes\n",
    "        \n",
    "        \n",
    "        kf = KFold(5)\n",
    "        train_idx, test_idx = next(kf.split(dataset_idx[dataset]))\n",
    "        dataset_train_idx[dataset] = train_idx\n",
    "        dataset_test_idx[dataset] = test_idx\n",
    "        print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_idx = []\n",
    "for dataset in [5]:\n",
    "    all_train_idx.extend(dataset_train_idx[dataset])\n",
    "    \n",
    "all_test_idx = []\n",
    "for dataset in [5]:\n",
    "    all_test_idx.extend(dataset_test_idx[dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from manipulations import get_abbr, get_name\n",
    "from global_vars import labels, Dx_map, Dx_map_unscored\n",
    "first_idx = {scored_code: None for scored_code in list(Dx_map['SNOMED CT Code'])}\n",
    "first_idx_unscored = {unscored_code: None for unscored_code in list(Dx_map_unscored['SNOMED CT Code'])}\n",
    "\n",
    "# for i, Header_data in tqdm(enumerate(Header_datas)):\n",
    "#     codes = get_classes_from_header(Header_data)\n",
    "#     abbrs = ' '.join([get_abbr(int(code), Dx_map, Dx_map_unscored) for code in codes])\n",
    "#     for code, abbr in zip(codes, abbrs):\n",
    "#         if code in first_idx and first_idx[code] is None:\n",
    "#             first_idx[code] = i\n",
    "#         if code in first_idx_unscored and first_idx_unscored[code] is None:\n",
    "#             first_idx_unscored[code] = i\n",
    "#     encore = False\n",
    "#     for code in first_idx.keys():\n",
    "#         if first_idx[code] is None:\n",
    "#             encore = True\n",
    "#             break\n",
    "# #     for code in first_idx_unscored.keys():\n",
    "# #         if first_idx_unscored[code] is None:\n",
    "# #             encore = True\n",
    "# #             break\n",
    "#     if not encore:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from signal_processing import myfilter, main_QRST\n",
    "# Codes = []\n",
    "# Q_locs = []\n",
    "# idxes = []\n",
    "# for idx in tqdm(range(0, len(Datas))): \n",
    "#     if np.sum(Datas[idx]) != 0: # not all zeros\n",
    "#         codes = get_classes_from_header(Header_datas[idx])\n",
    "#         names = ', '.join([get_name(int(code), Dx_map, Dx_map_unscored) for code in codes])\n",
    "\n",
    "#         filtered_Data = myfilter(Datas[idx], 500, vis=False)\n",
    "\n",
    "#         # get the lead to apply Pan Tomkins\n",
    "#         Q_loc = main_QRST(filtered_Data, idx, '', '', names, fig2=False)\n",
    "\n",
    "#         # store\n",
    "#         Codes.append(codes)\n",
    "#         Q_locs.append(Q_loc)\n",
    "#     else:\n",
    "#         Codes.append([])\n",
    "#         Q_locs.append([])\n",
    "#     idxes.append(idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('../saved/idxes_1000_7000.pkl', 'wb') as idxes_file:\n",
    "#     pickle.dump(idxes, idxes_file)\n",
    "\n",
    "# with open('../saved/Codes_1000_7000.pkl', 'wb') as Codes_file:\n",
    "#     pickle.dump(Codes, Codes_file)\n",
    "\n",
    "# with open('../saved/Q_locs_1000_7000.pkl', 'wb') as Q_locs_file:\n",
    "#     pickle.dump(Q_locs, Q_locs_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "016aba9f1b7e4051ad6d8547dd08526c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21837.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "Q_locs = None\n",
    "with open('../saved/Q_locs_1000_7000.pkl', 'rb') as Q_locs_file:\n",
    "    Q_locs = pickle.load(Q_locs_file)\n",
    "\n",
    "Codes = None\n",
    "with open('../saved/Codes_1000_7000.pkl', 'rb') as Codes_file:\n",
    "    Codes = pickle.load(Codes_file)\n",
    "\n",
    "idxes = None\n",
    "with open('../saved/idxes_1000_7000.pkl', 'rb') as idxes_file:\n",
    "    idxes = pickle.load(idxes_file)\n",
    "    \n",
    "Codes = []\n",
    "for idx in tqdm(range(0, len(Datas))): \n",
    "    if np.sum(Datas[idx]) != 0: # not all zeros\n",
    "        codes = get_classes_from_header(Header_datas[idx])\n",
    "        # store\n",
    "        Codes.append(codes)\n",
    "    else:\n",
    "        Codes.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from global_vars import labels\n",
    "def get_scored_class(code, labels):\n",
    "    return [1 if label in code else 0 for label in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_labels = np.array([get_scored_class(codes, labels) for codes in Codes])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_RR = 600 # 60 beats/min => 60 beats/60 s ==> beat/1s ==> 500 samples / beat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd5b90bcd51840c2baee428f9ff70735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17469.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yfeng/anaconda3/envs/physioNet/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/yfeng/anaconda3/envs/physioNet/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "Data_labels_train = []\n",
    "Idxes_train = []\n",
    "Idxes_dict_train = {}\n",
    "ct = 0\n",
    "for i in tqdm(dataset_train_idx[5]):\n",
    "    Q_loc = Q_locs[i]\n",
    "    RR_avg = np.median([Q_loc[k+1] - Q_loc[k] for k in range(len(Q_loc)-1)])\n",
    "    RR_th = (0.3 * RR_avg, 3 * RR_avg)\n",
    "    \n",
    "    ks = [k for k in range(len(Q_loc)-1) if Q_loc[k+1] - Q_loc[k] > RR_th[0] \n",
    "              and Q_loc[k+1] - Q_loc[k] < RR_th[1]]\n",
    "    \n",
    "    \n",
    "    Idxes_dict_train[i] = []\n",
    "    for k in ks:\n",
    "        Data_labels_train.append(get_scored_class(Codes[i], labels))\n",
    "        X_train.append(Datas[i][:,1000+Q_loc[k]:1000+Q_loc[k+1]])\n",
    "        Idxes_train.append(i)\n",
    "        Idxes_dict_train[i].append(ct)\n",
    "        \n",
    "    ct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a27711d8e57d4c28b6005e6eab626279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4368.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_test = []\n",
    "Data_labels_test = []\n",
    "Idxes_test = []\n",
    "Idxes_dict_test = {}\n",
    "ct = 0\n",
    "for i in tqdm(dataset_test_idx[5]):\n",
    "    Q_loc = Q_locs[i]\n",
    "    RR_avg = np.median([Q_loc[k+1] - Q_loc[k] for k in range(len(Q_loc)-1)])\n",
    "    RR_th = (0.3 * RR_avg, 3 * RR_avg)\n",
    "    \n",
    "    ks = [k for k in range(len(Q_loc)-1) if Q_loc[k+1] - Q_loc[k] > RR_th[0] \n",
    "              and Q_loc[k+1] - Q_loc[k] < RR_th[1]]\n",
    "    \n",
    "    \n",
    "    Idxes_dict_test[i] = []\n",
    "    for k in ks:\n",
    "        Data_labels_test.append(get_scored_class(Codes[i], labels))\n",
    "        X_test.append(Datas[i][:,1000+Q_loc[k]:1000+Q_loc[k+1]])\n",
    "        Idxes_test.append(i)\n",
    "        Idxes_dict_test[i].append(ct)\n",
    "        \n",
    "    ct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Signals_train = np.zeros((len(X_train),12,MAX_RR))\n",
    "for i in range(len(X_train)):\n",
    "    Signals_train[i,:,:min(len(X_train[i][0]),MAX_RR)] = X_train[i][:,:MAX_RR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Signals_test = np.zeros((len(X_test),12,MAX_RR))\n",
    "for i in range(len(X_test)):\n",
    "    Signals_test[i,:,:min(len(X_test[i][0]),MAX_RR)] = X_test[i][:,:MAX_RR]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On y va"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('runs/resnet1d_dataset5_cuda0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnet1d import resnet18, ECGResNet\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def weighted_binary_cross_entropy2(sigmoid_x, y, weighted_matrix, weight=None, reduction=None):\n",
    "    \"\"\"\n",
    "    Aha this is correct!\n",
    "    sigmoid_x = nn.Sigmoid()(x)\n",
    "    Args:\n",
    "        sigmoid_x: predicted probability of size [N,C], N sample and C Class. Eg. Must be in range of [0,1]\n",
    "        targets: true value, one-hot-like vector of size [N,C]\n",
    "        pos_weight: Weight for postive sample\n",
    "    \"\"\"\n",
    "    if not (y.size() == sigmoid_x.size()):\n",
    "        raise ValueError(\"Target size ({}) must be the same as input size ({})\".format(y.size(), sigmoid_x.size()))\n",
    "   \n",
    "    #print(\"y.size(), sigmoid_x.size()\", y.size(), sigmoid_x.size())\n",
    "    sigmoid_x = torch.clamp(sigmoid_x,min=1e-7,max=1-1e-7) \n",
    "    loss = - torch.matmul(y*sigmoid_x.log() + (1-y)*(1-sigmoid_x).log(), weighted_matrix)\n",
    "    \n",
    "    if weight is not None:\n",
    "        loss = loss * weight\n",
    "        \n",
    "    if reduction is None:\n",
    "        return loss\n",
    "    elif reduction == 'mean':\n",
    "        return loss.mean()\n",
    "    elif reduction == 'sum':\n",
    "        return loss.sum()\n",
    "    return None\n",
    "    \n",
    "class WeightedBCELoss(nn.Module):\n",
    "    def __init__(self, weights, PosWeightIsDynamic= False, WeightIsDynamic= False, \n",
    "                 reduction='mean'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            pos_weight = Weight for postive samples. Size [1,C]\n",
    "            weight = Weight for Each class. Size [1,C]\n",
    "            PosWeightIsDynamic: If True, the pos_weight is computed on each batch. If pos_weight is None, then it remains None.\n",
    "            WeightIsDynamic: If True, the weight is computed on each batch. If weight is None, then it remains None.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.register_buffer('weights', weights)\n",
    "        self.reduction = reduction\n",
    "        self.PosWeightIsDynamic = PosWeightIsDynamic\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        if self.PosWeightIsDynamic:\n",
    "            positive_counts = target.sum(dim=0)\n",
    "            nBatch = len(target)\n",
    "            self.pos_weight = (nBatch - positive_counts)/(positive_counts +1e-5)\n",
    "\n",
    "\n",
    "        return weighted_binary_cross_entropy2(input, target,\n",
    "                                             weighted_matrix=self.weights,\n",
    "                                             reduction=self.reduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Signal_12leads_train = np.transpose(Signals_train, (1,0,2))\n",
    "Signal_12leads_test= np.transpose(Signals_test, (1,0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from global_vars import labels\n",
    "import os\n",
    "class SignalDataset(Dataset):\n",
    "\n",
    "    def __init__(self, signals, labels):\n",
    "        self.signals = signals\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.signals)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        sample =(torch.cat([torch.Tensor(np.array([self.signals[channel,idx]]).transpose()) for channel in range(12)], axis=1), \n",
    "                  torch.Tensor(self.labels[idx]))\n",
    "\n",
    "        return sample\n",
    "    \n",
    "signal_datasets_train = SignalDataset(Signal_12leads_train, Data_labels_train)\n",
    "signal_datasets_test = SignalDataset(Signal_12leads_test, Data_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 169804, 600)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Signal_12leads_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([600, 12])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_datasets_train[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from global_vars import weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_tensor = torch.Tensor(weights).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.evaluate_12ECG_score import compute_modified_confusion_matrix, compute_challenge_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_idx = np.argwhere(labels.to_numpy()==426783006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_score(labels, outputs, weights, normal_index=normal_idx):\n",
    "    num_recordings, num_classes = np.shape(labels)\n",
    "    # Compute the observed score.\n",
    "    A = compute_modified_confusion_matrix(labels, outputs)\n",
    "    observed_score = np.nansum(weights * A)\n",
    "\n",
    "    # Compute the score for the model that always chooses the correct label(s).\n",
    "    correct_outputs = labels\n",
    "    A = compute_modified_confusion_matrix(labels, correct_outputs)\n",
    "    correct_score = np.nansum(weights * A)\n",
    "\n",
    "    # Compute the score for the model that always chooses the normal class.\n",
    "    inactive_outputs = np.zeros((num_recordings, num_classes), dtype=np.bool)\n",
    "    inactive_outputs[:, normal_index] = 1\n",
    "    A = compute_modified_confusion_matrix(labels, inactive_outputs)\n",
    "    inactive_score = np.nansum(weights * A)\n",
    "\n",
    "    if correct_score != inactive_score:\n",
    "        normalized_score = float(observed_score - inactive_score) / float(correct_score - inactive_score)\n",
    "    else:\n",
    "        normalized_score = float('nan')\n",
    "\n",
    "    return normalized_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_weight = np.ones(27) * 2\n",
    "pos_weight = torch.Tensor(pos_weight).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, models, transforms\n",
    "from myeval import agg_y_preds_bags, binary_acc, geometry_loss\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from snippets.pytorchtools import EarlyStopping\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import time\n",
    "\n",
    "st = time.time()\n",
    "patience = 50\n",
    "batch_size=65000\n",
    "\n",
    "saved_dir = '../saved/ResNet1d/'\n",
    "\n",
    "\n",
    "\n",
    "model = ECGResNet(MAX_RR, len(labels))\n",
    "model.to(device)\n",
    "\n",
    "trainDataset = torch.utils.data.Subset(signal_datasets_train, range(0,len(Signals_train)))\n",
    "testDataset = torch.utils.data.Subset(signal_datasets_test, range(0,len(Signals_test)))\n",
    "\n",
    "trainLoader = torch.utils.data.DataLoader(trainDataset, batch_size=batch_size, shuffle = True, pin_memory=True)#sampler = sampler)\n",
    "trainLoader2 = torch.utils.data.DataLoader(trainDataset, batch_size=batch_size, shuffle = False, pin_memory=True)#sampler = sampler)\n",
    "testLoader = torch.utils.data.DataLoader(testDataset, batch_size = batch_size, shuffle = False, pin_memory=True)\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9) #\n",
    "# Decay LR by a factor of 0.1 every 100 epochs\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=1000, gamma=0.1)\n",
    "\n",
    "#     criterion_train = WeightedBCELoss(weights=weights_tensor, reduction='mean')\n",
    "#     criterion_test = WeightedBCELoss(weights=weights_tensor, reduction='mean')\n",
    "\n",
    "criterion_train = nn.BCEWithLogitsLoss(pos_weight=pos_weight, reduction='mean')\n",
    "criterion_test = nn.BCEWithLogitsLoss(pos_weight=pos_weight, reduction='mean')\n",
    "\n",
    "losses_train = []\n",
    "losses_test = []\n",
    "\n",
    "avg_losses_train = []\n",
    "avg_losses_test = []\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(patience, verbose=False, \n",
    "                              saved_dir=saved_dir, \n",
    "                               save_name='Resnet1'+str(i))\n",
    "epoch = 0\n",
    "auroc = 0\n",
    "auprc = 0\n",
    "accuracy = 0\n",
    "fmeasure = 0\n",
    "fbeta = 0\n",
    "gbeta = 0\n",
    "for epoch in range(50000):\n",
    "\n",
    "    model.train()\n",
    "    output_trains = []\n",
    "\n",
    "    for X_train, y_train in trainLoader:\n",
    "        y_train = y_train.to(device)\n",
    "        X_train = X_train.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output_train = model(X_train)\n",
    "        loss_train = criterion_train(output_train, y_train)\n",
    "        #print(loss_train)\n",
    "        losses_train.append(loss_train.item())\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    avg_loss_train = np.average(losses_train)\n",
    "    avg_losses_train.append(avg_loss_train)\n",
    "\n",
    "    output_tests = []\n",
    "    y_tests = []\n",
    "    y_trains = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        running_loss_train = 0.0\n",
    "        for k, (X_train, y_train) in enumerate(trainLoader2):  \n",
    "            X_train = X_train.to(device)\n",
    "            output_train = model(X_train)\n",
    "            output_trains.append(output_train.cpu())\n",
    "            y_trains.append(y_train.cpu())\n",
    "\n",
    "            avg_loss_train = np.average(losses_train)\n",
    "            avg_losses_train.append(avg_loss_train)\n",
    "\n",
    "            running_loss_train += loss_train.item() \n",
    "            writer.add_scalar('training loss',\n",
    "                running_loss_train/(epoch * (len(train_idx)//batch_size+1) + k+1),\n",
    "                epoch * (len(train_idx)//batch_size+1) + k)\n",
    "\n",
    "\n",
    "        running_loss_test = 0.0\n",
    "        for X_test, y_test in testLoader:  \n",
    "            y_test = y_test.to(device)\n",
    "            X_test = X_test.to(device)\n",
    "            output_test = model(X_test)\n",
    "\n",
    "\n",
    "            loss_test = criterion_test(output_test, y_test)\n",
    "            losses_test.append(loss_test.item())\n",
    "\n",
    "            running_loss_test += loss_test.item()\n",
    "\n",
    "            output_tests.append(output_test.cpu())\n",
    "            y_tests.append(y_test.cpu())\n",
    "\n",
    "        avg_loss_test = np.average(losses_test)\n",
    "        avg_losses_test.append(avg_loss_test)\n",
    "\n",
    "\n",
    "        writer.add_scalar('testing loss',\n",
    "                running_loss_test/(epoch* (len(train_idx)//(batch_size+1))+1),\n",
    "                epoch* (len(train_idx)//batch_size+1))\n",
    "\n",
    "\n",
    "\n",
    "    y_trains = torch.cat(y_trains, axis=0)\n",
    "    y_tests = torch.cat(y_tests, axis=0)\n",
    "\n",
    "    output_trains = torch.cat(output_trains, axis=0)\n",
    "    y_train_preds = torch.sigmoid(output_trains)\n",
    "\n",
    "    output_tests = torch.cat(output_tests, axis=0)\n",
    "    y_test_preds = torch.sigmoid(output_tests)\n",
    "\n",
    "    #output_trains = torch.cat(output_trains, axis=0)\n",
    "#         y_train_preds_max, y_train_preds_mean, _ = agg_y_preds_bags(y_train_preds, bag_size=n_segments)\n",
    "#         y_test_preds_max, y_test_preds_mean, _ = agg_y_preds_bags(y_test_preds, bag_size=n_segments)\n",
    "#         _, _, y_trains = agg_y_preds_bags(y_trains, bag_size=n_segments)\n",
    "#         _, _, y_tests = agg_y_preds_bags(y_tests, bag_size=n_segments)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    acc, fmeasure, fbeta, gbeta = binary_acc(y_train_preds, y_trains)           \n",
    "    acc2, fmeasure2, fbeta2, gbeta2 = binary_acc(y_test_preds, y_tests)\n",
    "    geometry = geometry_loss(fbeta, gbeta)\n",
    "    geometry2 = geometry_loss(fbeta2, gbeta2)\n",
    "    score = compute_score(np.round(y_train_preds.data.numpy()), np.round(y_trains.data.numpy()), weights)\n",
    "    score2 = compute_score(np.round(y_test_preds.data.numpy()), np.round(y_tests.data.numpy()), weights)\n",
    "    output_str = 'S{}/{} {:.2f} min |\\n Train Loss: {:.6f}, Acc: {:.3f}, F: {:.3f}, Fbeta: {:.3f}, gbeta: {:.3f}, geo: {:.3f}, score: {:.3f} |\\n Valid Loss: {:.6f}, Acc: {:.3f}, F: {:.3f}, Fbeta: {:.3f}, gbeta: {:.3f}, geo: {:.3f}, score: {:.3f}\\n '.format(\n",
    "        i, epoch, (time.time()-st)/60,\n",
    "        avg_loss_train, acc, fmeasure, fbeta, gbeta, geometry, score, \n",
    "        avg_loss_test, acc2, fmeasure2, fbeta2, gbeta2, geometry2, score2)\n",
    "    print(output_str)\n",
    "\n",
    "#             output_str = 'S{}/{} {:.2f} min Train Loss: {:.6f} Valid Loss: {:.6f}'.format(i, epoch, (time.time()-st)/60, avg_loss_train, avg_loss_test)\n",
    "#             print(output_str)\n",
    "#             with open(saved_dir+'loss11_{}.txt'.format(i), 'a') as f:\n",
    "#                 print(output_str, file=f)\n",
    "\n",
    "#             early_stopping(avg_loss_test, model)\n",
    "\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "#     output_string = 'AUROC|AUPRC|Accuracy|F-measure|Fbeta-measure|Gbeta-measure|Geomotry\\n{:.3f}|{:.3f}|{:.3f}|{:.3f}|{:.3f}|{:.3f}|{:.3f}'.format(auroc2,auprc2,acc2,fmeasure2,fbeta2,gbeta2,geometry2)\n",
    "#     print(output_string)     \n",
    "#     with open(saved_dir+'score'+ str(i)+ '_epoch' + str(epoch) + '.txt', 'w') as f:\n",
    "#         f.write(output_string)\n",
    "\n",
    "#     avg_losses_train = np.array(avg_losses_train)\n",
    "#     avg_losses_test = np.array(avg_losses_test)\n",
    "\n",
    "#     np.save(saved_dir + 'avg_losses_train' + str(i) + '_epoch' + str(epoch), avg_losses_train)\n",
    "#     np.save(saved_dir + 'avg_losses_test' + str(i) + '_epoch' + str(epoch), avg_losses_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (physioNet)",
   "language": "python",
   "name": "physionet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
