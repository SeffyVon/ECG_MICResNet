{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_infos = pd.read_csv('../saved/infos.csv')\n",
    "fDataReNorms = np.load('../saved/fDataReNorms.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import normalize\n",
    "# #fDataReNorms=[fDataRe-np.tile(fDataRe[:,0],(250,1)).transpose() for fDataRe in fDataRes]\n",
    "# fDataReNorms=np.array([normalize(fDataRe) for fDataRe in fDataRes])\n",
    "# np.save('../saved/fDataReNorms.npy', fDataReNorms)\n",
    "# [plt.plot(fDataReNorm[6]) for fDataReNorm in fDataReNorms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fDataReNormAFs = fDataReNorms[df_infos['AF']]\n",
    "\n",
    "# for fDataReNormAF in fDataReNormAFs[:10]:\n",
    "#     plt.plot(fDataReNormAF[0])\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 100528})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from xgb.global_vars import headers, labels\n",
    "print(Counter(np.sum(df_infos[labels], axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.FloatTensor(df_infos[labels].to_numpy()).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.FloatTensor(fDataReNorms).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2487, -0.0068,  0.1357,  ...,  0.2155,  0.1215,  0.3133],\n",
       "        [ 0.2495, -0.0049,  0.1391,  ...,  0.2178,  0.1217,  0.3125],\n",
       "        [ 0.2515, -0.0049,  0.1423,  ...,  0.2213,  0.1201,  0.3112],\n",
       "        ...,\n",
       "        [ 0.2515, -0.0111,  0.1362,  ...,  0.2203,  0.1170,  0.3167],\n",
       "        [ 0.2490, -0.0043,  0.1393,  ...,  0.2201,  0.1224,  0.3141],\n",
       "        [ 0.2426, -0.0004,  0.1352,  ...,  0.2249,  0.1298,  0.3138]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, n_input, n_h1, n_h2, n_h3, verbose=False):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1        = nn.Linear(n_input, n_h1)\n",
    "        self.fc2        = nn.Linear(n_h1, n_h2)\n",
    "        self.fc3        = nn.Linear(120, n_h3)\n",
    "        self.fc4        = nn.Linear(n_h3, 9)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.verbose=verbose\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.verbose:\n",
    "            print('0: ', x.shape)\n",
    "        x = self.fc1( x )     \n",
    "        x = self.dropout(x)\n",
    "        if self.verbose:\n",
    "            print('1: ', x.shape)\n",
    "        x = F.relu(   x )     \n",
    "        x = self.fc2( x )    \n",
    "        if self.verbose:\n",
    "            print('2: ', x.shape)\n",
    "        x = F.relu(   x )      \n",
    "        if self.verbose:\n",
    "            print('3: ', x.shape)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc3( x )  \n",
    "        if self.verbose:\n",
    "            print('4: ', x.shape)\n",
    "        x = F.relu(   x )   \n",
    "        x = self.fc4(x)\n",
    "        if self.verbose:\n",
    "            print('5: ', x.shape)\n",
    "        return x\n",
    "\n",
    "model = SimpleNet(250, 250, 10, 10)\n",
    "model.forward(X.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S0/0 0.01 min|\n",
      "Train Loss: 0.746458, Acc: 0.31, F: 0.31, Fbeta: 0.17, gbeta: 0.10, auroc: 0.52, auprc: 0.12 |\n",
      "Valid Loss: 0.745841, Acc: 0.31, F: 0.31, Fbeta: 0.17, gbeta: 0.10, auroc: 0.53, auprc: 0.12\n",
      " \n",
      "S0/200 0.79 min|\n",
      "Train Loss: 0.253087, Acc: 0.93, F: 0.35, Fbeta: 0.37, gbeta: 0.22, auroc: 0.88, auprc: 0.52 |\n",
      "Valid Loss: 0.254342, Acc: 0.92, F: 0.34, Fbeta: 0.35, gbeta: 0.21, auroc: 0.87, auprc: 0.48\n",
      " \n",
      "S0/400 1.56 min|\n",
      "Train Loss: 0.219793, Acc: 0.93, F: 0.40, Fbeta: 0.42, gbeta: 0.27, auroc: 0.90, auprc: 0.57 |\n",
      "Valid Loss: 0.228372, Acc: 0.92, F: 0.38, Fbeta: 0.39, gbeta: 0.24, auroc: 0.88, auprc: 0.52\n",
      " \n",
      "S0/600 2.34 min|\n",
      "Train Loss: 0.204346, Acc: 0.94, F: 0.42, Fbeta: 0.43, gbeta: 0.29, auroc: 0.91, auprc: 0.60 |\n",
      "Valid Loss: 0.218410, Acc: 0.92, F: 0.38, Fbeta: 0.39, gbeta: 0.24, auroc: 0.88, auprc: 0.52\n",
      " \n",
      "S0/800 3.11 min|\n",
      "Train Loss: 0.194382, Acc: 0.94, F: 0.46, Fbeta: 0.49, gbeta: 0.31, auroc: 0.92, auprc: 0.64 |\n",
      "Valid Loss: 0.212785, Acc: 0.93, F: 0.41, Fbeta: 0.43, gbeta: 0.26, auroc: 0.89, auprc: 0.55\n",
      " \n",
      "S0/1000 3.88 min|\n",
      "Train Loss: 0.186875, Acc: 0.94, F: 0.47, Fbeta: 0.50, gbeta: 0.33, auroc: 0.92, auprc: 0.67 |\n",
      "Valid Loss: 0.209103, Acc: 0.93, F: 0.42, Fbeta: 0.44, gbeta: 0.27, auroc: 0.89, auprc: 0.56\n",
      " \n",
      "S0/1200 4.65 min|\n",
      "Train Loss: 0.181138, Acc: 0.94, F: 0.49, Fbeta: 0.53, gbeta: 0.34, auroc: 0.93, auprc: 0.68 |\n",
      "Valid Loss: 0.206617, Acc: 0.93, F: 0.42, Fbeta: 0.45, gbeta: 0.27, auroc: 0.89, auprc: 0.55\n",
      " \n",
      "S0/1400 5.43 min|\n",
      "Train Loss: 0.176469, Acc: 0.95, F: 0.52, Fbeta: 0.56, gbeta: 0.36, auroc: 0.93, auprc: 0.69 |\n",
      "Valid Loss: 0.204764, Acc: 0.93, F: 0.44, Fbeta: 0.47, gbeta: 0.28, auroc: 0.89, auprc: 0.56\n",
      " \n",
      "S0/1600 6.20 min|\n",
      "Train Loss: 0.172583, Acc: 0.95, F: 0.53, Fbeta: 0.57, gbeta: 0.36, auroc: 0.93, auprc: 0.70 |\n",
      "Valid Loss: 0.203410, Acc: 0.93, F: 0.45, Fbeta: 0.47, gbeta: 0.28, auroc: 0.89, auprc: 0.56\n",
      " \n",
      "S0/1800 6.97 min|\n",
      "Train Loss: 0.169311, Acc: 0.95, F: 0.55, Fbeta: 0.59, gbeta: 0.38, auroc: 0.93, auprc: 0.71 |\n",
      "Valid Loss: 0.202401, Acc: 0.93, F: 0.45, Fbeta: 0.48, gbeta: 0.29, auroc: 0.89, auprc: 0.57\n",
      " \n",
      "S0/2000 7.74 min|\n",
      "Train Loss: 0.166466, Acc: 0.95, F: 0.57, Fbeta: 0.62, gbeta: 0.39, auroc: 0.94, auprc: 0.72 |\n",
      "Valid Loss: 0.201735, Acc: 0.93, F: 0.46, Fbeta: 0.49, gbeta: 0.28, auroc: 0.89, auprc: 0.56\n",
      " \n",
      "S0/2200 8.51 min|\n",
      "Train Loss: 0.163935, Acc: 0.95, F: 0.59, Fbeta: 0.63, gbeta: 0.40, auroc: 0.94, auprc: 0.73 |\n",
      "Valid Loss: 0.201320, Acc: 0.93, F: 0.47, Fbeta: 0.50, gbeta: 0.29, auroc: 0.89, auprc: 0.56\n",
      " \n",
      "S0/2400 9.27 min|\n",
      "Train Loss: 0.161668, Acc: 0.95, F: 0.59, Fbeta: 0.63, gbeta: 0.40, auroc: 0.94, auprc: 0.73 |\n",
      "Valid Loss: 0.201094, Acc: 0.93, F: 0.47, Fbeta: 0.50, gbeta: 0.29, auroc: 0.88, auprc: 0.56\n",
      " \n",
      "S0/2600 10.04 min|\n",
      "Train Loss: 0.159631, Acc: 0.95, F: 0.59, Fbeta: 0.64, gbeta: 0.41, auroc: 0.94, auprc: 0.74 |\n",
      "Valid Loss: 0.201051, Acc: 0.93, F: 0.47, Fbeta: 0.50, gbeta: 0.29, auroc: 0.89, auprc: 0.56\n",
      " \n",
      "S0/2800 10.81 min|\n",
      "Train Loss: 0.157787, Acc: 0.95, F: 0.61, Fbeta: 0.65, gbeta: 0.42, auroc: 0.95, auprc: 0.75 |\n",
      "Valid Loss: 0.201085, Acc: 0.93, F: 0.47, Fbeta: 0.51, gbeta: 0.29, auroc: 0.89, auprc: 0.55\n",
      " \n",
      "Early stopping\n",
      "AUROC|AUPRC|Accuracy|F-measure|Fbeta-measure|Gbeta-measure\n",
      "0.945|0.747|0.000|0.605|0.651|0.416\n",
      "S1/0 11.05 min|\n",
      "Train Loss: 0.713401, Acc: 0.41, F: 0.29, Fbeta: 0.16, gbeta: 0.09, auroc: 0.51, auprc: 0.11 |\n",
      "Valid Loss: 0.712506, Acc: 0.41, F: 0.30, Fbeta: 0.17, gbeta: 0.10, auroc: 0.51, auprc: 0.11\n",
      " \n",
      "S1/200 11.83 min|\n",
      "Train Loss: 0.261314, Acc: 0.93, F: 0.40, Fbeta: 0.43, gbeta: 0.25, auroc: 0.88, auprc: 0.54 |\n",
      "Valid Loss: 0.269950, Acc: 0.92, F: 0.38, Fbeta: 0.41, gbeta: 0.23, auroc: 0.87, auprc: 0.52\n",
      " \n",
      "S1/400 12.61 min|\n",
      "Train Loss: 0.221570, Acc: 0.94, F: 0.47, Fbeta: 0.49, gbeta: 0.32, auroc: 0.90, auprc: 0.61 |\n",
      "Valid Loss: 0.236446, Acc: 0.93, F: 0.43, Fbeta: 0.45, gbeta: 0.27, auroc: 0.88, auprc: 0.55\n",
      " \n",
      "S1/600 13.39 min|\n",
      "Train Loss: 0.203714, Acc: 0.94, F: 0.50, Fbeta: 0.52, gbeta: 0.34, auroc: 0.91, auprc: 0.64 |\n",
      "Valid Loss: 0.224210, Acc: 0.93, F: 0.44, Fbeta: 0.46, gbeta: 0.28, auroc: 0.89, auprc: 0.56\n",
      " \n",
      "S1/800 14.16 min|\n",
      "Train Loss: 0.192761, Acc: 0.94, F: 0.52, Fbeta: 0.55, gbeta: 0.36, auroc: 0.92, auprc: 0.67 |\n",
      "Valid Loss: 0.218400, Acc: 0.93, F: 0.45, Fbeta: 0.47, gbeta: 0.29, auroc: 0.88, auprc: 0.56\n",
      " \n",
      "S1/1000 14.94 min|\n",
      "Train Loss: 0.185173, Acc: 0.95, F: 0.54, Fbeta: 0.57, gbeta: 0.38, auroc: 0.93, auprc: 0.68 |\n",
      "Valid Loss: 0.215221, Acc: 0.93, F: 0.46, Fbeta: 0.48, gbeta: 0.29, auroc: 0.89, auprc: 0.57\n",
      " \n",
      "S1/1200 15.71 min|\n",
      "Train Loss: 0.179516, Acc: 0.95, F: 0.55, Fbeta: 0.58, gbeta: 0.39, auroc: 0.93, auprc: 0.69 |\n",
      "Valid Loss: 0.213409, Acc: 0.93, F: 0.46, Fbeta: 0.48, gbeta: 0.29, auroc: 0.89, auprc: 0.58\n",
      " \n",
      "S1/1400 16.49 min|\n",
      "Train Loss: 0.175132, Acc: 0.95, F: 0.56, Fbeta: 0.59, gbeta: 0.39, auroc: 0.93, auprc: 0.70 |\n",
      "Valid Loss: 0.212283, Acc: 0.93, F: 0.47, Fbeta: 0.49, gbeta: 0.30, auroc: 0.89, auprc: 0.57\n",
      " \n",
      "S1/1600 17.26 min|\n",
      "Train Loss: 0.171626, Acc: 0.95, F: 0.57, Fbeta: 0.59, gbeta: 0.40, auroc: 0.93, auprc: 0.70 |\n",
      "Valid Loss: 0.211594, Acc: 0.93, F: 0.47, Fbeta: 0.50, gbeta: 0.30, auroc: 0.89, auprc: 0.58\n",
      " \n",
      "S1/1800 18.04 min|\n",
      "Train Loss: 0.168738, Acc: 0.95, F: 0.57, Fbeta: 0.60, gbeta: 0.40, auroc: 0.93, auprc: 0.71 |\n",
      "Valid Loss: 0.211211, Acc: 0.93, F: 0.47, Fbeta: 0.49, gbeta: 0.30, auroc: 0.88, auprc: 0.57\n",
      " \n",
      "S1/2000 18.81 min|\n",
      "Train Loss: 0.166301, Acc: 0.95, F: 0.57, Fbeta: 0.60, gbeta: 0.41, auroc: 0.94, auprc: 0.71 |\n",
      "Valid Loss: 0.211019, Acc: 0.93, F: 0.47, Fbeta: 0.49, gbeta: 0.30, auroc: 0.89, auprc: 0.58\n",
      " \n",
      "S1/2200 19.58 min|\n",
      "Train Loss: 0.164217, Acc: 0.95, F: 0.57, Fbeta: 0.60, gbeta: 0.41, auroc: 0.94, auprc: 0.71 |\n",
      "Valid Loss: 0.210983, Acc: 0.93, F: 0.47, Fbeta: 0.48, gbeta: 0.29, auroc: 0.89, auprc: 0.57\n",
      " \n",
      "S1/2400 20.35 min|\n",
      "Train Loss: 0.162411, Acc: 0.95, F: 0.57, Fbeta: 0.60, gbeta: 0.41, auroc: 0.94, auprc: 0.72 |\n",
      "Valid Loss: 0.211022, Acc: 0.93, F: 0.47, Fbeta: 0.49, gbeta: 0.29, auroc: 0.88, auprc: 0.58\n",
      " \n",
      "Early stopping\n",
      "AUROC|AUPRC|Accuracy|F-measure|Fbeta-measure|Gbeta-measure\n",
      "0.938|0.716|0.000|0.574|0.601|0.408\n",
      "S2/0 20.45 min|\n",
      "Train Loss: 0.726968, Acc: 0.44, F: 0.26, Fbeta: 0.15, gbeta: 0.08, auroc: 0.50, auprc: 0.11 |\n",
      "Valid Loss: 0.726331, Acc: 0.44, F: 0.27, Fbeta: 0.15, gbeta: 0.09, auroc: 0.52, auprc: 0.11\n",
      " \n",
      "S2/200 21.23 min|\n",
      "Train Loss: 0.280231, Acc: 0.92, F: 0.29, Fbeta: 0.32, gbeta: 0.18, auroc: 0.83, auprc: 0.44 |\n",
      "Valid Loss: 0.292530, Acc: 0.91, F: 0.30, Fbeta: 0.31, gbeta: 0.18, auroc: 0.81, auprc: 0.43\n",
      " \n",
      "S2/400 22.01 min|\n",
      "Train Loss: 0.245364, Acc: 0.93, F: 0.37, Fbeta: 0.39, gbeta: 0.24, auroc: 0.86, auprc: 0.50 |\n",
      "Valid Loss: 0.263200, Acc: 0.92, F: 0.35, Fbeta: 0.36, gbeta: 0.22, auroc: 0.83, auprc: 0.48\n",
      " \n",
      "S2/600 22.79 min|\n",
      "Train Loss: 0.229508, Acc: 0.93, F: 0.39, Fbeta: 0.41, gbeta: 0.26, auroc: 0.87, auprc: 0.52 |\n",
      "Valid Loss: 0.251432, Acc: 0.92, F: 0.36, Fbeta: 0.37, gbeta: 0.23, auroc: 0.83, auprc: 0.49\n",
      " \n",
      "S2/800 23.57 min|\n",
      "Train Loss: 0.219764, Acc: 0.93, F: 0.39, Fbeta: 0.41, gbeta: 0.27, auroc: 0.88, auprc: 0.54 |\n",
      "Valid Loss: 0.244909, Acc: 0.92, F: 0.36, Fbeta: 0.38, gbeta: 0.23, auroc: 0.84, auprc: 0.50\n",
      " \n",
      "S2/1000 24.35 min|\n",
      "Train Loss: 0.212809, Acc: 0.94, F: 0.41, Fbeta: 0.42, gbeta: 0.28, auroc: 0.88, auprc: 0.56 |\n",
      "Valid Loss: 0.240619, Acc: 0.92, F: 0.37, Fbeta: 0.39, gbeta: 0.24, auroc: 0.84, auprc: 0.51\n",
      " \n",
      "S2/1200 25.12 min|\n",
      "Train Loss: 0.207417, Acc: 0.94, F: 0.42, Fbeta: 0.44, gbeta: 0.29, auroc: 0.89, auprc: 0.57 |\n",
      "Valid Loss: 0.237652, Acc: 0.92, F: 0.38, Fbeta: 0.40, gbeta: 0.24, auroc: 0.84, auprc: 0.51\n",
      " \n",
      "S2/1400 25.90 min|\n",
      "Train Loss: 0.202903, Acc: 0.94, F: 0.48, Fbeta: 0.51, gbeta: 0.33, auroc: 0.91, auprc: 0.62 |\n",
      "Valid Loss: 0.235336, Acc: 0.93, F: 0.43, Fbeta: 0.45, gbeta: 0.27, auroc: 0.87, auprc: 0.55\n",
      " \n",
      "S2/1600 26.67 min|\n",
      "Train Loss: 0.197846, Acc: 0.94, F: 0.51, Fbeta: 0.54, gbeta: 0.35, auroc: 0.92, auprc: 0.65 |\n",
      "Valid Loss: 0.232548, Acc: 0.93, F: 0.44, Fbeta: 0.47, gbeta: 0.28, auroc: 0.87, auprc: 0.56\n",
      " \n",
      "S2/1800 27.45 min|\n",
      "Train Loss: 0.193371, Acc: 0.94, F: 0.52, Fbeta: 0.55, gbeta: 0.36, auroc: 0.92, auprc: 0.66 |\n",
      "Valid Loss: 0.230401, Acc: 0.93, F: 0.46, Fbeta: 0.48, gbeta: 0.29, auroc: 0.88, auprc: 0.56\n",
      " \n",
      "S2/2000 28.22 min|\n",
      "Train Loss: 0.188969, Acc: 0.95, F: 0.55, Fbeta: 0.57, gbeta: 0.39, auroc: 0.94, auprc: 0.70 |\n",
      "Valid Loss: 0.228291, Acc: 0.93, F: 0.47, Fbeta: 0.49, gbeta: 0.30, auroc: 0.89, auprc: 0.59\n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S2/2200 28.99 min|\n",
      "Train Loss: 0.184518, Acc: 0.95, F: 0.59, Fbeta: 0.63, gbeta: 0.41, auroc: 0.94, auprc: 0.74 |\n",
      "Valid Loss: 0.226217, Acc: 0.93, F: 0.50, Fbeta: 0.54, gbeta: 0.32, auroc: 0.89, auprc: 0.61\n",
      " \n",
      "S2/2400 29.76 min|\n",
      "Train Loss: 0.180434, Acc: 0.95, F: 0.61, Fbeta: 0.65, gbeta: 0.43, auroc: 0.95, auprc: 0.75 |\n",
      "Valid Loss: 0.224404, Acc: 0.93, F: 0.51, Fbeta: 0.54, gbeta: 0.33, auroc: 0.89, auprc: 0.61\n",
      " \n",
      "S2/2600 30.54 min|\n",
      "Train Loss: 0.176783, Acc: 0.95, F: 0.62, Fbeta: 0.66, gbeta: 0.43, auroc: 0.95, auprc: 0.76 |\n",
      "Valid Loss: 0.222855, Acc: 0.93, F: 0.52, Fbeta: 0.55, gbeta: 0.33, auroc: 0.89, auprc: 0.61\n",
      " \n",
      "S2/2800 31.31 min|\n",
      "Train Loss: 0.173511, Acc: 0.95, F: 0.63, Fbeta: 0.67, gbeta: 0.45, auroc: 0.95, auprc: 0.77 |\n",
      "Valid Loss: 0.221558, Acc: 0.93, F: 0.53, Fbeta: 0.56, gbeta: 0.34, auroc: 0.90, auprc: 0.61\n",
      " \n",
      "S2/3000 32.08 min|\n",
      "Train Loss: 0.170293, Acc: 0.95, F: 0.66, Fbeta: 0.71, gbeta: 0.47, auroc: 0.96, auprc: 0.79 |\n",
      "Valid Loss: 0.220235, Acc: 0.93, F: 0.55, Fbeta: 0.58, gbeta: 0.35, auroc: 0.90, auprc: 0.62\n",
      " \n",
      "S2/3200 32.85 min|\n",
      "Train Loss: 0.167260, Acc: 0.96, F: 0.68, Fbeta: 0.72, gbeta: 0.48, auroc: 0.96, auprc: 0.80 |\n",
      "Valid Loss: 0.219033, Acc: 0.93, F: 0.54, Fbeta: 0.58, gbeta: 0.35, auroc: 0.90, auprc: 0.62\n",
      " \n",
      "S2/3400 33.62 min|\n",
      "Train Loss: 0.164468, Acc: 0.96, F: 0.69, Fbeta: 0.73, gbeta: 0.49, auroc: 0.96, auprc: 0.80 |\n",
      "Valid Loss: 0.217993, Acc: 0.93, F: 0.55, Fbeta: 0.58, gbeta: 0.35, auroc: 0.90, auprc: 0.62\n",
      " \n",
      "S2/3600 34.39 min|\n",
      "Train Loss: 0.161904, Acc: 0.96, F: 0.69, Fbeta: 0.73, gbeta: 0.49, auroc: 0.96, auprc: 0.81 |\n",
      "Valid Loss: 0.217115, Acc: 0.93, F: 0.57, Fbeta: 0.60, gbeta: 0.36, auroc: 0.90, auprc: 0.62\n",
      " \n",
      "S2/3800 35.17 min|\n",
      "Train Loss: 0.159548, Acc: 0.96, F: 0.70, Fbeta: 0.74, gbeta: 0.49, auroc: 0.96, auprc: 0.81 |\n",
      "Valid Loss: 0.216391, Acc: 0.93, F: 0.56, Fbeta: 0.59, gbeta: 0.35, auroc: 0.90, auprc: 0.62\n",
      " \n",
      "S2/4000 35.94 min|\n",
      "Train Loss: 0.157381, Acc: 0.96, F: 0.70, Fbeta: 0.74, gbeta: 0.50, auroc: 0.96, auprc: 0.82 |\n",
      "Valid Loss: 0.215774, Acc: 0.93, F: 0.55, Fbeta: 0.58, gbeta: 0.35, auroc: 0.90, auprc: 0.62\n",
      " \n",
      "S2/4200 36.71 min|\n",
      "Train Loss: 0.155385, Acc: 0.96, F: 0.70, Fbeta: 0.74, gbeta: 0.50, auroc: 0.96, auprc: 0.82 |\n",
      "Valid Loss: 0.215261, Acc: 0.93, F: 0.55, Fbeta: 0.59, gbeta: 0.35, auroc: 0.90, auprc: 0.62\n",
      " \n",
      "S2/4400 37.48 min|\n",
      "Train Loss: 0.153534, Acc: 0.96, F: 0.71, Fbeta: 0.75, gbeta: 0.50, auroc: 0.96, auprc: 0.82 |\n",
      "Valid Loss: 0.214810, Acc: 0.93, F: 0.56, Fbeta: 0.59, gbeta: 0.36, auroc: 0.90, auprc: 0.62\n",
      " \n",
      "S2/4600 38.25 min|\n",
      "Train Loss: 0.151817, Acc: 0.96, F: 0.71, Fbeta: 0.75, gbeta: 0.50, auroc: 0.96, auprc: 0.82 |\n",
      "Valid Loss: 0.214434, Acc: 0.93, F: 0.55, Fbeta: 0.58, gbeta: 0.35, auroc: 0.90, auprc: 0.62\n",
      " \n",
      "S2/4800 39.02 min|\n",
      "Train Loss: 0.150216, Acc: 0.96, F: 0.71, Fbeta: 0.75, gbeta: 0.50, auroc: 0.96, auprc: 0.82 |\n",
      "Valid Loss: 0.214105, Acc: 0.93, F: 0.55, Fbeta: 0.59, gbeta: 0.35, auroc: 0.90, auprc: 0.62\n",
      " \n",
      "S2/5000 39.79 min|\n",
      "Train Loss: 0.148718, Acc: 0.96, F: 0.71, Fbeta: 0.75, gbeta: 0.51, auroc: 0.96, auprc: 0.83 |\n",
      "Valid Loss: 0.213838, Acc: 0.93, F: 0.55, Fbeta: 0.58, gbeta: 0.35, auroc: 0.90, auprc: 0.62\n",
      " \n",
      "S2/5200 40.56 min|\n",
      "Train Loss: 0.147317, Acc: 0.96, F: 0.71, Fbeta: 0.75, gbeta: 0.51, auroc: 0.96, auprc: 0.83 |\n",
      "Valid Loss: 0.213595, Acc: 0.93, F: 0.56, Fbeta: 0.59, gbeta: 0.36, auroc: 0.90, auprc: 0.63\n",
      " \n",
      "S2/5400 41.33 min|\n",
      "Train Loss: 0.146008, Acc: 0.96, F: 0.71, Fbeta: 0.75, gbeta: 0.51, auroc: 0.96, auprc: 0.83 |\n",
      "Valid Loss: 0.213403, Acc: 0.93, F: 0.56, Fbeta: 0.59, gbeta: 0.35, auroc: 0.90, auprc: 0.62\n",
      " \n",
      "S2/5600 42.10 min|\n",
      "Train Loss: 0.144764, Acc: 0.96, F: 0.72, Fbeta: 0.76, gbeta: 0.51, auroc: 0.96, auprc: 0.83 |\n",
      "Valid Loss: 0.213228, Acc: 0.93, F: 0.56, Fbeta: 0.59, gbeta: 0.35, auroc: 0.90, auprc: 0.63\n",
      " \n",
      "S2/5800 42.87 min|\n",
      "Train Loss: 0.143574, Acc: 0.96, F: 0.72, Fbeta: 0.76, gbeta: 0.52, auroc: 0.97, auprc: 0.83 |\n",
      "Valid Loss: 0.213042, Acc: 0.93, F: 0.57, Fbeta: 0.59, gbeta: 0.36, auroc: 0.90, auprc: 0.63\n",
      " \n",
      "S2/6000 43.64 min|\n",
      "Train Loss: 0.142444, Acc: 0.96, F: 0.72, Fbeta: 0.76, gbeta: 0.52, auroc: 0.97, auprc: 0.84 |\n",
      "Valid Loss: 0.212882, Acc: 0.93, F: 0.56, Fbeta: 0.59, gbeta: 0.35, auroc: 0.90, auprc: 0.63\n",
      " \n",
      "S2/6200 44.41 min|\n",
      "Train Loss: 0.141376, Acc: 0.96, F: 0.72, Fbeta: 0.77, gbeta: 0.52, auroc: 0.97, auprc: 0.84 |\n",
      "Valid Loss: 0.212754, Acc: 0.93, F: 0.56, Fbeta: 0.59, gbeta: 0.36, auroc: 0.90, auprc: 0.63\n",
      " \n",
      "S2/6400 45.18 min|\n",
      "Train Loss: 0.140357, Acc: 0.96, F: 0.73, Fbeta: 0.77, gbeta: 0.53, auroc: 0.97, auprc: 0.84 |\n",
      "Valid Loss: 0.212636, Acc: 0.93, F: 0.56, Fbeta: 0.59, gbeta: 0.36, auroc: 0.90, auprc: 0.62\n",
      " \n",
      "S2/6600 45.96 min|\n",
      "Train Loss: 0.139394, Acc: 0.96, F: 0.73, Fbeta: 0.77, gbeta: 0.53, auroc: 0.97, auprc: 0.84 |\n",
      "Valid Loss: 0.212543, Acc: 0.93, F: 0.57, Fbeta: 0.60, gbeta: 0.36, auroc: 0.90, auprc: 0.63\n",
      " \n",
      "S2/6800 46.73 min|\n",
      "Train Loss: 0.138448, Acc: 0.96, F: 0.74, Fbeta: 0.77, gbeta: 0.53, auroc: 0.97, auprc: 0.85 |\n",
      "Valid Loss: 0.212507, Acc: 0.93, F: 0.56, Fbeta: 0.59, gbeta: 0.35, auroc: 0.90, auprc: 0.63\n",
      " \n",
      "S2/7000 47.49 min|\n",
      "Train Loss: 0.137539, Acc: 0.96, F: 0.74, Fbeta: 0.77, gbeta: 0.53, auroc: 0.97, auprc: 0.85 |\n",
      "Valid Loss: 0.212497, Acc: 0.93, F: 0.56, Fbeta: 0.59, gbeta: 0.35, auroc: 0.89, auprc: 0.62\n",
      " \n",
      "Early stopping\n",
      "AUROC|AUPRC|Accuracy|F-measure|Fbeta-measure|Gbeta-measure\n",
      "0.968|0.847|0.000|0.736|0.775|0.532\n",
      "S3/0 48.10 min|\n",
      "Train Loss: 0.692265, Acc: 0.54, F: 0.15, Fbeta: 0.08, gbeta: 0.05, auroc: 0.52, auprc: 0.12 |\n",
      "Valid Loss: 0.691500, Acc: 0.54, F: 0.16, Fbeta: 0.09, gbeta: 0.05, auroc: 0.53, auprc: 0.13\n",
      " \n",
      "S3/200 48.88 min|\n",
      "Train Loss: 0.245115, Acc: 0.93, F: 0.45, Fbeta: 0.47, gbeta: 0.29, auroc: 0.89, auprc: 0.60 |\n",
      "Valid Loss: 0.247447, Acc: 0.93, F: 0.44, Fbeta: 0.46, gbeta: 0.28, auroc: 0.89, auprc: 0.57\n",
      " \n",
      "S3/400 49.66 min|\n",
      "Train Loss: 0.207790, Acc: 0.94, F: 0.52, Fbeta: 0.55, gbeta: 0.35, auroc: 0.92, auprc: 0.67 |\n",
      "Valid Loss: 0.215421, Acc: 0.93, F: 0.48, Fbeta: 0.51, gbeta: 0.31, auroc: 0.90, auprc: 0.62\n",
      " \n",
      "S3/600 50.44 min|\n",
      "Train Loss: 0.190783, Acc: 0.94, F: 0.56, Fbeta: 0.59, gbeta: 0.38, auroc: 0.93, auprc: 0.70 |\n",
      "Valid Loss: 0.203461, Acc: 0.93, F: 0.50, Fbeta: 0.53, gbeta: 0.32, auroc: 0.90, auprc: 0.63\n",
      " \n",
      "S3/800 51.22 min|\n",
      "Train Loss: 0.180433, Acc: 0.95, F: 0.57, Fbeta: 0.61, gbeta: 0.39, auroc: 0.94, auprc: 0.72 |\n",
      "Valid Loss: 0.197674, Acc: 0.94, F: 0.52, Fbeta: 0.55, gbeta: 0.33, auroc: 0.90, auprc: 0.63\n",
      " \n",
      "S3/1000 51.99 min|\n",
      "Train Loss: 0.173193, Acc: 0.95, F: 0.59, Fbeta: 0.63, gbeta: 0.41, auroc: 0.94, auprc: 0.73 |\n",
      "Valid Loss: 0.194453, Acc: 0.94, F: 0.52, Fbeta: 0.56, gbeta: 0.33, auroc: 0.90, auprc: 0.63\n",
      " \n",
      "S3/1200 52.77 min|\n",
      "Train Loss: 0.167658, Acc: 0.95, F: 0.62, Fbeta: 0.66, gbeta: 0.43, auroc: 0.95, auprc: 0.75 |\n",
      "Valid Loss: 0.192490, Acc: 0.94, F: 0.53, Fbeta: 0.57, gbeta: 0.33, auroc: 0.90, auprc: 0.64\n",
      " \n",
      "S3/1400 53.54 min|\n",
      "Train Loss: 0.163060, Acc: 0.95, F: 0.63, Fbeta: 0.68, gbeta: 0.43, auroc: 0.95, auprc: 0.76 |\n",
      "Valid Loss: 0.191109, Acc: 0.94, F: 0.53, Fbeta: 0.57, gbeta: 0.34, auroc: 0.90, auprc: 0.64\n",
      " \n",
      "S3/1600 54.32 min|\n",
      "Train Loss: 0.159204, Acc: 0.95, F: 0.64, Fbeta: 0.69, gbeta: 0.44, auroc: 0.95, auprc: 0.77 |\n",
      "Valid Loss: 0.190213, Acc: 0.94, F: 0.54, Fbeta: 0.57, gbeta: 0.34, auroc: 0.90, auprc: 0.64\n",
      " \n",
      "S3/1800 55.09 min|\n",
      "Train Loss: 0.155938, Acc: 0.95, F: 0.65, Fbeta: 0.69, gbeta: 0.45, auroc: 0.95, auprc: 0.77 |\n",
      "Valid Loss: 0.189537, Acc: 0.94, F: 0.54, Fbeta: 0.58, gbeta: 0.34, auroc: 0.90, auprc: 0.65\n",
      " \n",
      "S3/2000 55.86 min|\n",
      "Train Loss: 0.153139, Acc: 0.95, F: 0.66, Fbeta: 0.71, gbeta: 0.46, auroc: 0.95, auprc: 0.78 |\n",
      "Valid Loss: 0.189026, Acc: 0.94, F: 0.55, Fbeta: 0.58, gbeta: 0.35, auroc: 0.90, auprc: 0.65\n",
      " \n",
      "S3/2200 56.64 min|\n",
      "Train Loss: 0.150714, Acc: 0.95, F: 0.67, Fbeta: 0.71, gbeta: 0.46, auroc: 0.96, auprc: 0.79 |\n",
      "Valid Loss: 0.188660, Acc: 0.94, F: 0.54, Fbeta: 0.58, gbeta: 0.34, auroc: 0.90, auprc: 0.64\n",
      " \n",
      "S3/2400 57.41 min|\n",
      "Train Loss: 0.148587, Acc: 0.95, F: 0.67, Fbeta: 0.72, gbeta: 0.47, auroc: 0.96, auprc: 0.79 |\n",
      "Valid Loss: 0.188412, Acc: 0.94, F: 0.55, Fbeta: 0.58, gbeta: 0.34, auroc: 0.90, auprc: 0.64\n",
      " \n",
      "S3/2600 58.18 min|\n",
      "Train Loss: 0.146707, Acc: 0.96, F: 0.67, Fbeta: 0.72, gbeta: 0.47, auroc: 0.96, auprc: 0.79 |\n",
      "Valid Loss: 0.188249, Acc: 0.94, F: 0.54, Fbeta: 0.58, gbeta: 0.34, auroc: 0.90, auprc: 0.64\n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3/2800 58.95 min|\n",
      "Train Loss: 0.145031, Acc: 0.96, F: 0.68, Fbeta: 0.72, gbeta: 0.47, auroc: 0.96, auprc: 0.80 |\n",
      "Valid Loss: 0.188137, Acc: 0.94, F: 0.55, Fbeta: 0.58, gbeta: 0.35, auroc: 0.90, auprc: 0.64\n",
      " \n",
      "S3/3000 59.72 min|\n",
      "Train Loss: 0.143525, Acc: 0.96, F: 0.68, Fbeta: 0.72, gbeta: 0.47, auroc: 0.96, auprc: 0.80 |\n",
      "Valid Loss: 0.188063, Acc: 0.93, F: 0.55, Fbeta: 0.58, gbeta: 0.35, auroc: 0.90, auprc: 0.64\n",
      " \n",
      "S3/3200 60.49 min|\n",
      "Train Loss: 0.142166, Acc: 0.96, F: 0.69, Fbeta: 0.73, gbeta: 0.48, auroc: 0.96, auprc: 0.80 |\n",
      "Valid Loss: 0.188033, Acc: 0.94, F: 0.54, Fbeta: 0.58, gbeta: 0.34, auroc: 0.90, auprc: 0.64\n",
      " \n",
      "S3/3400 61.26 min|\n",
      "Train Loss: 0.140935, Acc: 0.96, F: 0.69, Fbeta: 0.73, gbeta: 0.48, auroc: 0.96, auprc: 0.81 |\n",
      "Valid Loss: 0.188029, Acc: 0.94, F: 0.55, Fbeta: 0.58, gbeta: 0.35, auroc: 0.90, auprc: 0.64\n",
      " \n",
      "Early stopping\n",
      "AUROC|AUPRC|Accuracy|F-measure|Fbeta-measure|Gbeta-measure\n",
      "0.959|0.806|0.000|0.688|0.729|0.481\n",
      "S4/0 61.72 min|\n",
      "Train Loss: 0.696923, Acc: 0.53, F: 0.14, Fbeta: 0.07, gbeta: 0.04, auroc: 0.51, auprc: 0.11 |\n",
      "Valid Loss: 0.698303, Acc: 0.53, F: 0.14, Fbeta: 0.07, gbeta: 0.04, auroc: 0.51, auprc: 0.11\n",
      " \n",
      "S4/200 62.50 min|\n",
      "Train Loss: 0.266647, Acc: 0.92, F: 0.27, Fbeta: 0.29, gbeta: 0.16, auroc: 0.84, auprc: 0.44 |\n",
      "Valid Loss: 0.271639, Acc: 0.92, F: 0.26, Fbeta: 0.28, gbeta: 0.16, auroc: 0.84, auprc: 0.41\n",
      " \n",
      "S4/400 63.28 min|\n",
      "Train Loss: 0.232330, Acc: 0.93, F: 0.45, Fbeta: 0.47, gbeta: 0.29, auroc: 0.89, auprc: 0.58 |\n",
      "Valid Loss: 0.240954, Acc: 0.93, F: 0.42, Fbeta: 0.45, gbeta: 0.27, auroc: 0.88, auprc: 0.54\n",
      " \n",
      "S4/600 64.05 min|\n",
      "Train Loss: 0.213404, Acc: 0.94, F: 0.50, Fbeta: 0.54, gbeta: 0.34, auroc: 0.91, auprc: 0.63 |\n",
      "Valid Loss: 0.226347, Acc: 0.93, F: 0.46, Fbeta: 0.49, gbeta: 0.29, auroc: 0.89, auprc: 0.58\n",
      " \n",
      "S4/800 64.82 min|\n",
      "Train Loss: 0.201549, Acc: 0.94, F: 0.52, Fbeta: 0.55, gbeta: 0.35, auroc: 0.91, auprc: 0.65 |\n",
      "Valid Loss: 0.219052, Acc: 0.93, F: 0.46, Fbeta: 0.49, gbeta: 0.29, auroc: 0.89, auprc: 0.58\n",
      " \n",
      "S4/1000 65.60 min|\n",
      "Train Loss: 0.193348, Acc: 0.94, F: 0.54, Fbeta: 0.56, gbeta: 0.37, auroc: 0.92, auprc: 0.67 |\n",
      "Valid Loss: 0.214806, Acc: 0.93, F: 0.46, Fbeta: 0.49, gbeta: 0.30, auroc: 0.89, auprc: 0.58\n",
      " \n",
      "S4/1200 66.37 min|\n",
      "Train Loss: 0.187201, Acc: 0.94, F: 0.54, Fbeta: 0.57, gbeta: 0.37, auroc: 0.92, auprc: 0.68 |\n",
      "Valid Loss: 0.211983, Acc: 0.93, F: 0.46, Fbeta: 0.49, gbeta: 0.30, auroc: 0.89, auprc: 0.59\n",
      " \n",
      "S4/1400 67.14 min|\n",
      "Train Loss: 0.182340, Acc: 0.95, F: 0.55, Fbeta: 0.58, gbeta: 0.38, auroc: 0.93, auprc: 0.69 |\n",
      "Valid Loss: 0.210163, Acc: 0.93, F: 0.47, Fbeta: 0.49, gbeta: 0.30, auroc: 0.89, auprc: 0.58\n",
      " \n",
      "S4/1600 67.91 min|\n",
      "Train Loss: 0.178336, Acc: 0.95, F: 0.55, Fbeta: 0.58, gbeta: 0.38, auroc: 0.93, auprc: 0.70 |\n",
      "Valid Loss: 0.208969, Acc: 0.93, F: 0.46, Fbeta: 0.49, gbeta: 0.30, auroc: 0.89, auprc: 0.59\n",
      " \n",
      "S4/1800 68.67 min|\n",
      "Train Loss: 0.174954, Acc: 0.95, F: 0.56, Fbeta: 0.59, gbeta: 0.39, auroc: 0.93, auprc: 0.71 |\n",
      "Valid Loss: 0.208152, Acc: 0.93, F: 0.47, Fbeta: 0.50, gbeta: 0.30, auroc: 0.89, auprc: 0.58\n",
      " \n",
      "S4/2000 69.44 min|\n",
      "Train Loss: 0.172015, Acc: 0.95, F: 0.56, Fbeta: 0.60, gbeta: 0.39, auroc: 0.94, auprc: 0.72 |\n",
      "Valid Loss: 0.207624, Acc: 0.93, F: 0.48, Fbeta: 0.51, gbeta: 0.30, auroc: 0.89, auprc: 0.59\n",
      " \n",
      "S4/2200 70.21 min|\n",
      "Train Loss: 0.169369, Acc: 0.95, F: 0.62, Fbeta: 0.66, gbeta: 0.43, auroc: 0.94, auprc: 0.75 |\n",
      "Valid Loss: 0.207254, Acc: 0.93, F: 0.52, Fbeta: 0.55, gbeta: 0.33, auroc: 0.89, auprc: 0.60\n",
      " \n",
      "S4/2400 70.98 min|\n",
      "Train Loss: 0.166677, Acc: 0.95, F: 0.64, Fbeta: 0.67, gbeta: 0.44, auroc: 0.95, auprc: 0.76 |\n",
      "Valid Loss: 0.206910, Acc: 0.93, F: 0.52, Fbeta: 0.55, gbeta: 0.33, auroc: 0.89, auprc: 0.60\n",
      " \n",
      "S4/2600 71.75 min|\n",
      "Train Loss: 0.164201, Acc: 0.95, F: 0.64, Fbeta: 0.68, gbeta: 0.45, auroc: 0.95, auprc: 0.77 |\n",
      "Valid Loss: 0.206688, Acc: 0.93, F: 0.52, Fbeta: 0.54, gbeta: 0.33, auroc: 0.89, auprc: 0.59\n",
      " \n",
      "S4/2800 72.51 min|\n",
      "Train Loss: 0.161944, Acc: 0.95, F: 0.65, Fbeta: 0.69, gbeta: 0.46, auroc: 0.95, auprc: 0.77 |\n",
      "Valid Loss: 0.206520, Acc: 0.93, F: 0.53, Fbeta: 0.55, gbeta: 0.33, auroc: 0.89, auprc: 0.59\n",
      " \n",
      "S4/3000 73.28 min|\n",
      "Train Loss: 0.159891, Acc: 0.95, F: 0.66, Fbeta: 0.70, gbeta: 0.46, auroc: 0.95, auprc: 0.78 |\n",
      "Valid Loss: 0.206370, Acc: 0.93, F: 0.52, Fbeta: 0.55, gbeta: 0.33, auroc: 0.89, auprc: 0.60\n",
      " \n",
      "S4/3200 74.05 min|\n",
      "Train Loss: 0.158010, Acc: 0.95, F: 0.66, Fbeta: 0.70, gbeta: 0.46, auroc: 0.95, auprc: 0.78 |\n",
      "Valid Loss: 0.206240, Acc: 0.93, F: 0.52, Fbeta: 0.55, gbeta: 0.33, auroc: 0.89, auprc: 0.60\n",
      " \n",
      "S4/3400 74.81 min|\n",
      "Train Loss: 0.156285, Acc: 0.95, F: 0.66, Fbeta: 0.71, gbeta: 0.46, auroc: 0.95, auprc: 0.78 |\n",
      "Valid Loss: 0.206098, Acc: 0.93, F: 0.53, Fbeta: 0.56, gbeta: 0.33, auroc: 0.89, auprc: 0.60\n",
      " \n",
      "S4/3600 75.58 min|\n",
      "Train Loss: 0.154705, Acc: 0.95, F: 0.67, Fbeta: 0.71, gbeta: 0.47, auroc: 0.95, auprc: 0.79 |\n",
      "Valid Loss: 0.205962, Acc: 0.93, F: 0.52, Fbeta: 0.55, gbeta: 0.33, auroc: 0.89, auprc: 0.59\n",
      " \n",
      "S4/3800 76.35 min|\n",
      "Train Loss: 0.153251, Acc: 0.95, F: 0.67, Fbeta: 0.72, gbeta: 0.47, auroc: 0.95, auprc: 0.79 |\n",
      "Valid Loss: 0.205858, Acc: 0.93, F: 0.54, Fbeta: 0.56, gbeta: 0.33, auroc: 0.89, auprc: 0.61\n",
      " \n",
      "S4/4000 77.11 min|\n",
      "Train Loss: 0.151910, Acc: 0.95, F: 0.68, Fbeta: 0.72, gbeta: 0.48, auroc: 0.95, auprc: 0.79 |\n",
      "Valid Loss: 0.205769, Acc: 0.93, F: 0.54, Fbeta: 0.56, gbeta: 0.34, auroc: 0.89, auprc: 0.60\n",
      " \n",
      "S4/4200 77.88 min|\n",
      "Train Loss: 0.150666, Acc: 0.95, F: 0.68, Fbeta: 0.72, gbeta: 0.48, auroc: 0.95, auprc: 0.79 |\n",
      "Valid Loss: 0.205691, Acc: 0.93, F: 0.54, Fbeta: 0.56, gbeta: 0.33, auroc: 0.89, auprc: 0.60\n",
      " \n",
      "S4/4400 78.64 min|\n",
      "Train Loss: 0.149509, Acc: 0.95, F: 0.68, Fbeta: 0.72, gbeta: 0.48, auroc: 0.95, auprc: 0.79 |\n",
      "Valid Loss: 0.205629, Acc: 0.93, F: 0.54, Fbeta: 0.57, gbeta: 0.34, auroc: 0.89, auprc: 0.61\n",
      " \n",
      "S4/4600 79.41 min|\n",
      "Train Loss: 0.148436, Acc: 0.95, F: 0.68, Fbeta: 0.72, gbeta: 0.48, auroc: 0.95, auprc: 0.80 |\n",
      "Valid Loss: 0.205589, Acc: 0.93, F: 0.55, Fbeta: 0.58, gbeta: 0.35, auroc: 0.89, auprc: 0.62\n",
      " \n",
      "S4/4800 80.17 min|\n",
      "Train Loss: 0.147431, Acc: 0.96, F: 0.69, Fbeta: 0.73, gbeta: 0.48, auroc: 0.95, auprc: 0.80 |\n",
      "Valid Loss: 0.205554, Acc: 0.93, F: 0.54, Fbeta: 0.57, gbeta: 0.34, auroc: 0.89, auprc: 0.61\n",
      " \n",
      "S4/5000 80.94 min|\n",
      "Train Loss: 0.146489, Acc: 0.96, F: 0.68, Fbeta: 0.73, gbeta: 0.48, auroc: 0.95, auprc: 0.80 |\n",
      "Valid Loss: 0.205547, Acc: 0.93, F: 0.54, Fbeta: 0.57, gbeta: 0.34, auroc: 0.89, auprc: 0.61\n",
      " \n",
      "Early stopping\n",
      "AUROC|AUPRC|Accuracy|F-measure|Fbeta-measure|Gbeta-measure\n",
      "0.954|0.799|0.000|0.684|0.727|0.481\n",
      "S5/0 81.37 min|\n",
      "Train Loss: 0.686313, Acc: 0.55, F: 0.16, Fbeta: 0.09, gbeta: 0.05, auroc: 0.50, auprc: 0.11 |\n",
      "Valid Loss: 0.686733, Acc: 0.55, F: 0.16, Fbeta: 0.09, gbeta: 0.05, auroc: 0.50, auprc: 0.11\n",
      " \n",
      "S5/200 82.15 min|\n",
      "Train Loss: 0.256752, Acc: 0.93, F: 0.35, Fbeta: 0.37, gbeta: 0.22, auroc: 0.87, auprc: 0.50 |\n",
      "Valid Loss: 0.262878, Acc: 0.92, F: 0.32, Fbeta: 0.34, gbeta: 0.19, auroc: 0.85, auprc: 0.46\n",
      " \n",
      "S5/400 82.93 min|\n",
      "Train Loss: 0.221768, Acc: 0.93, F: 0.41, Fbeta: 0.43, gbeta: 0.27, auroc: 0.90, auprc: 0.58 |\n",
      "Valid Loss: 0.235162, Acc: 0.93, F: 0.38, Fbeta: 0.40, gbeta: 0.23, auroc: 0.87, auprc: 0.52\n",
      " \n",
      "S5/600 83.70 min|\n",
      "Train Loss: 0.205593, Acc: 0.94, F: 0.43, Fbeta: 0.46, gbeta: 0.29, auroc: 0.91, auprc: 0.61 |\n",
      "Valid Loss: 0.223738, Acc: 0.93, F: 0.39, Fbeta: 0.41, gbeta: 0.24, auroc: 0.88, auprc: 0.54\n",
      " \n",
      "S5/800 84.48 min|\n",
      "Train Loss: 0.195482, Acc: 0.94, F: 0.45, Fbeta: 0.47, gbeta: 0.31, auroc: 0.92, auprc: 0.64 |\n",
      "Valid Loss: 0.217848, Acc: 0.93, F: 0.40, Fbeta: 0.43, gbeta: 0.25, auroc: 0.88, auprc: 0.56\n",
      " \n",
      "S5/1000 85.25 min|\n",
      "Train Loss: 0.188127, Acc: 0.94, F: 0.47, Fbeta: 0.50, gbeta: 0.32, auroc: 0.92, auprc: 0.65 |\n",
      "Valid Loss: 0.214298, Acc: 0.93, F: 0.42, Fbeta: 0.45, gbeta: 0.26, auroc: 0.88, auprc: 0.57\n",
      " \n",
      "S5/1200 86.02 min|\n",
      "Train Loss: 0.182441, Acc: 0.94, F: 0.49, Fbeta: 0.52, gbeta: 0.33, auroc: 0.93, auprc: 0.67 |\n",
      "Valid Loss: 0.212082, Acc: 0.93, F: 0.43, Fbeta: 0.47, gbeta: 0.26, auroc: 0.88, auprc: 0.57\n",
      " \n",
      "S5/1400 86.79 min|\n",
      "Train Loss: 0.177857, Acc: 0.95, F: 0.51, Fbeta: 0.55, gbeta: 0.35, auroc: 0.93, auprc: 0.68 |\n",
      "Valid Loss: 0.210717, Acc: 0.93, F: 0.45, Fbeta: 0.48, gbeta: 0.27, auroc: 0.88, auprc: 0.57\n",
      " \n",
      "S5/1600 87.56 min|\n",
      "Train Loss: 0.174064, Acc: 0.95, F: 0.52, Fbeta: 0.56, gbeta: 0.36, auroc: 0.93, auprc: 0.68 |\n",
      "Valid Loss: 0.209814, Acc: 0.93, F: 0.45, Fbeta: 0.48, gbeta: 0.27, auroc: 0.88, auprc: 0.57\n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S5/1800 88.33 min|\n",
      "Train Loss: 0.170814, Acc: 0.95, F: 0.54, Fbeta: 0.57, gbeta: 0.37, auroc: 0.94, auprc: 0.69 |\n",
      "Valid Loss: 0.209167, Acc: 0.93, F: 0.46, Fbeta: 0.49, gbeta: 0.28, auroc: 0.88, auprc: 0.57\n",
      " \n",
      "S5/2000 89.10 min|\n",
      "Train Loss: 0.167892, Acc: 0.95, F: 0.55, Fbeta: 0.59, gbeta: 0.38, auroc: 0.94, auprc: 0.70 |\n",
      "Valid Loss: 0.208702, Acc: 0.93, F: 0.46, Fbeta: 0.50, gbeta: 0.29, auroc: 0.88, auprc: 0.57\n",
      " \n",
      "S5/2200 89.87 min|\n",
      "Train Loss: 0.165300, Acc: 0.95, F: 0.55, Fbeta: 0.59, gbeta: 0.39, auroc: 0.94, auprc: 0.71 |\n",
      "Valid Loss: 0.208383, Acc: 0.93, F: 0.46, Fbeta: 0.49, gbeta: 0.28, auroc: 0.88, auprc: 0.57\n",
      " \n",
      "S5/2400 90.63 min|\n",
      "Train Loss: 0.162999, Acc: 0.95, F: 0.56, Fbeta: 0.60, gbeta: 0.39, auroc: 0.94, auprc: 0.72 |\n",
      "Valid Loss: 0.208102, Acc: 0.93, F: 0.47, Fbeta: 0.50, gbeta: 0.29, auroc: 0.88, auprc: 0.58\n",
      " \n",
      "S5/2600 91.40 min|\n",
      "Train Loss: 0.160940, Acc: 0.95, F: 0.57, Fbeta: 0.61, gbeta: 0.40, auroc: 0.94, auprc: 0.72 |\n",
      "Valid Loss: 0.207913, Acc: 0.93, F: 0.47, Fbeta: 0.50, gbeta: 0.29, auroc: 0.88, auprc: 0.57\n",
      " \n",
      "S5/2800 92.17 min|\n",
      "Train Loss: 0.159095, Acc: 0.95, F: 0.58, Fbeta: 0.62, gbeta: 0.41, auroc: 0.94, auprc: 0.72 |\n",
      "Valid Loss: 0.207819, Acc: 0.93, F: 0.47, Fbeta: 0.51, gbeta: 0.29, auroc: 0.88, auprc: 0.57\n",
      " \n",
      "S5/3000 92.93 min|\n",
      "Train Loss: 0.157433, Acc: 0.95, F: 0.58, Fbeta: 0.62, gbeta: 0.41, auroc: 0.94, auprc: 0.73 |\n",
      "Valid Loss: 0.207786, Acc: 0.93, F: 0.47, Fbeta: 0.51, gbeta: 0.29, auroc: 0.88, auprc: 0.57\n",
      " \n",
      "S5/3200 93.70 min|\n",
      "Train Loss: 0.155923, Acc: 0.95, F: 0.58, Fbeta: 0.62, gbeta: 0.41, auroc: 0.95, auprc: 0.73 |\n",
      "Valid Loss: 0.207777, Acc: 0.93, F: 0.47, Fbeta: 0.50, gbeta: 0.28, auroc: 0.88, auprc: 0.57\n",
      " \n",
      "S5/3400 94.47 min|\n",
      "Train Loss: 0.154541, Acc: 0.95, F: 0.59, Fbeta: 0.63, gbeta: 0.41, auroc: 0.95, auprc: 0.74 |\n",
      "Valid Loss: 0.207758, Acc: 0.93, F: 0.48, Fbeta: 0.51, gbeta: 0.29, auroc: 0.88, auprc: 0.58\n",
      " \n",
      "S5/3600 95.23 min|\n",
      "Train Loss: 0.153169, Acc: 0.95, F: 0.63, Fbeta: 0.68, gbeta: 0.45, auroc: 0.95, auprc: 0.77 |\n",
      "Valid Loss: 0.207647, Acc: 0.93, F: 0.50, Fbeta: 0.53, gbeta: 0.31, auroc: 0.89, auprc: 0.60\n",
      " \n",
      "S5/3800 96.00 min|\n",
      "Train Loss: 0.151632, Acc: 0.96, F: 0.68, Fbeta: 0.72, gbeta: 0.48, auroc: 0.96, auprc: 0.80 |\n",
      "Valid Loss: 0.207443, Acc: 0.93, F: 0.52, Fbeta: 0.56, gbeta: 0.32, auroc: 0.89, auprc: 0.61\n",
      " \n",
      "S5/4000 96.77 min|\n",
      "Train Loss: 0.150045, Acc: 0.96, F: 0.69, Fbeta: 0.73, gbeta: 0.50, auroc: 0.96, auprc: 0.81 |\n",
      "Valid Loss: 0.207144, Acc: 0.93, F: 0.54, Fbeta: 0.58, gbeta: 0.33, auroc: 0.89, auprc: 0.61\n",
      " \n",
      "S5/4200 97.54 min|\n",
      "Train Loss: 0.148536, Acc: 0.96, F: 0.70, Fbeta: 0.74, gbeta: 0.50, auroc: 0.96, auprc: 0.81 |\n",
      "Valid Loss: 0.206862, Acc: 0.93, F: 0.54, Fbeta: 0.58, gbeta: 0.33, auroc: 0.89, auprc: 0.61\n",
      " \n",
      "S5/4400 98.30 min|\n",
      "Train Loss: 0.147113, Acc: 0.96, F: 0.71, Fbeta: 0.75, gbeta: 0.51, auroc: 0.96, auprc: 0.81 |\n",
      "Valid Loss: 0.206616, Acc: 0.93, F: 0.54, Fbeta: 0.58, gbeta: 0.33, auroc: 0.89, auprc: 0.61\n",
      " \n",
      "S5/4600 99.07 min|\n",
      "Train Loss: 0.145766, Acc: 0.96, F: 0.71, Fbeta: 0.75, gbeta: 0.51, auroc: 0.96, auprc: 0.82 |\n",
      "Valid Loss: 0.206395, Acc: 0.93, F: 0.54, Fbeta: 0.58, gbeta: 0.33, auroc: 0.90, auprc: 0.61\n",
      " \n",
      "S5/4800 99.84 min|\n",
      "Train Loss: 0.144497, Acc: 0.96, F: 0.71, Fbeta: 0.75, gbeta: 0.51, auroc: 0.96, auprc: 0.82 |\n",
      "Valid Loss: 0.206217, Acc: 0.93, F: 0.54, Fbeta: 0.58, gbeta: 0.33, auroc: 0.89, auprc: 0.61\n",
      " \n",
      "S5/5000 100.60 min|\n",
      "Train Loss: 0.143300, Acc: 0.96, F: 0.72, Fbeta: 0.76, gbeta: 0.52, auroc: 0.96, auprc: 0.82 |\n",
      "Valid Loss: 0.206070, Acc: 0.93, F: 0.53, Fbeta: 0.56, gbeta: 0.32, auroc: 0.89, auprc: 0.61\n",
      " \n",
      "S5/5200 101.37 min|\n",
      "Train Loss: 0.142176, Acc: 0.96, F: 0.72, Fbeta: 0.76, gbeta: 0.52, auroc: 0.96, auprc: 0.83 |\n",
      "Valid Loss: 0.205965, Acc: 0.93, F: 0.54, Fbeta: 0.57, gbeta: 0.33, auroc: 0.90, auprc: 0.61\n",
      " \n",
      "S5/5400 102.14 min|\n",
      "Train Loss: 0.141109, Acc: 0.96, F: 0.73, Fbeta: 0.76, gbeta: 0.53, auroc: 0.96, auprc: 0.83 |\n",
      "Valid Loss: 0.205886, Acc: 0.93, F: 0.54, Fbeta: 0.58, gbeta: 0.33, auroc: 0.90, auprc: 0.61\n",
      " \n",
      "S5/5600 102.90 min|\n",
      "Train Loss: 0.140082, Acc: 0.96, F: 0.73, Fbeta: 0.76, gbeta: 0.53, auroc: 0.96, auprc: 0.83 |\n",
      "Valid Loss: 0.205835, Acc: 0.93, F: 0.53, Fbeta: 0.57, gbeta: 0.33, auroc: 0.89, auprc: 0.61\n",
      " \n",
      "S5/5800 103.67 min|\n",
      "Train Loss: 0.139094, Acc: 0.96, F: 0.73, Fbeta: 0.77, gbeta: 0.53, auroc: 0.96, auprc: 0.83 |\n",
      "Valid Loss: 0.205780, Acc: 0.93, F: 0.53, Fbeta: 0.57, gbeta: 0.33, auroc: 0.90, auprc: 0.61\n",
      " \n",
      "S5/6000 104.44 min|\n",
      "Train Loss: 0.138143, Acc: 0.96, F: 0.73, Fbeta: 0.77, gbeta: 0.53, auroc: 0.96, auprc: 0.84 |\n",
      "Valid Loss: 0.205730, Acc: 0.93, F: 0.53, Fbeta: 0.57, gbeta: 0.33, auroc: 0.90, auprc: 0.61\n",
      " \n",
      "S5/6200 105.20 min|\n",
      "Train Loss: 0.137232, Acc: 0.96, F: 0.74, Fbeta: 0.77, gbeta: 0.53, auroc: 0.96, auprc: 0.84 |\n",
      "Valid Loss: 0.205677, Acc: 0.93, F: 0.54, Fbeta: 0.58, gbeta: 0.33, auroc: 0.90, auprc: 0.62\n",
      " \n",
      "S5/6400 105.97 min|\n",
      "Train Loss: 0.136366, Acc: 0.96, F: 0.74, Fbeta: 0.77, gbeta: 0.54, auroc: 0.96, auprc: 0.84 |\n",
      "Valid Loss: 0.205637, Acc: 0.93, F: 0.53, Fbeta: 0.57, gbeta: 0.32, auroc: 0.90, auprc: 0.61\n",
      " \n",
      "S5/6600 106.73 min|\n",
      "Train Loss: 0.135540, Acc: 0.96, F: 0.74, Fbeta: 0.77, gbeta: 0.54, auroc: 0.97, auprc: 0.84 |\n",
      "Valid Loss: 0.205605, Acc: 0.93, F: 0.54, Fbeta: 0.58, gbeta: 0.33, auroc: 0.90, auprc: 0.62\n",
      " \n",
      "S5/6800 107.50 min|\n",
      "Train Loss: 0.134750, Acc: 0.96, F: 0.74, Fbeta: 0.78, gbeta: 0.54, auroc: 0.96, auprc: 0.84 |\n",
      "Valid Loss: 0.205577, Acc: 0.93, F: 0.53, Fbeta: 0.57, gbeta: 0.33, auroc: 0.90, auprc: 0.62\n",
      " \n",
      "S5/7000 108.27 min|\n",
      "Train Loss: 0.133997, Acc: 0.96, F: 0.74, Fbeta: 0.78, gbeta: 0.54, auroc: 0.97, auprc: 0.84 |\n",
      "Valid Loss: 0.205561, Acc: 0.93, F: 0.55, Fbeta: 0.59, gbeta: 0.33, auroc: 0.90, auprc: 0.62\n",
      " \n",
      "S5/7200 109.03 min|\n",
      "Train Loss: 0.133275, Acc: 0.96, F: 0.74, Fbeta: 0.78, gbeta: 0.54, auroc: 0.97, auprc: 0.84 |\n",
      "Valid Loss: 0.205547, Acc: 0.93, F: 0.54, Fbeta: 0.58, gbeta: 0.33, auroc: 0.90, auprc: 0.61\n",
      " \n",
      "S5/7400 109.80 min|\n",
      "Train Loss: 0.132582, Acc: 0.96, F: 0.74, Fbeta: 0.78, gbeta: 0.54, auroc: 0.97, auprc: 0.84 |\n",
      "Valid Loss: 0.205545, Acc: 0.93, F: 0.54, Fbeta: 0.58, gbeta: 0.34, auroc: 0.90, auprc: 0.62\n",
      " \n",
      "Early stopping\n",
      "AUROC|AUPRC|Accuracy|F-measure|Fbeta-measure|Gbeta-measure\n",
      "0.966|0.843|0.000|0.740|0.778|0.541\n",
      "S6/0 110.45 min|\n",
      "Train Loss: 0.669538, Acc: 0.64, F: 0.14, Fbeta: 0.08, gbeta: 0.04, auroc: 0.52, auprc: 0.12 |\n",
      "Valid Loss: 0.670735, Acc: 0.63, F: 0.13, Fbeta: 0.07, gbeta: 0.04, auroc: 0.50, auprc: 0.12\n",
      " \n",
      "S6/200 111.23 min|\n",
      "Train Loss: 0.254914, Acc: 0.93, F: 0.38, Fbeta: 0.41, gbeta: 0.24, auroc: 0.87, auprc: 0.52 |\n",
      "Valid Loss: 0.264044, Acc: 0.92, F: 0.36, Fbeta: 0.39, gbeta: 0.21, auroc: 0.85, auprc: 0.50\n",
      " \n",
      "S6/400 112.00 min|\n",
      "Train Loss: 0.220123, Acc: 0.94, F: 0.46, Fbeta: 0.49, gbeta: 0.31, auroc: 0.89, auprc: 0.59 |\n",
      "Valid Loss: 0.235802, Acc: 0.93, F: 0.42, Fbeta: 0.44, gbeta: 0.26, auroc: 0.87, auprc: 0.53\n",
      " \n",
      "S6/800 113.55 min|\n",
      "Train Loss: 0.191481, Acc: 0.94, F: 0.54, Fbeta: 0.56, gbeta: 0.37, auroc: 0.92, auprc: 0.67 |\n",
      "Valid Loss: 0.217849, Acc: 0.93, F: 0.47, Fbeta: 0.49, gbeta: 0.29, auroc: 0.88, auprc: 0.57\n",
      " \n",
      "S6/1000 114.32 min|\n",
      "Train Loss: 0.183062, Acc: 0.95, F: 0.55, Fbeta: 0.58, gbeta: 0.39, auroc: 0.93, auprc: 0.69 |\n",
      "Valid Loss: 0.214036, Acc: 0.93, F: 0.47, Fbeta: 0.49, gbeta: 0.29, auroc: 0.89, auprc: 0.57\n",
      " \n",
      "S6/1200 115.09 min|\n",
      "Train Loss: 0.176585, Acc: 0.95, F: 0.57, Fbeta: 0.60, gbeta: 0.40, auroc: 0.94, auprc: 0.71 |\n",
      "Valid Loss: 0.211848, Acc: 0.93, F: 0.48, Fbeta: 0.50, gbeta: 0.29, auroc: 0.89, auprc: 0.58\n",
      " \n",
      "S6/1400 115.86 min|\n",
      "Train Loss: 0.171445, Acc: 0.95, F: 0.58, Fbeta: 0.61, gbeta: 0.41, auroc: 0.94, auprc: 0.72 |\n",
      "Valid Loss: 0.210554, Acc: 0.93, F: 0.48, Fbeta: 0.51, gbeta: 0.30, auroc: 0.89, auprc: 0.57\n",
      " \n",
      "S6/1600 116.63 min|\n",
      "Train Loss: 0.167250, Acc: 0.95, F: 0.59, Fbeta: 0.62, gbeta: 0.41, auroc: 0.94, auprc: 0.73 |\n",
      "Valid Loss: 0.209776, Acc: 0.93, F: 0.48, Fbeta: 0.50, gbeta: 0.30, auroc: 0.89, auprc: 0.58\n",
      " \n",
      "S6/1800 117.40 min|\n",
      "Train Loss: 0.163760, Acc: 0.95, F: 0.59, Fbeta: 0.63, gbeta: 0.42, auroc: 0.94, auprc: 0.74 |\n",
      "Valid Loss: 0.209335, Acc: 0.93, F: 0.48, Fbeta: 0.51, gbeta: 0.30, auroc: 0.89, auprc: 0.58\n",
      " \n",
      "S6/2000 118.17 min|\n",
      "Train Loss: 0.160802, Acc: 0.95, F: 0.60, Fbeta: 0.63, gbeta: 0.42, auroc: 0.95, auprc: 0.74 |\n",
      "Valid Loss: 0.209151, Acc: 0.93, F: 0.48, Fbeta: 0.51, gbeta: 0.30, auroc: 0.89, auprc: 0.57\n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S6/2200 118.93 min|\n",
      "Train Loss: 0.158247, Acc: 0.95, F: 0.61, Fbeta: 0.64, gbeta: 0.43, auroc: 0.95, auprc: 0.75 |\n",
      "Valid Loss: 0.209138, Acc: 0.93, F: 0.48, Fbeta: 0.51, gbeta: 0.30, auroc: 0.89, auprc: 0.57\n",
      " \n",
      "Early stopping\n",
      "AUROC|AUPRC|Accuracy|F-measure|Fbeta-measure|Gbeta-measure\n",
      "0.947|0.751|0.000|0.607|0.643|0.430\n",
      "S7/0 119.41 min|\n",
      "Train Loss: 0.700673, Acc: 0.41, F: 0.15, Fbeta: 0.07, gbeta: 0.04, auroc: 0.47, auprc: 0.10 |\n",
      "Valid Loss: 0.701918, Acc: 0.40, F: 0.13, Fbeta: 0.06, gbeta: 0.04, auroc: 0.47, auprc: 0.11\n",
      " \n",
      "S7/200 120.19 min|\n",
      "Train Loss: 0.260374, Acc: 0.92, F: 0.39, Fbeta: 0.42, gbeta: 0.24, auroc: 0.87, auprc: 0.52 |\n",
      "Valid Loss: 0.262897, Acc: 0.92, F: 0.35, Fbeta: 0.39, gbeta: 0.21, auroc: 0.84, auprc: 0.46\n",
      " \n",
      "S7/400 120.97 min|\n",
      "Train Loss: 0.223658, Acc: 0.93, F: 0.46, Fbeta: 0.48, gbeta: 0.30, auroc: 0.90, auprc: 0.59 |\n",
      "Valid Loss: 0.235684, Acc: 0.93, F: 0.41, Fbeta: 0.44, gbeta: 0.25, auroc: 0.86, auprc: 0.53\n",
      " \n",
      "S7/600 121.75 min|\n",
      "Train Loss: 0.206243, Acc: 0.94, F: 0.48, Fbeta: 0.50, gbeta: 0.33, auroc: 0.91, auprc: 0.62 |\n",
      "Valid Loss: 0.224868, Acc: 0.93, F: 0.43, Fbeta: 0.46, gbeta: 0.27, auroc: 0.87, auprc: 0.55\n",
      " \n",
      "S7/800 122.53 min|\n",
      "Train Loss: 0.195662, Acc: 0.94, F: 0.50, Fbeta: 0.51, gbeta: 0.35, auroc: 0.91, auprc: 0.64 |\n",
      "Valid Loss: 0.219143, Acc: 0.94, F: 0.44, Fbeta: 0.47, gbeta: 0.28, auroc: 0.87, auprc: 0.56\n",
      " \n",
      "S7/1000 123.31 min|\n",
      "Train Loss: 0.188296, Acc: 0.94, F: 0.51, Fbeta: 0.53, gbeta: 0.36, auroc: 0.92, auprc: 0.65 |\n",
      "Valid Loss: 0.215572, Acc: 0.94, F: 0.45, Fbeta: 0.48, gbeta: 0.29, auroc: 0.87, auprc: 0.56\n",
      " \n",
      "S7/1200 124.09 min|\n",
      "Train Loss: 0.182636, Acc: 0.94, F: 0.52, Fbeta: 0.54, gbeta: 0.37, auroc: 0.92, auprc: 0.67 |\n",
      "Valid Loss: 0.213174, Acc: 0.94, F: 0.44, Fbeta: 0.47, gbeta: 0.29, auroc: 0.87, auprc: 0.56\n",
      " \n",
      "S7/1400 124.86 min|\n",
      "Train Loss: 0.178132, Acc: 0.94, F: 0.52, Fbeta: 0.54, gbeta: 0.38, auroc: 0.93, auprc: 0.67 |\n",
      "Valid Loss: 0.211527, Acc: 0.94, F: 0.45, Fbeta: 0.48, gbeta: 0.29, auroc: 0.88, auprc: 0.57\n",
      " \n",
      "S7/1600 125.64 min|\n",
      "Train Loss: 0.174435, Acc: 0.95, F: 0.53, Fbeta: 0.55, gbeta: 0.38, auroc: 0.93, auprc: 0.68 |\n",
      "Valid Loss: 0.210391, Acc: 0.94, F: 0.44, Fbeta: 0.47, gbeta: 0.29, auroc: 0.88, auprc: 0.56\n",
      " \n",
      "S7/1800 126.41 min|\n",
      "Train Loss: 0.171335, Acc: 0.95, F: 0.54, Fbeta: 0.56, gbeta: 0.39, auroc: 0.93, auprc: 0.69 |\n",
      "Valid Loss: 0.209650, Acc: 0.94, F: 0.45, Fbeta: 0.48, gbeta: 0.29, auroc: 0.87, auprc: 0.55\n",
      " \n",
      "S7/2000 127.18 min|\n",
      "Train Loss: 0.168697, Acc: 0.95, F: 0.54, Fbeta: 0.56, gbeta: 0.39, auroc: 0.93, auprc: 0.69 |\n",
      "Valid Loss: 0.209180, Acc: 0.94, F: 0.45, Fbeta: 0.48, gbeta: 0.29, auroc: 0.88, auprc: 0.56\n",
      " \n",
      "S7/2200 127.96 min|\n",
      "Train Loss: 0.166425, Acc: 0.95, F: 0.55, Fbeta: 0.58, gbeta: 0.40, auroc: 0.93, auprc: 0.70 |\n",
      "Valid Loss: 0.208884, Acc: 0.94, F: 0.45, Fbeta: 0.49, gbeta: 0.29, auroc: 0.87, auprc: 0.55\n",
      " \n",
      "S7/2400 128.73 min|\n",
      "Train Loss: 0.164444, Acc: 0.95, F: 0.55, Fbeta: 0.58, gbeta: 0.40, auroc: 0.93, auprc: 0.70 |\n",
      "Valid Loss: 0.208692, Acc: 0.94, F: 0.46, Fbeta: 0.49, gbeta: 0.30, auroc: 0.87, auprc: 0.56\n",
      " \n",
      "S7/2600 129.50 min|\n",
      "Train Loss: 0.162708, Acc: 0.95, F: 0.56, Fbeta: 0.58, gbeta: 0.40, auroc: 0.94, auprc: 0.70 |\n",
      "Valid Loss: 0.208583, Acc: 0.94, F: 0.46, Fbeta: 0.49, gbeta: 0.29, auroc: 0.87, auprc: 0.56\n",
      " \n",
      "S7/2800 130.27 min|\n",
      "Train Loss: 0.161165, Acc: 0.95, F: 0.56, Fbeta: 0.59, gbeta: 0.40, auroc: 0.94, auprc: 0.71 |\n",
      "Valid Loss: 0.208534, Acc: 0.94, F: 0.46, Fbeta: 0.49, gbeta: 0.29, auroc: 0.87, auprc: 0.55\n",
      " \n",
      "S7/3000 131.05 min|\n",
      "Train Loss: 0.159788, Acc: 0.95, F: 0.56, Fbeta: 0.59, gbeta: 0.41, auroc: 0.94, auprc: 0.71 |\n",
      "Valid Loss: 0.208491, Acc: 0.94, F: 0.47, Fbeta: 0.50, gbeta: 0.30, auroc: 0.87, auprc: 0.56\n",
      " \n",
      "S7/3200 131.82 min|\n",
      "Train Loss: 0.158521, Acc: 0.95, F: 0.59, Fbeta: 0.62, gbeta: 0.42, auroc: 0.94, auprc: 0.73 |\n",
      "Valid Loss: 0.208477, Acc: 0.94, F: 0.47, Fbeta: 0.51, gbeta: 0.30, auroc: 0.88, auprc: 0.57\n",
      " \n",
      "S7/3400 132.59 min|\n",
      "Train Loss: 0.157233, Acc: 0.95, F: 0.60, Fbeta: 0.64, gbeta: 0.42, auroc: 0.94, auprc: 0.74 |\n",
      "Valid Loss: 0.208401, Acc: 0.94, F: 0.47, Fbeta: 0.51, gbeta: 0.30, auroc: 0.87, auprc: 0.56\n",
      " \n",
      "S7/3600 133.36 min|\n",
      "Train Loss: 0.156013, Acc: 0.95, F: 0.60, Fbeta: 0.64, gbeta: 0.43, auroc: 0.94, auprc: 0.74 |\n",
      "Valid Loss: 0.208305, Acc: 0.94, F: 0.48, Fbeta: 0.52, gbeta: 0.30, auroc: 0.87, auprc: 0.57\n",
      " \n",
      "S7/3800 134.13 min|\n",
      "Train Loss: 0.154879, Acc: 0.95, F: 0.61, Fbeta: 0.65, gbeta: 0.43, auroc: 0.94, auprc: 0.75 |\n",
      "Valid Loss: 0.208232, Acc: 0.94, F: 0.48, Fbeta: 0.52, gbeta: 0.30, auroc: 0.88, auprc: 0.57\n",
      " \n",
      "S7/4000 134.90 min|\n",
      "Train Loss: 0.153822, Acc: 0.95, F: 0.62, Fbeta: 0.66, gbeta: 0.43, auroc: 0.94, auprc: 0.75 |\n",
      "Valid Loss: 0.208177, Acc: 0.94, F: 0.48, Fbeta: 0.52, gbeta: 0.30, auroc: 0.87, auprc: 0.57\n",
      " \n",
      "S7/4200 135.67 min|\n",
      "Train Loss: 0.152842, Acc: 0.95, F: 0.62, Fbeta: 0.66, gbeta: 0.44, auroc: 0.94, auprc: 0.75 |\n",
      "Valid Loss: 0.208140, Acc: 0.94, F: 0.49, Fbeta: 0.53, gbeta: 0.31, auroc: 0.87, auprc: 0.57\n",
      " \n",
      "S7/4400 136.44 min|\n",
      "Train Loss: 0.151931, Acc: 0.95, F: 0.62, Fbeta: 0.67, gbeta: 0.44, auroc: 0.94, auprc: 0.75 |\n",
      "Valid Loss: 0.208125, Acc: 0.94, F: 0.48, Fbeta: 0.52, gbeta: 0.30, auroc: 0.87, auprc: 0.57\n",
      " \n",
      "S7/4600 137.21 min|\n",
      "Train Loss: 0.151079, Acc: 0.95, F: 0.63, Fbeta: 0.67, gbeta: 0.45, auroc: 0.95, auprc: 0.75 |\n",
      "Valid Loss: 0.208150, Acc: 0.94, F: 0.49, Fbeta: 0.53, gbeta: 0.31, auroc: 0.87, auprc: 0.57\n",
      " \n",
      "Early stopping\n",
      "AUROC|AUPRC|Accuracy|F-measure|Fbeta-measure|Gbeta-measure\n",
      "0.945|0.751|0.000|0.630|0.671|0.446\n",
      "S8/0 137.22 min|\n",
      "Train Loss: 0.711739, Acc: 0.39, F: 0.26, Fbeta: 0.15, gbeta: 0.08, auroc: 0.48, auprc: 0.11 |\n",
      "Valid Loss: 0.711074, Acc: 0.39, F: 0.27, Fbeta: 0.15, gbeta: 0.09, auroc: 0.48, auprc: 0.11\n",
      " \n",
      "S8/200 138.01 min|\n",
      "Train Loss: 0.252156, Acc: 0.93, F: 0.41, Fbeta: 0.45, gbeta: 0.26, auroc: 0.88, auprc: 0.56 |\n",
      "Valid Loss: 0.257821, Acc: 0.93, F: 0.40, Fbeta: 0.44, gbeta: 0.24, auroc: 0.88, auprc: 0.58\n",
      " \n",
      "S8/400 138.79 min|\n",
      "Train Loss: 0.215484, Acc: 0.94, F: 0.48, Fbeta: 0.52, gbeta: 0.32, auroc: 0.91, auprc: 0.63 |\n",
      "Valid Loss: 0.224247, Acc: 0.93, F: 0.46, Fbeta: 0.50, gbeta: 0.29, auroc: 0.90, auprc: 0.62\n",
      " \n",
      "S8/600 139.56 min|\n",
      "Train Loss: 0.197816, Acc: 0.94, F: 0.52, Fbeta: 0.56, gbeta: 0.35, auroc: 0.92, auprc: 0.67 |\n",
      "Valid Loss: 0.210505, Acc: 0.94, F: 0.49, Fbeta: 0.52, gbeta: 0.31, auroc: 0.90, auprc: 0.63\n",
      " \n",
      "S8/800 140.34 min|\n",
      "Train Loss: 0.186302, Acc: 0.95, F: 0.56, Fbeta: 0.60, gbeta: 0.38, auroc: 0.93, auprc: 0.70 |\n",
      "Valid Loss: 0.203084, Acc: 0.94, F: 0.51, Fbeta: 0.54, gbeta: 0.33, auroc: 0.91, auprc: 0.64\n",
      " \n",
      "S8/1000 141.12 min|\n",
      "Train Loss: 0.178016, Acc: 0.95, F: 0.59, Fbeta: 0.62, gbeta: 0.40, auroc: 0.94, auprc: 0.72 |\n",
      "Valid Loss: 0.198556, Acc: 0.93, F: 0.52, Fbeta: 0.55, gbeta: 0.33, auroc: 0.91, auprc: 0.65\n",
      " \n",
      "S8/1200 141.89 min|\n",
      "Train Loss: 0.171596, Acc: 0.95, F: 0.61, Fbeta: 0.64, gbeta: 0.42, auroc: 0.94, auprc: 0.74 |\n",
      "Valid Loss: 0.195575, Acc: 0.94, F: 0.53, Fbeta: 0.56, gbeta: 0.34, auroc: 0.91, auprc: 0.65\n",
      " \n",
      "S8/1400 142.66 min|\n",
      "Train Loss: 0.166320, Acc: 0.95, F: 0.63, Fbeta: 0.66, gbeta: 0.44, auroc: 0.95, auprc: 0.75 |\n",
      "Valid Loss: 0.193435, Acc: 0.94, F: 0.55, Fbeta: 0.58, gbeta: 0.35, auroc: 0.91, auprc: 0.66\n",
      " \n",
      "S8/1600 143.44 min|\n",
      "Train Loss: 0.161977, Acc: 0.95, F: 0.64, Fbeta: 0.68, gbeta: 0.45, auroc: 0.95, auprc: 0.76 |\n",
      "Valid Loss: 0.191889, Acc: 0.94, F: 0.55, Fbeta: 0.59, gbeta: 0.36, auroc: 0.91, auprc: 0.66\n",
      " \n",
      "S8/1800 144.21 min|\n",
      "Train Loss: 0.158348, Acc: 0.95, F: 0.66, Fbeta: 0.70, gbeta: 0.46, auroc: 0.95, auprc: 0.77 |\n",
      "Valid Loss: 0.190761, Acc: 0.94, F: 0.57, Fbeta: 0.61, gbeta: 0.37, auroc: 0.91, auprc: 0.67\n",
      " \n",
      "S8/2000 144.98 min|\n",
      "Train Loss: 0.155233, Acc: 0.95, F: 0.67, Fbeta: 0.71, gbeta: 0.47, auroc: 0.95, auprc: 0.78 |\n",
      "Valid Loss: 0.189966, Acc: 0.94, F: 0.57, Fbeta: 0.61, gbeta: 0.37, auroc: 0.91, auprc: 0.66\n",
      " \n",
      "S8/2200 145.75 min|\n",
      "Train Loss: 0.152509, Acc: 0.95, F: 0.67, Fbeta: 0.71, gbeta: 0.47, auroc: 0.95, auprc: 0.79 |\n",
      "Valid Loss: 0.189373, Acc: 0.94, F: 0.57, Fbeta: 0.60, gbeta: 0.36, auroc: 0.92, auprc: 0.66\n",
      " \n",
      "S8/2400 146.52 min|\n",
      "Train Loss: 0.150111, Acc: 0.95, F: 0.67, Fbeta: 0.72, gbeta: 0.47, auroc: 0.96, auprc: 0.79 |\n",
      "Valid Loss: 0.188905, Acc: 0.94, F: 0.56, Fbeta: 0.60, gbeta: 0.36, auroc: 0.92, auprc: 0.66\n",
      " \n",
      "S8/2600 147.29 min|\n",
      "Train Loss: 0.147989, Acc: 0.96, F: 0.68, Fbeta: 0.72, gbeta: 0.48, auroc: 0.96, auprc: 0.80 |\n",
      "Valid Loss: 0.188511, Acc: 0.94, F: 0.56, Fbeta: 0.60, gbeta: 0.36, auroc: 0.91, auprc: 0.66\n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S8/2800 148.07 min|\n",
      "Train Loss: 0.146096, Acc: 0.96, F: 0.69, Fbeta: 0.73, gbeta: 0.48, auroc: 0.96, auprc: 0.80 |\n",
      "Valid Loss: 0.188222, Acc: 0.94, F: 0.57, Fbeta: 0.61, gbeta: 0.37, auroc: 0.92, auprc: 0.67\n",
      " \n",
      "S8/3000 148.84 min|\n",
      "Train Loss: 0.144397, Acc: 0.96, F: 0.70, Fbeta: 0.74, gbeta: 0.49, auroc: 0.96, auprc: 0.81 |\n",
      "Valid Loss: 0.188017, Acc: 0.94, F: 0.57, Fbeta: 0.60, gbeta: 0.36, auroc: 0.91, auprc: 0.66\n",
      " \n",
      "S8/3200 149.61 min|\n",
      "Train Loss: 0.142865, Acc: 0.96, F: 0.69, Fbeta: 0.73, gbeta: 0.49, auroc: 0.96, auprc: 0.81 |\n",
      "Valid Loss: 0.187858, Acc: 0.94, F: 0.56, Fbeta: 0.60, gbeta: 0.36, auroc: 0.91, auprc: 0.66\n",
      " \n",
      "S8/3400 150.38 min|\n",
      "Train Loss: 0.141471, Acc: 0.96, F: 0.69, Fbeta: 0.73, gbeta: 0.48, auroc: 0.96, auprc: 0.81 |\n",
      "Valid Loss: 0.187737, Acc: 0.94, F: 0.56, Fbeta: 0.59, gbeta: 0.36, auroc: 0.91, auprc: 0.66\n",
      " \n",
      "S8/3600 151.15 min|\n",
      "Train Loss: 0.140095, Acc: 0.96, F: 0.70, Fbeta: 0.74, gbeta: 0.50, auroc: 0.96, auprc: 0.82 |\n",
      "Valid Loss: 0.187612, Acc: 0.94, F: 0.57, Fbeta: 0.61, gbeta: 0.37, auroc: 0.91, auprc: 0.66\n",
      " \n",
      "S8/3800 151.92 min|\n",
      "Train Loss: 0.138782, Acc: 0.96, F: 0.71, Fbeta: 0.75, gbeta: 0.50, auroc: 0.96, auprc: 0.82 |\n",
      "Valid Loss: 0.187482, Acc: 0.94, F: 0.58, Fbeta: 0.62, gbeta: 0.37, auroc: 0.92, auprc: 0.67\n",
      " \n",
      "S8/4000 152.69 min|\n",
      "Train Loss: 0.137549, Acc: 0.96, F: 0.71, Fbeta: 0.75, gbeta: 0.51, auroc: 0.96, auprc: 0.82 |\n",
      "Valid Loss: 0.187354, Acc: 0.94, F: 0.57, Fbeta: 0.61, gbeta: 0.37, auroc: 0.92, auprc: 0.67\n",
      " \n",
      "S8/4200 153.46 min|\n",
      "Train Loss: 0.136391, Acc: 0.96, F: 0.71, Fbeta: 0.75, gbeta: 0.51, auroc: 0.96, auprc: 0.83 |\n",
      "Valid Loss: 0.187242, Acc: 0.94, F: 0.58, Fbeta: 0.62, gbeta: 0.37, auroc: 0.92, auprc: 0.67\n",
      " \n",
      "S8/4400 154.23 min|\n",
      "Train Loss: 0.135263, Acc: 0.96, F: 0.72, Fbeta: 0.76, gbeta: 0.52, auroc: 0.97, auprc: 0.83 |\n",
      "Valid Loss: 0.187133, Acc: 0.93, F: 0.58, Fbeta: 0.61, gbeta: 0.37, auroc: 0.92, auprc: 0.66\n",
      " \n",
      "S8/4600 155.00 min|\n",
      "Train Loss: 0.134175, Acc: 0.96, F: 0.72, Fbeta: 0.76, gbeta: 0.52, auroc: 0.97, auprc: 0.83 |\n",
      "Valid Loss: 0.187049, Acc: 0.94, F: 0.59, Fbeta: 0.62, gbeta: 0.38, auroc: 0.92, auprc: 0.67\n",
      " \n",
      "S8/4800 155.78 min|\n",
      "Train Loss: 0.133149, Acc: 0.96, F: 0.72, Fbeta: 0.76, gbeta: 0.52, auroc: 0.97, auprc: 0.84 |\n",
      "Valid Loss: 0.186996, Acc: 0.94, F: 0.58, Fbeta: 0.62, gbeta: 0.37, auroc: 0.92, auprc: 0.66\n",
      " \n",
      "S8/5000 156.54 min|\n",
      "Train Loss: 0.132184, Acc: 0.96, F: 0.72, Fbeta: 0.76, gbeta: 0.52, auroc: 0.97, auprc: 0.84 |\n",
      "Valid Loss: 0.186969, Acc: 0.94, F: 0.58, Fbeta: 0.61, gbeta: 0.37, auroc: 0.92, auprc: 0.66\n",
      " \n",
      "S8/5200 157.31 min|\n",
      "Train Loss: 0.131280, Acc: 0.96, F: 0.73, Fbeta: 0.76, gbeta: 0.52, auroc: 0.97, auprc: 0.84 |\n",
      "Valid Loss: 0.186959, Acc: 0.94, F: 0.58, Fbeta: 0.62, gbeta: 0.37, auroc: 0.92, auprc: 0.66\n",
      " \n",
      "Early stopping\n",
      "AUROC|AUPRC|Accuracy|F-measure|Fbeta-measure|Gbeta-measure\n",
      "0.967|0.840|0.000|0.725|0.765|0.523\n",
      "S9/0 158.05 min|\n",
      "Train Loss: 0.687326, Acc: 0.55, F: 0.18, Fbeta: 0.09, gbeta: 0.05, auroc: 0.49, auprc: 0.11 |\n",
      "Valid Loss: 0.686243, Acc: 0.56, F: 0.18, Fbeta: 0.10, gbeta: 0.06, auroc: 0.51, auprc: 0.11\n",
      " \n",
      "S9/200 158.83 min|\n",
      "Train Loss: 0.255877, Acc: 0.93, F: 0.44, Fbeta: 0.47, gbeta: 0.28, auroc: 0.88, auprc: 0.57 |\n",
      "Valid Loss: 0.259167, Acc: 0.93, F: 0.39, Fbeta: 0.42, gbeta: 0.24, auroc: 0.87, auprc: 0.51\n",
      " \n",
      "S9/400 159.61 min|\n",
      "Train Loss: 0.214217, Acc: 0.94, F: 0.52, Fbeta: 0.55, gbeta: 0.35, auroc: 0.91, auprc: 0.66 |\n",
      "Valid Loss: 0.225708, Acc: 0.93, F: 0.47, Fbeta: 0.49, gbeta: 0.29, auroc: 0.89, auprc: 0.56\n",
      " \n",
      "S9/600 160.39 min|\n",
      "Train Loss: 0.195575, Acc: 0.94, F: 0.55, Fbeta: 0.58, gbeta: 0.38, auroc: 0.92, auprc: 0.69 |\n",
      "Valid Loss: 0.212544, Acc: 0.93, F: 0.48, Fbeta: 0.51, gbeta: 0.30, auroc: 0.90, auprc: 0.59\n",
      " \n",
      "S9/800 161.17 min|\n",
      "Train Loss: 0.184025, Acc: 0.95, F: 0.56, Fbeta: 0.59, gbeta: 0.40, auroc: 0.93, auprc: 0.70 |\n",
      "Valid Loss: 0.205551, Acc: 0.93, F: 0.48, Fbeta: 0.50, gbeta: 0.31, auroc: 0.90, auprc: 0.58\n",
      " \n",
      "S9/1000 161.94 min|\n",
      "Train Loss: 0.175585, Acc: 0.95, F: 0.62, Fbeta: 0.66, gbeta: 0.43, auroc: 0.94, auprc: 0.75 |\n",
      "Valid Loss: 0.201375, Acc: 0.93, F: 0.52, Fbeta: 0.55, gbeta: 0.32, auroc: 0.90, auprc: 0.59\n",
      " \n",
      "S9/1200 162.72 min|\n",
      "Train Loss: 0.168853, Acc: 0.95, F: 0.64, Fbeta: 0.68, gbeta: 0.44, auroc: 0.95, auprc: 0.77 |\n",
      "Valid Loss: 0.198987, Acc: 0.93, F: 0.51, Fbeta: 0.55, gbeta: 0.32, auroc: 0.90, auprc: 0.60\n",
      " \n",
      "S9/1400 163.49 min|\n",
      "Train Loss: 0.163504, Acc: 0.95, F: 0.65, Fbeta: 0.70, gbeta: 0.45, auroc: 0.95, auprc: 0.78 |\n",
      "Valid Loss: 0.197457, Acc: 0.93, F: 0.53, Fbeta: 0.56, gbeta: 0.33, auroc: 0.90, auprc: 0.60\n",
      " \n",
      "S9/1600 164.26 min|\n",
      "Train Loss: 0.159165, Acc: 0.95, F: 0.66, Fbeta: 0.71, gbeta: 0.46, auroc: 0.95, auprc: 0.79 |\n",
      "Valid Loss: 0.196472, Acc: 0.93, F: 0.52, Fbeta: 0.56, gbeta: 0.33, auroc: 0.90, auprc: 0.60\n",
      " \n",
      "S9/1800 165.03 min|\n",
      "Train Loss: 0.155553, Acc: 0.95, F: 0.68, Fbeta: 0.72, gbeta: 0.47, auroc: 0.95, auprc: 0.79 |\n",
      "Valid Loss: 0.195835, Acc: 0.93, F: 0.52, Fbeta: 0.56, gbeta: 0.33, auroc: 0.90, auprc: 0.59\n",
      " \n",
      "S9/2000 165.81 min|\n",
      "Train Loss: 0.152422, Acc: 0.96, F: 0.68, Fbeta: 0.73, gbeta: 0.48, auroc: 0.96, auprc: 0.80 |\n",
      "Valid Loss: 0.195361, Acc: 0.93, F: 0.53, Fbeta: 0.56, gbeta: 0.33, auroc: 0.90, auprc: 0.61\n",
      " \n",
      "S9/2200 166.58 min|\n",
      "Train Loss: 0.149414, Acc: 0.96, F: 0.70, Fbeta: 0.74, gbeta: 0.49, auroc: 0.96, auprc: 0.81 |\n",
      "Valid Loss: 0.194905, Acc: 0.93, F: 0.54, Fbeta: 0.58, gbeta: 0.34, auroc: 0.91, auprc: 0.62\n",
      " \n",
      "S9/2400 167.35 min|\n",
      "Train Loss: 0.146707, Acc: 0.96, F: 0.71, Fbeta: 0.75, gbeta: 0.50, auroc: 0.96, auprc: 0.82 |\n",
      "Valid Loss: 0.194558, Acc: 0.93, F: 0.55, Fbeta: 0.58, gbeta: 0.34, auroc: 0.91, auprc: 0.61\n",
      " \n",
      "S9/2600 168.12 min|\n",
      "Train Loss: 0.144296, Acc: 0.96, F: 0.71, Fbeta: 0.75, gbeta: 0.51, auroc: 0.96, auprc: 0.82 |\n",
      "Valid Loss: 0.194309, Acc: 0.93, F: 0.55, Fbeta: 0.58, gbeta: 0.34, auroc: 0.91, auprc: 0.61\n",
      " \n",
      "S9/2800 168.89 min|\n",
      "Train Loss: 0.142146, Acc: 0.96, F: 0.71, Fbeta: 0.75, gbeta: 0.51, auroc: 0.96, auprc: 0.83 |\n",
      "Valid Loss: 0.194184, Acc: 0.93, F: 0.54, Fbeta: 0.57, gbeta: 0.33, auroc: 0.91, auprc: 0.61\n",
      " \n",
      "S9/3000 169.66 min|\n",
      "Train Loss: 0.140204, Acc: 0.96, F: 0.72, Fbeta: 0.76, gbeta: 0.51, auroc: 0.96, auprc: 0.83 |\n",
      "Valid Loss: 0.194157, Acc: 0.93, F: 0.54, Fbeta: 0.58, gbeta: 0.34, auroc: 0.90, auprc: 0.61\n",
      " \n",
      "Early stopping\n",
      "AUROC|AUPRC|Accuracy|F-measure|Fbeta-measure|Gbeta-measure\n",
      "0.963|0.829|0.000|0.715|0.757|0.511\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
    "from evaluate_12ECG_score import compute_beta_score, compute_auc\n",
    "\n",
    "# def evaluate_beta(output, y):\n",
    "    \n",
    "#     accuracy,f_measure,f_beta,g_beta = compute_beta_score(labels=y, \n",
    "#                        output=output, \n",
    "#                        beta=2, num_classes=1)\n",
    "    \n",
    "#     auroc, auprc = compute_auc(labels=y, \n",
    "#                                 probabilities=output,\n",
    "#                                 num_classes=1)\n",
    "\n",
    "#     return accuracy,f_measure,f_beta,g_beta, auroc, auprc\n",
    "\n",
    "\n",
    "def confusion(prediction, truth):\n",
    "    \n",
    "    \"\"\" Returns the confusion matrix for the values in the `prediction` and `truth`\n",
    "    tensors, i.e. the amount of positions where the values of `prediction`\n",
    "    and `truth` are\n",
    "    - 1 and 1 (True Positive)\n",
    "    - 1 and 0 (False Positive)\n",
    "    - 0 and 0 (True Negative)\n",
    "    - 0 and 1 (False Negative)\n",
    "    https://gist.github.com/the-bass/cae9f3976866776dea17a5049013258d\n",
    "    \"\"\"\n",
    "\n",
    "    confusion_vector = prediction / truth\n",
    "    # Element-wise division of the 2 tensors returns a new tensor which holds a\n",
    "    # unique value for each case:\n",
    "    #   1     where prediction and truth are 1 (True Positive)\n",
    "    #   inf   where prediction is 1 and truth is 0 (False Positive)\n",
    "    #   nan   where prediction and truth are 0 (True Negative)\n",
    "    #   0     where prediction is 0 and truth is 1 (False Negative)\n",
    "\n",
    "    true_positives = torch.sum(confusion_vector == 1).item()\n",
    "    false_positives = torch.sum(confusion_vector == float('inf')).item()\n",
    "    true_negatives = torch.sum(torch.isnan(confusion_vector)).item()\n",
    "    false_negatives = torch.sum(confusion_vector == 0).item()\n",
    "\n",
    "    return true_positives, false_positives, true_negatives, false_negatives\n",
    "\n",
    "def binary_acc(y_preds, y_tests, beta=2):\n",
    "    accs = []\n",
    "    fmeasures = []\n",
    "    fbetas = []\n",
    "    gbetas = []\n",
    "    aurocs = []\n",
    "    auprcs = []\n",
    "    for i in range(9):\n",
    "        y_pred, y_test = y_preds[:,i], y_tests[:,i]\n",
    "        \n",
    "        # prob\n",
    "        y_pred_prob = torch.sigmoid(y_pred)\n",
    "        \n",
    "        # auroc\n",
    "        y_test_numpy = y_test.data.cpu().numpy()\n",
    "        y_pred_prob_numpy = y_pred_prob.data.cpu().numpy()\n",
    "        auroc = roc_auc_score(y_test_numpy, y_pred_prob_numpy)\n",
    "        \n",
    "        # auprc\n",
    "        precision, recall, thresholds = precision_recall_curve(y_test_numpy, y_pred_prob_numpy)\n",
    "        auprc = auc(recall, precision)\n",
    "\n",
    "        # binary result\n",
    "        y_pred_tag = torch.round(y_pred_prob)\n",
    "        tp, fp, tn, fn = confusion(y_pred_tag, y_test)\n",
    "        \n",
    "        # acc, fmeasure, fbeta, gbeta\n",
    "        acc = float(tp + tn) / float(tp + fp + fn + tn)\n",
    "        fmeasure = float(2 * tp) / float(2 * tp + fp + fn)\n",
    "        fbeta = float((1+beta**2)* tp) / float(((1+beta**2)*tp) + (fn*beta**2) + fp)\n",
    "        gbeta = float(tp) / float(tp + fp + beta*fn)\n",
    "        \n",
    "        # old way to cal acc:\n",
    "        #correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "        #acc = true_positives/y_test.shape[0]\n",
    "        #acc = torch.round(acc * 100)\n",
    "\n",
    "        accs.append(acc)#.data.cpu().numpy())\n",
    "        fbetas.append(fbeta)#.data.cpu().numpy())\n",
    "        fmeasures.append(fmeasure)\n",
    "        gbetas.append(gbeta)\n",
    "        aurocs.append(auroc)\n",
    "        auprcs.append(auprc)\n",
    "    return np.mean(accs), np.mean(fbetas), np.mean(fmeasures), np.mean(gbetas), np.mean(aurocs), np.mean(auprcs)\n",
    "\n",
    "from snippets.pytorchtools import EarlyStopping\n",
    "from sklearn.model_selection import KFold\n",
    "import time\n",
    "\n",
    "st = time.time()\n",
    "patience = 200\n",
    "kf = KFold(10)\n",
    "\n",
    "saved_dir = '../saved/model/'\n",
    "for i, (train_idx, test_idx) in enumerate(kf.split(X, y)):\n",
    "    model = SimpleNet(250, 250, 10, 10).to(device)\n",
    "    learning_rate = 0.01\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    losses_train = []\n",
    "    losses_test = []\n",
    "\n",
    "    avg_losses_train = []\n",
    "    avg_losses_test = []\n",
    "\n",
    "\n",
    "    early_stopping = EarlyStopping(patience, verbose=False, \n",
    "                                  saved_dir=saved_dir, \n",
    "                                   save_name='SimpleNet'+str(i))\n",
    "    epoch = 0\n",
    "    auroc = 0\n",
    "    auprc = 0\n",
    "    accuracy = 0\n",
    "    fmeasure = 0\n",
    "    fbeta = 0\n",
    "    gbeta = 0\n",
    "    for epoch in range(10000):\n",
    "        train_loss = 0\n",
    "        validation_loss = 0\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output_train = model(X[train_idx])\n",
    "        output_test = model(X[test_idx])\n",
    "\n",
    "        loss_train = criterion(output_train, y[train_idx])\n",
    "        loss_test = criterion(output_test, y[test_idx])\n",
    "\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses_train.append(loss_train.item())\n",
    "        losses_test.append(loss_test.item())\n",
    "\n",
    "        avg_loss_train = np.average(losses_train)\n",
    "        avg_loss_test = np.average(losses_test)\n",
    "\n",
    "        avg_losses_train.append(avg_loss_train)\n",
    "        avg_losses_test.append(avg_loss_test)\n",
    "\n",
    "        if epoch % 200 == 0:\n",
    "            acc, fmeasure, fbeta, gbeta, auroc, auprc = binary_acc(output_train, y[train_idx])\n",
    "            acc2, fmeasure2, fbeta2, gbeta2, auroc2, auprc2 = binary_acc(output_test, y[test_idx])\n",
    "            #accuracy_p = ' '.join(['{:.2f},'.format(acc)for acc in accuracy])\n",
    "            #accuracy2_p = ' '.join(['{:.2f},'.format(acc)for acc in accuracy2])\n",
    "            print('S{}/{} {:.2f} min|\\nTrain Loss: {:.6f}, Acc: {:.2f}, F: {:.2f}, Fbeta: {:.2f}, gbeta: {:.2f}, auroc: {:.2f}, auprc: {:.2f} |\\nValid Loss: {:.6f}, Acc: {:.2f}, F: {:.2f}, Fbeta: {:.2f}, gbeta: {:.2f}, auroc: {:.2f}, auprc: {:.2f}\\n '.format(\n",
    "                i, epoch, (time.time()-st)/60,\n",
    "                avg_loss_train, acc, fmeasure, fbeta, gbeta, auroc, auprc, \n",
    "                avg_loss_test, acc2, fmeasure2, fbeta2, gbeta2, auroc2, auprc2))\n",
    "\n",
    "        early_stopping(avg_loss_test, model)\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "            \n",
    "    output_string = 'AUROC|AUPRC|Accuracy|F-measure|Fbeta-measure|Gbeta-measure\\n{:.3f}|{:.3f}|{:.3f}|{:.3f}|{:.3f}|{:.3f}'.format(auroc,auprc,acc,fmeasure,fbeta,gbeta)\n",
    "    print(output_string)     \n",
    "    with open(saved_dir+'score'+ str(i)+ '_epoch' + str(epoch) + '.txt', 'w') as f:\n",
    "        f.write(output_string)\n",
    "\n",
    "    avg_losses_train = np.array(avg_losses_train)\n",
    "    avg_losses_test = np.array(avg_losses_test)\n",
    "    \n",
    "    np.save(saved_dir + 'avg_losses_train' + str(i) + '_epoch' + str(epoch), avg_losses_train)\n",
    "    np.save(saved_dir + 'avg_losses_test' + str(i) + '_epoch' + str(epoch), avg_losses_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (physioNet)",
   "language": "python",
   "name": "physionet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
