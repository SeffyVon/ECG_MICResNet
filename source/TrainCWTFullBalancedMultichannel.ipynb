{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import torch, torchvision \n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_infos2 = pd.read_csv('../saved/infos2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52a45aaf5f74485ead10325d3538e853",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='0', max=53194.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bf2865ac0f645d98434f08c76022ecc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='1', max=53194.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ab4e97153374fbd80b79fd15af37a74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='2', max=53194.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d431b59df53b41b89e24431929931600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='3', max=53194.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b202a6e417145e2970a85917c4dd62f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='4', max=53194.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab9d92c25d56464382d53a1f86ac930c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='5', max=53194.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aabda9879e99467ea13958481795ca9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='6', max=53194.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac7b5bf4cb2d4d6bbcd1c383c4a92183",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='7', max=53194.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b360f0badeb246308e263a3d1740e684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='8', max=53194.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a582f64380440cd89ec910480ed9a80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='9', max=53194.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def import_chn_imgs(chn):\n",
    "    st = time.time()\n",
    "    data_imgs = []\n",
    "    \n",
    "    #This line is the strange hack\n",
    "    print(' ', end='', flush=True)\n",
    "    \n",
    "    for i in tqdm(range(len(df_infos2)), desc=str(chn), mininterval=1): #   \n",
    "        with Image.open('../saved/channel_imgs/{}/'.format(chn)+'/'+str(i)+'.png') as img:\n",
    "            data_imgs.append(img.copy())\n",
    "    return data_imgs\n",
    "\n",
    "import time\n",
    "st = time.time()\n",
    "\n",
    "chn_imgs = [import_chn_imgs(chn) for chn in range(12)]\n",
    "\n",
    "print(\"Time passed:\", int(time.time()-st), \"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(chn_imgs[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from global_vars import labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import os\n",
    "class MyImageMultichannelDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, infos, channel_imgs):\n",
    "        \"\"\"\n",
    "                \n",
    "        channel_imgs = chn -> array of PImage\n",
    "        \"\"\"\n",
    "        self.infos = infos\n",
    "        self.channel_imgs = channel_imgs\n",
    "        self.transform =  transforms.Compose([\n",
    "                         transforms.ToTensor(),\n",
    "                         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                         ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.infos)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        images = [self.channel_imgs[i][idx] for i in range(12)]\n",
    "        info_labels = self.infos.iloc[idx][labels]\n",
    "        sample =([self.transform(image) for image in images], torch.Tensor(info_labels.astype(int)))\n",
    "\n",
    "        return sample\n",
    "    \n",
    "image_datasets = MyImageMultichannelDataset(df_infos2, chn_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(chn_imgs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs0, label0 = image_datasets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloaders = torch.utils.data.DataLoader(image_datasets, batch_size=4,\n",
    "#                                              shuffle=True, num_workers=4)\n",
    "# dataset_sizes = len(image_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torchvision import models\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "def load_cwt_nn_model(device, model_saved_path='../saved/modelCWTFullBalanced/CWTNetFull0_model.dict', \n",
    "                      freeze=True):\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, 9)\n",
    "    model.load_state_dict(torch.load(model_saved_path, map_location=device))\n",
    "    \n",
    "    if freeze:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "    # change the last output to 9 classes\n",
    "    model.fc = nn.Linear(num_ftrs, 1000)\n",
    "    \n",
    "    # load saved model\n",
    "    \n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n",
    "class MultiCWTNet(nn.Module):\n",
    "    def __init__(self, device, verbose=False):\n",
    "        super(MultiCWTNet, self).__init__()\n",
    "        \n",
    "        self.chn_resnets = [load_cwt_nn_model(device) for i in range(12)]\n",
    "        num_ftrs = self.chn_resnets[0].fc.out_features\n",
    "        self.fc1 = nn.Linear(num_ftrs*12, 9)\n",
    "        self.fc2 = nn.Linear(9, 9)\n",
    "        self.verbose = verbose\n",
    "        \n",
    "    def forward(self, xs):\n",
    "        x = [self.chn_resnets[i](xs[i]) for i in range(12)]\n",
    "        \n",
    "        x = torch.cat(x, 1)\n",
    "        if self.verbose:\n",
    "            print('0: ', x.shape, x.device)\n",
    "            \n",
    "        x = self.fc1(x)\n",
    "        if self.verbose:\n",
    "            print('2: ', x.shape)\n",
    "            \n",
    "        x = F.relu(   x )     \n",
    "        if self.verbose:\n",
    "            print('3: ', x.shape)\n",
    "            \n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        if self.verbose:\n",
    "            print('4: ', x.shape)\n",
    "        return x\n",
    "\n",
    "# model = MultiCWTNet(device, verbose=True)\n",
    "# model.to(device)\n",
    "# for X,y in dataloaders:\n",
    "#     xs = [x.to(device) for x in X]\n",
    "#     model.forward(xs)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def make_weights_for_balanced_classes(ys, weight_per_class):                                                                                          \n",
    "#     weight = [0] * len(ys)                                              \n",
    "#     for idx, y in enumerate(ys):    \n",
    "#         for i, val in enumerate(y):\n",
    "#             weight[idx] += weight_per_class[i]                           \n",
    "#     return weight  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, models, transforms\n",
    "from myeval import binary_acc\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from snippets.pytorchtools import EarlyStopping\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import time\n",
    "\n",
    "st = time.time()\n",
    "patience = 20\n",
    "kf = GroupKFold(10)\n",
    "batch_size=20\n",
    "\n",
    "saved_dir = '../saved/modelMultiCWTFull'\n",
    "y = df_infos2[labels].astype(int)\n",
    "\n",
    "for i, (train_idx, test_idx) in enumerate(kf.split(df_infos2, y, df_infos2['ptID'])):\n",
    "    \n",
    "    \n",
    "#     df_y_train = df_infos2.iloc[train_idx][labels].to_numpy().astype(int)\n",
    "#     weights = make_weights_for_balanced_classes(df_y_train, 1.0/np.sum(df_y_train,axis=0))\n",
    "\n",
    "#     per_weights = torch.Tensor(weights).to(device)\n",
    "    #sampler = torch.utils.data.sampler.WeightedRandomSampler(per_weights, len(train_idx))\n",
    "\n",
    "    trainDataset = torch.utils.data.Subset(image_datasets, train_idx)\n",
    "    testDataset = torch.utils.data.Subset(image_datasets, test_idx)\n",
    "    \n",
    "    trainLoader = torch.utils.data.DataLoader(trainDataset, batch_size=batch_size, shuffle = True, pin_memory=True)#sampler = sampler)\n",
    "    testLoader = torch.utils.data.DataLoader(testDataset, batch_size = batch_size, shuffle = False, pin_memory=True)\n",
    "\n",
    "    model = MultiCWTNet(device, verbose=False)\n",
    "    model.to(device)\n",
    "    \n",
    "    \n",
    "    # load saved model\n",
    "#     model_saved_path = saved_dir + 'CWTNetFull0_model.dict'\n",
    "#     model.load_state_dict(torch.load(model_saved_path))\n",
    "    \n",
    "\n",
    "    \n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9) #\n",
    "    # Decay LR by a factor of 0.1 every 100 epochs\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    \n",
    "    class_weights = np.ones(9) * 2\n",
    "    class_weights = torch.Tensor(class_weights).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=class_weights)\n",
    "\n",
    "    losses_train = []\n",
    "    losses_test = []\n",
    "\n",
    "    avg_losses_train = []\n",
    "    avg_losses_test = []\n",
    "\n",
    "\n",
    "    early_stopping = EarlyStopping(patience, verbose=False, \n",
    "                                  saved_dir=saved_dir, \n",
    "                                   save_name='MutliCWTNetFull'+str(i))\n",
    "    epoch = 0\n",
    "    auroc = 0\n",
    "    auprc = 0\n",
    "    accuracy = 0\n",
    "    fmeasure = 0\n",
    "    fbeta = 0\n",
    "    gbeta = 0\n",
    "    for epoch in range(1000):\n",
    "        \n",
    "        model.train()\n",
    "        output_trains = []\n",
    "        y_trains = []\n",
    "        for X_train, y_train in tqdm(trainLoader):\n",
    "            y_train = y_train.to(device)\n",
    "            X_train_chns = [x.to(device) for x in X_train]\n",
    "            optimizer.zero_grad()\n",
    "            output_train = model(X_train_chns)\n",
    "            \n",
    "            loss_train = criterion(output_train, y_train)\n",
    "            losses_train.append(loss_train.item())\n",
    "            loss_train.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            output_trains.append(output_train.cpu())\n",
    "            y_trains.append(y_train.cpu())\n",
    "\n",
    "        scheduler.step()\n",
    "        \n",
    "        avg_loss_train = np.average(losses_train)\n",
    "        avg_losses_train.append(avg_loss_train)\n",
    "        \n",
    "        output_tests = []\n",
    "        y_tests = []\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            \n",
    "            for X_test, y_test in testLoader:  \n",
    "                y_test = y_test.to(device)\n",
    "                X_test_chns = [x.to(device) for x in X_test]\n",
    "                output_test = model(X_test_chns)\n",
    "                \n",
    "                loss_test = criterion(output_test, y_test)\n",
    "                losses_test.append(loss_test.item())\n",
    "                \n",
    "                output_tests.append(output_test.cpu())\n",
    "                y_tests.append(y_test.cpu())\n",
    "                \n",
    "            avg_loss_test = np.average(losses_test)\n",
    "            avg_losses_test.append(avg_loss_test)\n",
    "\n",
    "       \n",
    "        \n",
    "        output_trains = torch.cat(output_trains, axis=0)\n",
    "        y_trains = torch.cat(y_trains, axis=0)\n",
    "        acc, fmeasure, fbeta, gbeta, auroc, auprc = binary_acc(output_trains, y_trains)\n",
    "\n",
    "        output_tests = torch.cat(output_tests, axis=0)\n",
    "        y_tests = torch.cat(y_tests, axis=0)\n",
    "        acc2, fmeasure2, fbeta2, gbeta2, auroc2, auprc2 = binary_acc(output_tests, y_tests)\n",
    "\n",
    "        print('S{}/{} {:.2f} min|\\nTrain Loss: {:.6f}, Acc: {:.3f}, F: {:.3f}, Fbeta: {:.3f}, gbeta: {:.3f}, auroc: {:.3f}, auprc: {:.3f} |\\nValid Loss: {:.6f}, Acc: {:.3f}, F: {:.3f}, Fbeta: {:.3f}, gbeta: {:.3f}, auroc: {:.3f}, auprc: {:.3f}\\n '.format(\n",
    "            i, epoch, (time.time()-st)/60,\n",
    "            avg_loss_train, acc, fmeasure, fbeta, gbeta, auroc, auprc, \n",
    "            avg_loss_test, acc2, fmeasure2, fbeta2, gbeta2, auroc2, auprc2))\n",
    "#         print('S{}/{} {:.2f} min|\\nTrain Loss: {:.6f} |Valid Loss: {:.6f} '.format(\n",
    "#              i, epoch, (time.time()-st)/60, avg_loss_train, avg_loss_test))\n",
    "\n",
    "        early_stopping(avg_loss_test, model)\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "            \n",
    "    output_string = 'AUROC|AUPRC|Accuracy|F-measure|Fbeta-measure|Gbeta-measure\\n{:.3f}|{:.3f}|{:.3f}|{:.3f}|{:.3f}|{:.3f}'.format(auroc2,auprc2,acc2,fmeasure2,fbeta2,gbeta2)\n",
    "    print(output_string)     \n",
    "    with open(saved_dir+'score'+ str(i)+ '_epoch' + str(epoch) + '.txt', 'w') as f:\n",
    "        f.write(output_string)\n",
    "\n",
    "    avg_losses_train = np.array(avg_losses_train)\n",
    "    avg_losses_test = np.array(avg_losses_test)\n",
    "    \n",
    "    np.save(saved_dir + 'avg_losses_train' + str(i) + '_epoch' + str(epoch), avg_losses_train)\n",
    "    np.save(saved_dir + 'avg_losses_test' + str(i) + '_epoch' + str(epoch), avg_losses_test)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
