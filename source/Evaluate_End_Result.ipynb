{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "from tqdm.notebook import tqdm\n",
    "import torch, torchvision \n",
    "from PIL import Image\n",
    "from global_vars import labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_infos2 = pd.read_csv('../saved/infos2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, models, transforms\n",
    "from myeval import binary_acc\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from snippets.pytorchtools import EarlyStopping\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import time\n",
    "from myeval import binary_acc_core\n",
    "\n",
    "kf = GroupKFold(5)\n",
    "it = kf.split(df_infos2, df_infos2[labels], df_infos2['ptID'])\n",
    "next(it)\n",
    "train_indices, test_indices = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "def load_cwt_nn_model(model_saved_path):\n",
    "    model = models.resnet50(pretrained=True)\n",
    "#     for param in model.parameters():\n",
    "#         param.requires_grad = False\n",
    "    \n",
    "    num_ftrs = model.fc.in_features\n",
    "    # change the last output to 9 classes\n",
    "    model.fc = nn.Linear(num_ftrs, 9)\n",
    "    \n",
    "    # load saved model\n",
    "    model.load_state_dict(torch.load(model_saved_path, map_location=torch.device('cpu')))\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from myeval import agg_y_preds, binary_acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# out type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_imgs = []\n",
    "# for i in tqdm(range(len(df_infos2))):\n",
    "#     with Image.open('../saved/channel_imgs/0/'+str(i)+'.png') as img:\n",
    "#         data_imgs.append(img.copy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle as pkl\n",
    "\n",
    "# with open('../saved/channel_imgs0.pkg', 'wb') as f:\n",
    "#     pickle.dump(data_imgs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0958879590034485 min\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "st = time.time()\n",
    "with open('../saved/channel_imgs0.pkg', 'rb') as f:\n",
    "    data_imgs = pickle.load(f)\n",
    "    \n",
    "print((time.time()-st)/60, 'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "class MyImageDatasetEvaluate(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, data_imgs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.data_imgs = data_imgs\n",
    "        self.transform =  transforms.Compose([\n",
    "                         transforms.ToTensor(),\n",
    "                         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                         ])\n",
    "    def __len__(self):\n",
    "        return len(self.data_imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        image = self.data_imgs[idx]\n",
    "        sample = self.transform(image)\n",
    "        return sample\n",
    "    \n",
    "image_datasets = MyImageDatasetEvaluate(data_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_12ECG_classifier(data_imgs,model):\n",
    "    # Use your classifier here to obtain a label and score for each class. \n",
    "    \n",
    "    fDatas = []\n",
    "    #infos =[]\n",
    "    fData = filter_data(data[:,1000:], highcut=50.0)\n",
    "    #fData = datas[idx][:,1000:]\n",
    "    intervals = sep_rr_interval(fData[:3], height=0.2, distance=200, plot=False)\n",
    "\n",
    "    # basic info\n",
    "    #info = get_basic_info(header_datas[idx], labels)\n",
    "    \n",
    "    # get data\n",
    "    #ptID = info[0]\n",
    "    #print(str(idx) + ' ' + ptID)\n",
    "    for i in range(len(intervals)):\n",
    "        l, r = intervals[i]\n",
    "        fDatas.append(fData[:,l:r])\n",
    "        #infos.append(info)\n",
    "            \n",
    "    fDataRes=np.array([signal.resample(fData, 250, axis=1) for fData in fDatas])\n",
    "    fDataReNorms=np.array([normalize(fDataRe) for fDataRe in fDataRes])\n",
    "    \n",
    "    X = torch.FloatTensor(fDataReNorms)\n",
    "    \n",
    "    try:\n",
    "        output = model(X)\n",
    "        current_score = np.mean(torch.sigmoid(output).data.numpy(), axis=0)\n",
    "        current_label = np.rint(current_score).astype(int)\n",
    "   # print(current_score.shape, current_label.shape)\n",
    "    except:\n",
    "        print(fDataRes, header_data)\n",
    "        current_label = np.zeros((9,), dtype=int)\n",
    "        current_score = np.zeros((9,))\n",
    "    return current_label, current_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_cwt_nn_model('../saved/modelCWTFullWeightedLoss/modelCWTFull1_model.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform =  transforms.Compose([\n",
    "                         transforms.ToTensor(),\n",
    "                         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a5f91507a4a441987bb1f84a8bbd408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1375.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "y_trues = []\n",
    "y_prob_maxs = []\n",
    "y_prob_means = []\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for _, test_patient_indices in tqdm(df_infos2.iloc[test_indices].groupby('ptID').indices.items()):\n",
    "        y_true = df_infos2.iloc[test_patient_indices[0]][labels]\n",
    "        y_trues.append(y_true)\n",
    "    \n",
    "        imgs_tensor = torch.stack([transform(data_imgs[idx]) for idx in test_patient_indices])\n",
    "        output = model(imgs_tensor)\n",
    "        y_prob_max, y_prob_mean = agg_y_preds(output)\n",
    "\n",
    "        y_prob_maxs.append(y_prob_max)\n",
    "        y_prob_means.append(y_prob_mean)\n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full\n",
    "\n",
    "'../saved/modelCWTFullWeightedLoss/modelCWTNetFull0_model.dict'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC|AUPRC|Accuracy|F-measure|Fbeta-measure|Gbeta-measure\n",
      "0.119|0.377|0.207|0.119|0.912|0.512\n"
     ]
    }
   ],
   "source": [
    "auroc,auprc,acc,fmeasure,fbeta,gbeta = binary_acc(torch.stack(y_prob_maxs), torch.Tensor(y_trues))\n",
    "output_string = 'AUROC|AUPRC|Accuracy|F-measure|Fbeta-measure|Gbeta-measure\\n{:.3f}|{:.3f}|{:.3f}|{:.3f}|{:.3f}|{:.3f}'.format(auroc,auprc,acc,fmeasure,fbeta,gbeta)\n",
    "print(output_string) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC|AUPRC|Accuracy|F-measure|Fbeta-measure|Gbeta-measure\n",
      "0.119|0.377|0.207|0.119|0.918|0.647\n"
     ]
    }
   ],
   "source": [
    "auroc,auprc,acc,fmeasure,fbeta,gbeta = binary_acc(torch.stack(y_prob_means), torch.Tensor(y_trues))\n",
    "output_string = 'AUROC|AUPRC|Accuracy|F-measure|Fbeta-measure|Gbeta-measure\\n{:.3f}|{:.3f}|{:.3f}|{:.3f}|{:.3f}|{:.3f}'.format(auroc,auprc,acc,fmeasure,fbeta,gbeta)\n",
    "print(output_string) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampler\n",
    "\n",
    "'../saved/modelCWTFullBalancedWeightedLoss/modelCWTFull0_model.dict'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC|AUPRC|Accuracy|F-measure|Fbeta-measure|Gbeta-measure\n",
      "0.120|0.381|0.209|0.120|0.914|0.547\n"
     ]
    }
   ],
   "source": [
    "auroc,auprc,acc,fmeasure,fbeta,gbeta = binary_acc(torch.stack(y_prob_maxs), torch.Tensor(y_trues))\n",
    "output_string = 'AUROC|AUPRC|Accuracy|F-measure|Fbeta-measure|Gbeta-measure\\n{:.3f}|{:.3f}|{:.3f}|{:.3f}|{:.3f}|{:.3f}'.format(auroc,auprc,acc,fmeasure,fbeta,gbeta)\n",
    "print(output_string) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC|AUPRC|Accuracy|F-measure|Fbeta-measure|Gbeta-measure\n",
      "0.120|0.381|0.209|0.120|0.919|0.665\n"
     ]
    }
   ],
   "source": [
    "auroc,auprc,acc,fmeasure,fbeta,gbeta = binary_acc(torch.stack(y_prob_means), torch.Tensor(y_trues))\n",
    "output_string = 'AUROC|AUPRC|Accuracy|F-measure|Fbeta-measure|Gbeta-measure\\n{:.3f}|{:.3f}|{:.3f}|{:.3f}|{:.3f}|{:.3f}'.format(auroc,auprc,acc,fmeasure,fbeta,gbeta)\n",
    "print(output_string) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use drive format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_infos3 = pd.read_csv('../saved/infos3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('fold0ptIDs.npy', np.unique(df_infos3.iloc[test_indices]['ptID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold0ptIDs = np.load('fold0ptIDs.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A0003', 'A0013', 'A0014', ..., 'A6873', 'A6874', 'A6875'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold0ptIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../saved/datas.pkl', 'rb') as f:\n",
    "    datas = pickle.load(f)\n",
    "with open('../saved/header_datas.pkl', 'rb') as f:\n",
    "    header_datas = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "def cwt(signals,name='', chn=6, wavelet_type = 'morl', vis=False):\n",
    "    #print(signals.shape)\n",
    "    # signals: channels x time\n",
    "    num_steps = signals.shape[1]\n",
    "    x = np.arange(num_steps) * 0.002\n",
    "    delta_t = x[1] - x[0] # 500Hz 0.02s\n",
    "    #print(delta_t)\n",
    "    #Freq (5, 100)\n",
    "    if wavelet_type == 'morl':\n",
    "        scales = np.linspace(8,200,100)\n",
    "    elif wavelet_type == 'mexh':\n",
    "        scales = np.linspace(5,50,100)\n",
    "    elif wavelet_type == 'gaus8':\n",
    "        scales = np.linspace(12,120,100)\n",
    "    else: # cmor\n",
    "        scales = np.linspace(12,120,100)\n",
    "    \n",
    "\n",
    "    coef, freqs = pywt.cwt(signals[chn], scales, wavelet_type, delta_t)\n",
    "    coef2 = (coef-np.min(coef))/(np.max(coef) - np.min(coef))\n",
    "    #np.save('../saved/cwt/'+name, coef)\n",
    "    if vis:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(211)\n",
    "        plt.plot(x,signals[chn])\n",
    "\n",
    "        ax = fig.add_subplot(212)\n",
    "        #plt.matshow(coefs.astype(float)) \n",
    "        plt.imshow(coef.astype(float), aspect='auto', extent=(1, signals.shape[1], freqs[-1], freqs[0]), cmap='jet')\n",
    "       # plt.colorbar()\n",
    "        #print((freqs[0], freqs[-1]))\n",
    "       # plt.yticks(freqs)\n",
    "        plt.suptitle(name  + ' ' +str(freqs[-1]) + ' '+  str(freqs[0]))\n",
    "        plt.ylabel('Frequency(Hz)')\n",
    "        plt.xlabel('Time(ms)')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "    return coef2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from global_vars import labels\n",
    "def get_image_and_labels(data, header_data):\n",
    "    cmap = plt.get_cmap('jet')\n",
    "    resize = torchvision.transforms.Resize((244, 244))\n",
    "    info = get_basic_info(header_data, labels)\n",
    "    \n",
    "    n_length = data.shape[1]\n",
    "    n_segments = int((n_length)/1000)\n",
    "    \n",
    "    coef = cwt(data, str(i)+' '+str(info[3]), chn=0, vis=False)\n",
    "    data_imgs = []\n",
    "    for j in range(n_segments):\n",
    "        s = j*1000\n",
    "        rgba_img = cmap(coef[:,s:s+1000])\n",
    "        data_img = Image.fromarray((rgba_img[:, :, :3] * 255).astype(np.uint8))\n",
    "        data_imgs.append(resize(data_img))\n",
    "        \n",
    "    return data_imgs, info[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from global_vars import labels\n",
    "def get_basic_info(header_data, labels):\n",
    "    tmp_hea = header_data[0].split(' ')\n",
    "    ptID = tmp_hea[0]\n",
    "    age = None\n",
    "    sex = None\n",
    "    label = None\n",
    "    Dx = None\n",
    "    for iline in header_data:\n",
    "        if iline.startswith('#Age'):\n",
    "            tmp_age = iline.split(': ')[1].strip()\n",
    "            age = int(tmp_age if tmp_age != 'NaN' else 57)\n",
    "        elif iline.startswith('#Sex'):\n",
    "            tmp_sex = iline.split(': ')[1]\n",
    "            if tmp_sex.strip()=='Female':\n",
    "                sex =1\n",
    "            else:\n",
    "                sex=0\n",
    "        elif iline.startswith('#Dx'):\n",
    "            Dx = np.char.rstrip(iline.split(': ')[1].split(','))\n",
    "            label = [ll in Dx for ll in labels]\n",
    "    \n",
    "    return [ptID, sex, age, ' '.join(Dx)] + label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46de3c399867438fbb93fbe6a26cf17b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6877.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_cwt_nn_model('../saved/modelCWTFullWeightedLoss/modelCWTFull1_model.dict')\n",
    "transform =  transforms.Compose([\n",
    "                         transforms.ToTensor(),\n",
    "                         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                         ])\n",
    "\n",
    "y_prob_maxs = []\n",
    "y_prob_means = []\n",
    "y_trues = []\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(len(header_datas))):#fDataReNorms.shape[0])): # , leave=False\n",
    "        tmp_hea = header_datas[i][0].split(' ')\n",
    "        ptID = tmp_hea[0]\n",
    "        \n",
    "        if ptID in np.unique(df_infos3.iloc[test_indices]['ptID']):\n",
    "            data_imgs, y_true = get_image_and_labels(datas[i], header_datas[i])\n",
    "            imgs_tensor = torch.stack([transform(data_img) for data_img in data_imgs])\n",
    "            test_output = model(imgs_tensor)\n",
    "            y_prob_max, y_prob_mean = agg_y_preds(test_output)\n",
    "            y_prob_maxs.append(y_prob_max)\n",
    "            y_prob_means.append(y_prob_mean)\n",
    "            y_trues.append(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC|AUPRC|Accuracy|F-measure|Fbeta-measure|Gbeta-measure\n",
      "0.118|0.375|0.205|0.118|0.905|0.658\n"
     ]
    }
   ],
   "source": [
    "auroc,auprc,acc,fmeasure,fbeta,gbeta = binary_acc(torch.stack(y_prob_maxs), torch.Tensor(y_trues))\n",
    "output_string = 'AUROC|AUPRC|Accuracy|F-measure|Fbeta-measure|Gbeta-measure\\n{:.3f}|{:.3f}|{:.3f}|{:.3f}|{:.3f}|{:.3f}'.format(auroc,auprc,acc,fmeasure,fbeta,gbeta)\n",
    "print(output_string) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC|AUPRC|Accuracy|F-measure|Fbeta-measure|Gbeta-measure\n",
      "0.118|0.375|0.205|0.118|0.911|0.672\n"
     ]
    }
   ],
   "source": [
    "auroc,auprc,acc,fmeasure,fbeta,gbeta = binary_acc(torch.stack(y_prob_means), torch.Tensor(y_trues))\n",
    "output_string = 'AUROC|AUPRC|Accuracy|F-measure|Fbeta-measure|Gbeta-measure\\n{:.3f}|{:.3f}|{:.3f}|{:.3f}|{:.3f}|{:.3f}'.format(auroc,auprc,acc,fmeasure,fbeta,gbeta)\n",
    "print(output_string) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (physioNet)",
   "language": "python",
   "name": "physionet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
