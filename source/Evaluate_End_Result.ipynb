{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "from tqdm.notebook import tqdm\n",
    "import torch, torchvision \n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fef0311b33647c6b20a81253e718c78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "with tqdm(range(10), leave=True) as tq:\n",
    "    for i in tq:\n",
    "        j = 0\n",
    "        sleep(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../saved/datas.pkl', 'rb') as f:\n",
    "    datas = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../saved/header_datas.pkl', 'rb') as f:\n",
    "    header_datas = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "def cwt(signals,name='', chn=6, wavelet_type = 'morl', vis=False):\n",
    "    #print(signals.shape)\n",
    "    # signals: channels x time\n",
    "    num_steps = signals.shape[1]\n",
    "    x = np.arange(num_steps) * 0.002\n",
    "    delta_t = x[1] - x[0] # 500Hz 0.02s\n",
    "    #print(delta_t)\n",
    "    #Freq (5, 100)\n",
    "    if wavelet_type == 'morl':\n",
    "        scales = np.linspace(8,200,100)\n",
    "    elif wavelet_type == 'mexh':\n",
    "        scales = np.linspace(5,50,100)\n",
    "    elif wavelet_type == 'gaus8':\n",
    "        scales = np.linspace(12,120,100)\n",
    "    else: # cmor\n",
    "        scales = np.linspace(12,120,100)\n",
    "    \n",
    "\n",
    "    coef, freqs = pywt.cwt(signals[chn], scales, wavelet_type, delta_t)\n",
    "    coef2 = (coef-np.min(coef))/(np.max(coef) - np.min(coef))\n",
    "    #np.save('../saved/cwt/'+name, coef)\n",
    "    if vis:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(211)\n",
    "        plt.plot(x,signals[chn])\n",
    "\n",
    "        ax = fig.add_subplot(212)\n",
    "        #plt.matshow(coefs.astype(float)) \n",
    "        plt.imshow(coef.astype(float), aspect='auto', extent=(1, signals.shape[1], freqs[-1], freqs[0]), cmap='jet')\n",
    "       # plt.colorbar()\n",
    "        #print((freqs[0], freqs[-1]))\n",
    "       # plt.yticks(freqs)\n",
    "        plt.suptitle(name  + ' ' +str(freqs[-1]) + ' '+  str(freqs[0]))\n",
    "        plt.ylabel('Frequency(Hz)')\n",
    "        plt.xlabel('Time(ms)')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "    return coef2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from global_vars import labels\n",
    "def get_basic_info(header_data, labels):\n",
    "    tmp_hea = header_data[0].split(' ')\n",
    "    ptID = tmp_hea[0]\n",
    "    age = None\n",
    "    sex = None\n",
    "    label = None\n",
    "    Dx = None\n",
    "    for iline in header_data:\n",
    "        if iline.startswith('#Age'):\n",
    "            tmp_age = iline.split(': ')[1].strip()\n",
    "            age = int(tmp_age if tmp_age != 'NaN' else 57)\n",
    "        elif iline.startswith('#Sex'):\n",
    "            tmp_sex = iline.split(': ')[1]\n",
    "            if tmp_sex.strip()=='Female':\n",
    "                sex =1\n",
    "            else:\n",
    "                sex=0\n",
    "        elif iline.startswith('#Dx'):\n",
    "            Dx = np.char.rstrip(iline.split(': ')[1].split(','))\n",
    "            label = [ll in Dx for ll in labels]\n",
    "            \n",
    "    \n",
    "    return [ptID, sex, age, ' '.join(Dx)] + label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, models, transforms\n",
    "from myeval import binary_acc\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from snippets.pytorchtools import EarlyStopping\n",
    "from sklearn.model_selection import KFold\n",
    "import time\n",
    "from myeval import binary_acc_core\n",
    "\n",
    "st = time.time()\n",
    "patience = 200\n",
    "kf = KFold(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "class MyImageDatasetEvaluate(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, data_imgs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.infos = infos\n",
    "        self.data_imgs = data_imgs\n",
    "        self.transform = torchvision.transforms.ToTensor()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        image = self.data_imgs[idx]\n",
    "        sample = self.transform(image)\n",
    "        return sample\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=688.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yfeng/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:21: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n"
     ]
    }
   ],
   "source": [
    "cmap = plt.get_cmap('jet')\n",
    "resize = torchvision.transforms.Resize((244, 244))\n",
    "\n",
    "infos = []\n",
    "data_imgs = []\n",
    "y_pred_res_all = []\n",
    "labels_all = []\n",
    "model = load_cwt_nn_model()\n",
    "\n",
    "for i in tqdm(range(int(6877*0.9), 6877), leave=False):#fDataReNorms.shape[0])): #\n",
    "    data_imgs, labels = get_image_and_labels(datas[i], header_datas[i])\n",
    "    image_datasets = MyImageDatasetEvaluate(data_imgs)\n",
    "    evaluateLoader = torch.utils.data.DataLoader(image_datasets, batch_size=len(data_imgs))\n",
    "    y_preds = []\n",
    "    for evaluate_data in evaluateLoader:\n",
    "        y_preds.append(model(evaluate_data))\n",
    "    y_pred = y_preds[0]\n",
    "    y_pred_res = np.max(torch.sigmoid(y_pred).data.numpy(), axis=0)\n",
    "    y_pred_res_all.append(y_pred_res)\n",
    "    labels_all.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6877"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-7.7559, -3.8176, -6.3618, -0.7391, -2.8079, -3.8788, -0.6910, -3.4339,\n",
       "         -2.8801],\n",
       "        [-6.1261, -3.3991, -5.3951, -0.7411, -2.5121, -3.2138, -1.6194, -1.7641,\n",
       "         -3.0295],\n",
       "        [-8.9664, -4.3498, -6.7516, -0.8275, -2.1237, -3.5941, -1.5199, -2.7619,\n",
       "         -4.2407],\n",
       "        [-7.9214, -1.2597, -5.8512, -1.4833, -2.0789, -4.3321, -2.9035, -2.9721,\n",
       "         -4.2069],\n",
       "        [-6.8842, -3.9893, -6.0467, -1.1785, -3.7997, -2.8877, -2.1973, -1.4071,\n",
       "         -3.2863]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(evaluate_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "def load_cwt_nn_model(model_saved_path='../saved/modelCWTFullBalanced/CWTNetFull0_model.dict'):\n",
    "    model = models.resnet18(pretrained=True)\n",
    "#     for param in model.parameters():\n",
    "#         param.requires_grad = False\n",
    "    \n",
    "    num_ftrs = model.fc.in_features\n",
    "    # change the last output to 9 classes\n",
    "    model.fc = nn.Linear(num_ftrs, 9)\n",
    "    \n",
    "    # load saved model\n",
    "    model.load_state_dict(torch.load(model_saved_path, map_location=torch.device('cpu')))\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from global_vars import labels\n",
    "def get_image_and_labels(data, header_data):\n",
    "    info = get_basic_info(header_data, labels)\n",
    "    \n",
    "    n_length = data.shape[1]\n",
    "    n_segments = int((n_length)/1000)\n",
    "    \n",
    "    coef = cwt(data, str(i)+' '+str(info[3]), chn=0, vis=False)\n",
    "    data_imgs = []\n",
    "    for j in range(n_segments):\n",
    "        s = j*1000\n",
    "        infos.append(info)\n",
    "        rgba_img = cmap(coef[:,s:s+1000])\n",
    "        data_img = Image.fromarray((rgba_img[:, :, :3] * 255).astype(np.uint8))\n",
    "        data_imgs.append(resize(data_img))\n",
    "        \n",
    "    return data_imgs, info[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_12ECG_classifier(data_imgs,model):\n",
    "    # Use your classifier here to obtain a label and score for each class. \n",
    "    \n",
    "    fDatas = []\n",
    "    #infos =[]\n",
    "    fData = filter_data(data[:,1000:], highcut=50.0)\n",
    "    #fData = datas[idx][:,1000:]\n",
    "    intervals = sep_rr_interval(fData[:3], height=0.2, distance=200, plot=False)\n",
    "\n",
    "    # basic info\n",
    "    #info = get_basic_info(header_datas[idx], labels)\n",
    "    \n",
    "    # get data\n",
    "    #ptID = info[0]\n",
    "    #print(str(idx) + ' ' + ptID)\n",
    "    for i in range(len(intervals)):\n",
    "        l, r = intervals[i]\n",
    "        fDatas.append(fData[:,l:r])\n",
    "        #infos.append(info)\n",
    "            \n",
    "    fDataRes=np.array([signal.resample(fData, 250, axis=1) for fData in fDatas])\n",
    "    fDataReNorms=np.array([normalize(fDataRe) for fDataRe in fDataRes])\n",
    "    \n",
    "    X = torch.FloatTensor(fDataReNorms)\n",
    "    \n",
    "    try:\n",
    "        output = model(X)\n",
    "        current_score = np.mean(torch.sigmoid(output).data.numpy(), axis=0)\n",
    "        current_label = np.rint(current_score).astype(int)\n",
    "   # print(current_score.shape, current_label.shape)\n",
    "    except:\n",
    "        print(fDataRes, header_data)\n",
    "        current_label = np.zeros((9,), dtype=int)\n",
    "        current_score = np.zeros((9,))\n",
    "    return current_label, current_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36] *",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
