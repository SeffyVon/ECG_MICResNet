{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_infos = pd.read_csv('../saved/infos.csv')\n",
    "fDataReNorms = np.load('../saved/fDataReNorms.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ptID</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>AF</th>\n",
       "      <th>I-AVB</th>\n",
       "      <th>LBBB</th>\n",
       "      <th>Normal</th>\n",
       "      <th>PAC</th>\n",
       "      <th>PVC</th>\n",
       "      <th>RBBB</th>\n",
       "      <th>STD</th>\n",
       "      <th>STE</th>\n",
       "      <th>mean_intervals</th>\n",
       "      <th>std_intervals</th>\n",
       "      <th>interval_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A0001</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>299.055556</td>\n",
       "      <td>32.777825</td>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A0001</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>299.055556</td>\n",
       "      <td>32.777825</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A0001</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>299.055556</td>\n",
       "      <td>32.777825</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A0001</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>299.055556</td>\n",
       "      <td>32.777825</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>A0001</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>299.055556</td>\n",
       "      <td>32.777825</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104423</th>\n",
       "      <td>104423</td>\n",
       "      <td>A6813</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>511.076923</td>\n",
       "      <td>20.409129</td>\n",
       "      <td>529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104424</th>\n",
       "      <td>104424</td>\n",
       "      <td>A6813</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>511.076923</td>\n",
       "      <td>20.409129</td>\n",
       "      <td>526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104425</th>\n",
       "      <td>104425</td>\n",
       "      <td>A6813</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>511.076923</td>\n",
       "      <td>20.409129</td>\n",
       "      <td>516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104426</th>\n",
       "      <td>104426</td>\n",
       "      <td>A6813</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>511.076923</td>\n",
       "      <td>20.409129</td>\n",
       "      <td>488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104427</th>\n",
       "      <td>104427</td>\n",
       "      <td>A6813</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>511.076923</td>\n",
       "      <td>20.409129</td>\n",
       "      <td>483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104428 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0   ptID  Sex  Age     AF  I-AVB   LBBB  Normal    PAC  \\\n",
       "0                0  A0001    0   74  False  False  False   False  False   \n",
       "1                1  A0001    0   74  False  False  False   False  False   \n",
       "2                2  A0001    0   74  False  False  False   False  False   \n",
       "3                3  A0001    0   74  False  False  False   False  False   \n",
       "4                4  A0001    0   74  False  False  False   False  False   \n",
       "...            ...    ...  ...  ...    ...    ...    ...     ...    ...   \n",
       "104423      104423  A6813    0   60  False  False   True   False  False   \n",
       "104424      104424  A6813    0   60  False  False   True   False  False   \n",
       "104425      104425  A6813    0   60  False  False   True   False  False   \n",
       "104426      104426  A6813    0   60  False  False   True   False  False   \n",
       "104427      104427  A6813    0   60  False  False   True   False  False   \n",
       "\n",
       "          PVC   RBBB    STD    STE  mean_intervals  std_intervals  \\\n",
       "0       False   True  False  False      299.055556      32.777825   \n",
       "1       False   True  False  False      299.055556      32.777825   \n",
       "2       False   True  False  False      299.055556      32.777825   \n",
       "3       False   True  False  False      299.055556      32.777825   \n",
       "4       False   True  False  False      299.055556      32.777825   \n",
       "...       ...    ...    ...    ...             ...            ...   \n",
       "104423  False  False  False  False      511.076923      20.409129   \n",
       "104424  False  False  False  False      511.076923      20.409129   \n",
       "104425  False  False  False  False      511.076923      20.409129   \n",
       "104426  False  False  False  False      511.076923      20.409129   \n",
       "104427  False  False  False  False      511.076923      20.409129   \n",
       "\n",
       "        interval_len  \n",
       "0                303  \n",
       "1                292  \n",
       "2                296  \n",
       "3                296  \n",
       "4                298  \n",
       "...              ...  \n",
       "104423           529  \n",
       "104424           526  \n",
       "104425           516  \n",
       "104426           488  \n",
       "104427           483  \n",
       "\n",
       "[104428 rows x 16 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import normalize\n",
    "#fDataReNorms=[fDataRe-np.tile(fDataRe[:,0],(250,1)).transpose() for fDataRe in fDataRes]\n",
    "# fDataReNorms=np.array([normalize(fDataRe) for fDataRe in fDataRes])\n",
    "# np.save('../saved/fDataReNorms.npy', fDataReNorms)\n",
    "#[plt.plot(fDataReNorm[6]) for fDataReNorm in fDataReNorms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fDataReNormAFs = fDataReNorms[df_infos['AF']]\n",
    "\n",
    "# for fDataReNormAF in fDataReNormAFs[:10]:\n",
    "#     plt.plot(fDataReNormAF[0])\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 104428})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from global_vars import headers, labels\n",
    "print(Counter(np.sum(df_infos[labels], axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.FloatTensor(df_infos[labels].to_numpy()).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.FloatTensor(fDataReNorms).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = torch.FloatTensor(df_infos[['Sex', 'Age', 'mean_intervals', 'std_intervals', 'interval_len']].to_numpy()).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:  torch.Size([104428, 12, 250])\n",
      "1:  torch.Size([104428, 12, 250])\n",
      "2:  torch.Size([104428, 12, 10])\n",
      "3:  torch.Size([104428, 12, 10])\n",
      "4:  torch.Size([104428, 15])\n",
      "5:  torch.Size([104428, 20])\n",
      "6:  torch.Size([104428, 20])\n",
      "7:  torch.Size([104428, 9])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 43.3860,  19.5141,  26.6070,  ...,  77.4055,  -6.3090, -33.0933],\n",
       "        [ 41.6239,  20.8789,  24.5374,  ...,  77.2411,  -7.0637, -30.8619],\n",
       "        [ 42.2668,  20.3814,  25.2884,  ...,  77.3065,  -6.7882, -31.6744],\n",
       "        ...,\n",
       "        [ 57.9131,  25.9445,  38.9378,  ..., 123.7940,  -8.7163, -43.7670],\n",
       "        [ 53.4099,  29.4192,  33.6622,  ..., 123.3690, -10.6288, -38.0921],\n",
       "        [ 52.6100,  30.0407,  32.7229,  ..., 123.2971, -10.9716, -37.0805]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SimpleNetWithProp(nn.Module):\n",
    "    def __init__(self, n_input, n_h1, n_h2, n_h3, verbose=False):\n",
    "        super(SimpleNetWithProp, self).__init__()\n",
    "        self.fc1        = nn.Linear(n_input, n_h1)\n",
    "        self.fc2        = nn.Linear(n_h1, n_h2)\n",
    "        self.fc3        = nn.Linear(120, n_h3)\n",
    "        self.fc4        = nn.Linear(20, 9)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.verbose=verbose\n",
    "\n",
    "    def forward(self, x, x2):\n",
    "        if self.verbose:\n",
    "            print('0: ', x.shape)\n",
    "        x = self.fc1( x )     \n",
    "        x = self.dropout(x)\n",
    "        if self.verbose:\n",
    "            print('1: ', x.shape)\n",
    "        x = F.relu(   x )     \n",
    "        x = self.fc2( x )    \n",
    "        if self.verbose:\n",
    "            print('2: ', x.shape)\n",
    "        x = F.relu(   x )      \n",
    "        if self.verbose:\n",
    "            print('3: ', x.shape)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc3( x )  \n",
    "        if self.verbose:\n",
    "            print('4: ', x.shape)\n",
    "        x = torch.cat((x, x2),1)\n",
    "        if self.verbose:\n",
    "            print('5: ', x.shape)\n",
    "            \n",
    "        x = F.relu(   x )   \n",
    "        if self.verbose:\n",
    "            print('6: ', x.shape)\n",
    "            \n",
    "        x = self.fc4(x)\n",
    "        if self.verbose:\n",
    "            print('7: ', x.shape)\n",
    "        return x\n",
    "\n",
    "model = SimpleNetWithProp(250, 250, 10, 15, verbose=True)\n",
    "model.forward(X.cpu(), X2.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([104428, 5])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S0/0 0.01 min|\n",
      "Train Loss: 54.943287, Acc: 0.36, F: 0.19, Fbeta: 0.10, gbeta: 0.05, auroc: 0.51, auprc: 0.37 |\n",
      "Valid Loss: 54.129162, Acc: 0.36, F: 0.19, Fbeta: 0.10, gbeta: 0.05, auroc: 0.49, auprc: 0.37\n",
      " \n",
      "S0/200 0.80 min|\n",
      "Train Loss: 2.512851, Acc: 0.90, F: 0.31, Fbeta: 0.34, gbeta: 0.17, auroc: 0.79, auprc: 0.40 |\n",
      "Valid Loss: 2.507475, Acc: 0.90, F: 0.32, Fbeta: 0.36, gbeta: 0.18, auroc: 0.78, auprc: 0.41\n",
      " \n",
      "S0/400 1.60 min|\n",
      "Train Loss: 1.383165, Acc: 0.91, F: 0.35, Fbeta: 0.39, gbeta: 0.20, auroc: 0.85, auprc: 0.50 |\n",
      "Valid Loss: 1.389162, Acc: 0.91, F: 0.36, Fbeta: 0.40, gbeta: 0.21, auroc: 0.83, auprc: 0.48\n",
      " \n",
      "S0/600 2.41 min|\n",
      "Train Loss: 0.994446, Acc: 0.92, F: 0.39, Fbeta: 0.44, gbeta: 0.23, auroc: 0.88, auprc: 0.55 |\n",
      "Valid Loss: 1.002656, Acc: 0.92, F: 0.41, Fbeta: 0.45, gbeta: 0.24, auroc: 0.87, auprc: 0.54\n",
      " \n",
      "S0/800 3.22 min|\n",
      "Train Loss: 0.795094, Acc: 0.93, F: 0.43, Fbeta: 0.48, gbeta: 0.26, auroc: 0.90, auprc: 0.60 |\n",
      "Valid Loss: 0.803945, Acc: 0.92, F: 0.44, Fbeta: 0.48, gbeta: 0.26, auroc: 0.88, auprc: 0.58\n",
      " \n",
      "S0/1000 4.03 min|\n",
      "Train Loss: 0.673343, Acc: 0.93, F: 0.47, Fbeta: 0.53, gbeta: 0.29, auroc: 0.91, auprc: 0.63 |\n",
      "Valid Loss: 0.682840, Acc: 0.93, F: 0.47, Fbeta: 0.52, gbeta: 0.29, auroc: 0.89, auprc: 0.60\n",
      " \n",
      "S0/1200 4.85 min|\n",
      "Train Loss: 0.590960, Acc: 0.93, F: 0.48, Fbeta: 0.53, gbeta: 0.30, auroc: 0.91, auprc: 0.65 |\n",
      "Valid Loss: 0.601284, Acc: 0.93, F: 0.48, Fbeta: 0.52, gbeta: 0.29, auroc: 0.90, auprc: 0.61\n",
      " \n",
      "S0/1400 5.65 min|\n",
      "Train Loss: 0.531409, Acc: 0.93, F: 0.51, Fbeta: 0.56, gbeta: 0.32, auroc: 0.92, auprc: 0.66 |\n",
      "Valid Loss: 0.542703, Acc: 0.93, F: 0.50, Fbeta: 0.54, gbeta: 0.31, auroc: 0.90, auprc: 0.62\n",
      " \n",
      "S0/1600 6.46 min|\n",
      "Train Loss: 0.486254, Acc: 0.94, F: 0.50, Fbeta: 0.55, gbeta: 0.32, auroc: 0.92, auprc: 0.68 |\n",
      "Valid Loss: 0.498550, Acc: 0.93, F: 0.49, Fbeta: 0.52, gbeta: 0.30, auroc: 0.90, auprc: 0.62\n",
      " \n",
      "S0/1800 7.27 min|\n",
      "Train Loss: 0.450795, Acc: 0.94, F: 0.52, Fbeta: 0.56, gbeta: 0.33, auroc: 0.92, auprc: 0.69 |\n",
      "Valid Loss: 0.464075, Acc: 0.93, F: 0.49, Fbeta: 0.54, gbeta: 0.31, auroc: 0.91, auprc: 0.63\n",
      " \n",
      "S0/2000 8.08 min|\n",
      "Train Loss: 0.422175, Acc: 0.94, F: 0.54, Fbeta: 0.59, gbeta: 0.34, auroc: 0.93, auprc: 0.70 |\n",
      "Valid Loss: 0.436426, Acc: 0.93, F: 0.50, Fbeta: 0.54, gbeta: 0.31, auroc: 0.91, auprc: 0.63\n",
      " \n",
      "S0/2200 8.89 min|\n",
      "Train Loss: 0.398542, Acc: 0.94, F: 0.54, Fbeta: 0.59, gbeta: 0.35, auroc: 0.93, auprc: 0.71 |\n",
      "Valid Loss: 0.413772, Acc: 0.93, F: 0.50, Fbeta: 0.55, gbeta: 0.31, auroc: 0.91, auprc: 0.63\n",
      " \n",
      "S0/2400 9.69 min|\n",
      "Train Loss: 0.378655, Acc: 0.94, F: 0.54, Fbeta: 0.60, gbeta: 0.35, auroc: 0.93, auprc: 0.72 |\n",
      "Valid Loss: 0.394853, Acc: 0.93, F: 0.49, Fbeta: 0.54, gbeta: 0.31, auroc: 0.91, auprc: 0.63\n",
      " \n",
      "S0/2600 10.50 min|\n",
      "Train Loss: 0.361590, Acc: 0.94, F: 0.58, Fbeta: 0.64, gbeta: 0.38, auroc: 0.93, auprc: 0.73 |\n",
      "Valid Loss: 0.378774, Acc: 0.93, F: 0.53, Fbeta: 0.57, gbeta: 0.33, auroc: 0.91, auprc: 0.64\n",
      " \n",
      "S0/2800 11.30 min|\n",
      "Train Loss: 0.346820, Acc: 0.94, F: 0.57, Fbeta: 0.62, gbeta: 0.37, auroc: 0.94, auprc: 0.73 |\n",
      "Valid Loss: 0.364974, Acc: 0.93, F: 0.51, Fbeta: 0.55, gbeta: 0.32, auroc: 0.91, auprc: 0.64\n",
      " \n",
      "S0/3000 12.11 min|\n",
      "Train Loss: 0.333904, Acc: 0.94, F: 0.60, Fbeta: 0.65, gbeta: 0.39, auroc: 0.94, auprc: 0.74 |\n",
      "Valid Loss: 0.353018, Acc: 0.93, F: 0.53, Fbeta: 0.57, gbeta: 0.34, auroc: 0.91, auprc: 0.64\n",
      " \n",
      "S0/3200 12.92 min|\n",
      "Train Loss: 0.322496, Acc: 0.94, F: 0.58, Fbeta: 0.63, gbeta: 0.39, auroc: 0.94, auprc: 0.75 |\n",
      "Valid Loss: 0.342576, Acc: 0.93, F: 0.53, Fbeta: 0.56, gbeta: 0.34, auroc: 0.91, auprc: 0.64\n",
      " \n",
      "S0/3400 13.72 min|\n",
      "Train Loss: 0.312340, Acc: 0.94, F: 0.61, Fbeta: 0.66, gbeta: 0.40, auroc: 0.94, auprc: 0.75 |\n",
      "Valid Loss: 0.333390, Acc: 0.93, F: 0.53, Fbeta: 0.57, gbeta: 0.34, auroc: 0.91, auprc: 0.64\n",
      " \n",
      "S0/3600 14.53 min|\n",
      "Train Loss: 0.303236, Acc: 0.94, F: 0.59, Fbeta: 0.64, gbeta: 0.39, auroc: 0.94, auprc: 0.76 |\n",
      "Valid Loss: 0.325260, Acc: 0.93, F: 0.52, Fbeta: 0.55, gbeta: 0.33, auroc: 0.91, auprc: 0.63\n",
      " \n",
      "S0/3800 15.33 min|\n",
      "Train Loss: 0.295024, Acc: 0.94, F: 0.62, Fbeta: 0.67, gbeta: 0.41, auroc: 0.94, auprc: 0.76 |\n",
      "Valid Loss: 0.318018, Acc: 0.93, F: 0.54, Fbeta: 0.57, gbeta: 0.34, auroc: 0.91, auprc: 0.64\n",
      " \n",
      "S0/4000 16.13 min|\n",
      "Train Loss: 0.287569, Acc: 0.95, F: 0.64, Fbeta: 0.68, gbeta: 0.42, auroc: 0.94, auprc: 0.76 |\n",
      "Valid Loss: 0.311515, Acc: 0.93, F: 0.54, Fbeta: 0.58, gbeta: 0.35, auroc: 0.91, auprc: 0.64\n",
      " \n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
    "from evaluate_12ECG_score import compute_beta_score, compute_auc\n",
    "\n",
    "# def evaluate_beta(output, y):\n",
    "    \n",
    "#     accuracy,f_measure,f_beta,g_beta = compute_beta_score(labels=y, \n",
    "#                        output=output, \n",
    "#                        beta=2, num_classes=1)\n",
    "    \n",
    "#     auroc, auprc = compute_auc(labels=y, \n",
    "#                                 probabilities=output,\n",
    "#                                 num_classes=1)\n",
    "\n",
    "#     return accuracy,f_measure,f_beta,g_beta, auroc, auprc\n",
    "\n",
    "\n",
    "def confusion(prediction, truth):\n",
    "    \n",
    "    \"\"\" Returns the confusion matrix for the values in the `prediction` and `truth`\n",
    "    tensors, i.e. the amount of positions where the values of `prediction`\n",
    "    and `truth` are\n",
    "    - 1 and 1 (True Positive)\n",
    "    - 1 and 0 (False Positive)\n",
    "    - 0 and 0 (True Negative)\n",
    "    - 0 and 1 (False Negative)\n",
    "    https://gist.github.com/the-bass/cae9f3976866776dea17a5049013258d\n",
    "    \"\"\"\n",
    "\n",
    "    confusion_vector = prediction / truth\n",
    "    # Element-wise division of the 2 tensors returns a new tensor which holds a\n",
    "    # unique value for each case:\n",
    "    #   1     where prediction and truth are 1 (True Positive)\n",
    "    #   inf   where prediction is 1 and truth is 0 (False Positive)\n",
    "    #   nan   where prediction and truth are 0 (True Negative)\n",
    "    #   0     where prediction is 0 and truth is 1 (False Negative)\n",
    "\n",
    "    true_positives = torch.sum(confusion_vector == 1).item()\n",
    "    false_positives = torch.sum(confusion_vector == float('inf')).item()\n",
    "    true_negatives = torch.sum(torch.isnan(confusion_vector)).item()\n",
    "    false_negatives = torch.sum(confusion_vector == 0).item()\n",
    "\n",
    "    return true_positives, false_positives, true_negatives, false_negatives\n",
    "\n",
    "def binary_acc(y_preds, y_tests, beta=2):\n",
    "    accs = []\n",
    "    fmeasures = []\n",
    "    fbetas = []\n",
    "    gbetas = []\n",
    "    aurocs = []\n",
    "    auprcs = []\n",
    "    for i in range(9):\n",
    "        y_pred, y_test = y_preds[:,i], y_tests[:,i]\n",
    "        \n",
    "        # prob\n",
    "        y_pred_prob = torch.sigmoid(y_pred)\n",
    "        \n",
    "        # auroc\n",
    "        y_test_numpy = y_test.data.cpu().numpy()\n",
    "        y_pred_prob_numpy = y_pred_prob.data.cpu().numpy()\n",
    "        auroc = roc_auc_score(y_test_numpy, y_pred_prob_numpy)\n",
    "        \n",
    "        # auprc\n",
    "        precision, recall, thresholds = precision_recall_curve(y_test_numpy, y_pred_prob_numpy)\n",
    "        auprc = auc(recall, precision)\n",
    "\n",
    "        # binary result\n",
    "        y_pred_tag = torch.round(y_pred_prob)\n",
    "        tp, fp, tn, fn = confusion(y_pred_tag, y_test)\n",
    "        \n",
    "        # acc, fmeasure, fbeta, gbeta\n",
    "        acc = float(tp + tn) / float(tp + fp + fn + tn)\n",
    "        fmeasure = float(2 * tp) / float(2 * tp + fp + fn)\n",
    "        fbeta = float((1+beta**2)* tp) / float(((1+beta**2)*tp) + (fn*beta**2) + fp)\n",
    "        gbeta = float(tp) / float(tp + fp + beta*fn)\n",
    "        \n",
    "        # old way to cal acc:\n",
    "        #correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "        #acc = true_positives/y_test.shape[0]\n",
    "        #acc = torch.round(acc * 100)\n",
    "\n",
    "        accs.append(acc)#.data.cpu().numpy())\n",
    "        fbetas.append(fbeta)#.data.cpu().numpy())\n",
    "        fmeasures.append(fmeasure)\n",
    "        gbetas.append(gbeta)\n",
    "        aurocs.append(auroc)\n",
    "        auprcs.append(auprc)\n",
    "    return np.mean(accs), np.mean(fbetas), np.mean(fmeasures), np.mean(gbetas), np.mean(aurocs), np.mean(auprcs)\n",
    "\n",
    "from snippets.pytorchtools import EarlyStopping\n",
    "from sklearn.model_selection import KFold\n",
    "import time\n",
    "\n",
    "st = time.time()\n",
    "patience = 200\n",
    "kf = KFold(10)\n",
    "\n",
    "saved_dir = '../saved/model/'\n",
    "for i, (train_idx, test_idx) in enumerate(kf.split(X, y)):\n",
    "    model = SimpleNetWithProp(250, 250, 10, 15).to(device)\n",
    "    learning_rate = 0.01\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    losses_train = []\n",
    "    losses_test = []\n",
    "\n",
    "    avg_losses_train = []\n",
    "    avg_losses_test = []\n",
    "\n",
    "\n",
    "    early_stopping = EarlyStopping(patience, verbose=False, \n",
    "                                  saved_dir=saved_dir, \n",
    "                                   save_name='SimpleNetWithProp'+str(i))\n",
    "    epoch = 0\n",
    "    auroc = 0\n",
    "    auprc = 0\n",
    "    accuracy = 0\n",
    "    fmeasure = 0\n",
    "    fbeta = 0\n",
    "    gbeta = 0\n",
    "    for epoch in range(10000):\n",
    "        train_loss = 0\n",
    "        validation_loss = 0\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output_train = model(X[train_idx], X2[train_idx])\n",
    "        output_test = model(X[test_idx], X2[test_idx])\n",
    "\n",
    "        loss_train = criterion(output_train, y[train_idx])\n",
    "        loss_test = criterion(output_test, y[test_idx])\n",
    "\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses_train.append(loss_train.item())\n",
    "        losses_test.append(loss_test.item())\n",
    "\n",
    "        avg_loss_train = np.average(losses_train)\n",
    "        avg_loss_test = np.average(losses_test)\n",
    "\n",
    "        avg_losses_train.append(avg_loss_train)\n",
    "        avg_losses_test.append(avg_loss_test)\n",
    "\n",
    "        if epoch % 200 == 0:\n",
    "            acc, fmeasure, fbeta, gbeta, auroc, auprc = binary_acc(output_train, y[train_idx])\n",
    "            acc2, fmeasure2, fbeta2, gbeta2, auroc2, auprc2 = binary_acc(output_test, y[test_idx])\n",
    "            #accuracy_p = ' '.join(['{:.2f},'.format(acc)for acc in accuracy])\n",
    "            #accuracy2_p = ' '.join(['{:.2f},'.format(acc)for acc in accuracy2])\n",
    "            print('S{}/{} {:.2f} min|\\nTrain Loss: {:.6f}, Acc: {:.2f}, F: {:.2f}, Fbeta: {:.2f}, gbeta: {:.2f}, auroc: {:.2f}, auprc: {:.2f} |\\nValid Loss: {:.6f}, Acc: {:.2f}, F: {:.2f}, Fbeta: {:.2f}, gbeta: {:.2f}, auroc: {:.2f}, auprc: {:.2f}\\n '.format(\n",
    "                i, epoch, (time.time()-st)/60,\n",
    "                avg_loss_train, acc, fmeasure, fbeta, gbeta, auroc, auprc, \n",
    "                avg_loss_test, acc2, fmeasure2, fbeta2, gbeta2, auroc2, auprc2))\n",
    "\n",
    "        early_stopping(avg_loss_test, model)\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "            \n",
    "    output_string = 'AUROC|AUPRC|Accuracy|F-measure|Fbeta-measure|Gbeta-measure\\n{:.3f}|{:.3f}|{:.3f}|{:.3f}|{:.3f}|{:.3f}'.format(auroc,auprc,acc,fmeasure,fbeta,gbeta)\n",
    "    print(output_string)     \n",
    "    with open(saved_dir+'score'+ str(i)+ '_epoch' + str(epoch) + '.txt', 'w') as f:\n",
    "        f.write(output_string)\n",
    "\n",
    "    avg_losses_train = np.array(avg_losses_train)\n",
    "    avg_losses_test = np.array(avg_losses_test)\n",
    "    \n",
    "    np.save(saved_dir + 'avg_losses_train' + str(i) + '_epoch' + str(epoch), avg_losses_train)\n",
    "    np.save(saved_dir + 'avg_losses_test' + str(i) + '_epoch' + str(epoch), avg_losses_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (physioNet)",
   "language": "python",
   "name": "physionet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
